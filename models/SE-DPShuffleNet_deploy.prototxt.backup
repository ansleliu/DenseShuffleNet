name: "SE-DPShuffleNet"

input: "data"
input_dim: 1
input_dim: 3
input_dim: 384
input_dim: 768

# ------------------------------ Net Define ------------------------------ #
#################### conv1 ####################
layer {
  name: "conv1"
  type: "Convolution"

  bottom: "data"
  top: "conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 128

    kernel_size: 7
    pad: 3
    stride: 2
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"

  bottom: "conv1"
  top: "conv1"

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"

  bottom: "conv1"
  top: "conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"

  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"

  bottom: "conv1"
  top: "pool1"

  pooling_param {
    pool: MAX

    kernel_size: 3
    stride: 2
  }
}
#################### dpn1 ####################
layer {
  name: "dpn1_match_bn"
  type: "BatchNorm"

  bottom: "pool1"
  top: "dpn1_match_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_match_scale"
  type: "Scale"

  bottom: "dpn1_match_bn"
  top: "dpn1_match_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_match_relu"
  type: "ReLU"

  bottom: "dpn1_match_bn"
  top: "dpn1_match_bn"
}

layer {
  name: "dpn1_match_conv"
  type: "Convolution"

  bottom: "dpn1_match_bn"
  top: "dpn1_match_conv"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 288

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# ------------------------- Channel Shuffle Start
layer {
  name: "dpn1_match_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn1_match_conv"
  top: "dpn1_match_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End


layer {
  name: "dpn1_match_conv_Slice"
  type: "Slice"

  bottom: "dpn1_match_shuffle"
  top: "dpn1_match_conv_split1"  # 0~255
  top: "dpn1_match_conv_split2"  # 256~287  32

  slice_param {
    axis: 1     # channel wise
    slice_point: 256
  }
}
layer {
  name: "dpn1_bn"
  type: "BatchNorm"

  bottom: "pool1"
  top: "dpn1_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_scale"
  type: "Scale"

  bottom: "dpn1_bn"
  top: "dpn1_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_relu"
  type: "ReLU"

  bottom: "dpn1_bn"
  top: "dpn1_bn"
}

layer {
  name: "dpn1_conv1"
  type: "Convolution"

  bottom: "dpn1_bn"
  top: "dpn1_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn1_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn1_conv1"
  top: "dpn1_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_conv1_scale"
  type: "Scale"

  bottom: "dpn1_conv1"
  top: "dpn1_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_conv1_relu"
  type: "ReLU"

  bottom: "dpn1_conv1"
  top: "dpn1_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn1_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn1_conv1"
  top: "dpn1_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn1_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn1_shuffle"
  top: "dpn1_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn1_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn1_conv2"
  top: "dpn1_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_conv2_scale"
  type: "Scale"

  bottom: "dpn1_conv2"
  top: "dpn1_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_conv2_relu"
  type: "ReLU"

  bottom: "dpn1_conv2"
  top: "dpn1_conv2"
}
layer {
  name: "dpn1_conv3"
  type: "Convolution"

  bottom: "dpn1_conv2"
  top: "dpn1_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 272

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn1_pool/gap"
  type: "Pooling"

  bottom: "dpn1_conv3"
  top: "dpn1_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn1_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn1_pool/gap"
  top: "dpn1_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 17       # 272/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn1_relu/sqz"
  type: "ReLU"

  bottom: "dpn1_fc1/sqz"
  top: "dpn1_fc1/sqz"
}
layer {
  name: "dpn1_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn1_fc1/sqz"
  top: "dpn1_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 272

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn1_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn1_fc2/exc"
  top: "dpn1_fc2/exc"
}
layer {
  name: "dpn1_scale/se"
  type: "Scale"

  bottom: "dpn1_conv3"
  bottom: "dpn1_fc2/exc"
  top: "dpn1_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End

layer {
  name: "dpn1_conv3_Slice"
  type: "Slice"

  bottom: "dpn1_scale/se"
  top: "dpn1_conv3_split1"  # 0~255
  top: "dpn1_conv3_split2"  # 256~271

  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn1_elewise"
  type: "Eltwise"

  bottom: "dpn1_match_conv_split1"
  bottom: "dpn1_conv3_split1"
  top: "dpn1_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn1_concat"
  type: "Concat"

  bottom: "dpn1_match_conv_split2"
  bottom: "dpn1_conv3_split2"
  top: "dpn1_concat"
}

#################### dpn2 ####################
layer {
  name: "dpn2_concat_input"
  type: "Concat"

  bottom: "dpn1_elewise"
  bottom: "dpn1_concat"
  top: "dpn2_concat_input"
}
layer {
  name: "dpn2_bn"
  type: "BatchNorm"

  bottom: "dpn2_concat_input"
  top: "dpn2_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn2_scale"
  type: "Scale"

  bottom: "dpn2_bn"
  top: "dpn2_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn2_relu"
  type: "ReLU"

  bottom: "dpn2_bn"
  top: "dpn2_bn"
}
layer {
  name: "dpn2_conv1"
  type: "Convolution"

  bottom: "dpn2_bn"
  top: "dpn2_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn2_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn2_conv1"
  top: "dpn2_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn2_conv1_scale"
  type: "Scale"

  bottom: "dpn2_conv1"
  top: "dpn2_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn2_conv1_relu"
  type: "ReLU"

  bottom: "dpn2_conv1"
  top: "dpn2_conv1"
}


# ------------------------- Channel Shuffle Start
layer {
  name: "dpn2_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn2_conv1"
  top: "dpn2_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End


layer {
  name: "dpn2_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn2_shuffle"
  top: "dpn2_conv2"

  convolution_param {
    num_output: 160

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn2_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn2_conv2"
  top: "dpn2_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn2_conv2_scale"
  type: "Scale"

  bottom: "dpn2_conv2"
  top: "dpn2_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn2_conv2_relu"
  type: "ReLU"

  bottom: "dpn2_conv2"
  top: "dpn2_conv2"
}
layer {
  name: "dpn2_conv3"
  type: "Convolution"

  bottom: "dpn2_conv2"
  top: "dpn2_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 272

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn2_pool/gap"
  type: "Pooling"

  bottom: "dpn2_conv3"
  top: "dpn2_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn2_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn2_pool/gap"
  top: "dpn2_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 17       # 272/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn2_relu/sqz"
  type: "ReLU"

  bottom: "dpn2_fc1/sqz"
  top: "dpn2_fc1/sqz"
}
layer {
  name: "dpn2_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn2_fc1/sqz"
  top: "dpn2_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 272

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn2_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn2_fc2/exc"
  top: "dpn2_fc2/exc"
}
layer {
  name: "dpn2_scale/se"
  type: "Scale"

  bottom: "dpn2_conv3"
  bottom: "dpn2_fc2/exc"
  top: "dpn2_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End

layer {
  name: "dpn2_conv3_Slice"
  type: "Slice"

  bottom: "dpn2_scale/se"
  top: "dpn2_conv3_split1"  # 0~255
  top: "dpn2_conv3_split2"  # 256~271

  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn2_elewise"
  type: "Eltwise"

  bottom: "dpn1_elewise"
  bottom: "dpn2_conv3_split1"
  top: "dpn2_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn2_concat"
  type: "Concat"

  bottom: "dpn1_concat"
  bottom: "dpn2_conv3_split2"
  top: "dpn2_concat"
}
#################### dpn3 ####################
layer {
  name: "dpn3_concat_input"
  type: "Concat"

  bottom: "dpn2_elewise"
  bottom: "dpn2_concat"
  top: "dpn3_concat_input"
}
layer {
  name: "dpn3_bn"
  type: "BatchNorm"

  bottom: "dpn3_concat_input"
  top: "dpn3_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn3_scale"
  type: "Scale"

  bottom: "dpn3_bn"
  top: "dpn3_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn3_relu"
  type: "ReLU"

  bottom: "dpn3_bn"
  top: "dpn3_bn"
}
layer {
  name: "dpn3_conv1"
  type: "Convolution"

  bottom: "dpn3_bn"
  top: "dpn3_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn3_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn3_conv1"
  top: "dpn3_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn3_conv1_scale"
  type: "Scale"

  bottom: "dpn3_conv1"
  top: "dpn3_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn3_conv1_relu"
  type: "ReLU"

  bottom: "dpn3_conv1"
  top: "dpn3_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn3_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn3_conv1"
  top: "dpn3_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn3_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn3_shuffle"
  top: "dpn3_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn3_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn3_conv2"
  top: "dpn3_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn3_conv2_scale"
  type: "Scale"

  bottom: "dpn3_conv2"
  top: "dpn3_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn3_conv2_relu"
  type: "ReLU"

  bottom: "dpn3_conv2"
  top: "dpn3_conv2"
}
layer {
  name: "dpn3_conv3"
  type: "Convolution"

  bottom: "dpn3_conv2"
  top: "dpn3_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 272

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn3_pool/gap"
  type: "Pooling"

  bottom: "dpn3_conv3"
  top: "dpn3_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn3_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn3_pool/gap"
  top: "dpn3_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 17       # 272/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn3_relu/sqz"
  type: "ReLU"

  bottom: "dpn3_fc1/sqz"
  top: "dpn3_fc1/sqz"
}
layer {
  name: "dpn3_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn3_fc1/sqz"
  top: "dpn3_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 272

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn3_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn3_fc2/exc"
  top: "dpn3_fc2/exc"
}
layer {
  name: "dpn3_scale/se"
  type: "Scale"

  bottom: "dpn3_conv3"
  bottom: "dpn3_fc2/exc"
  top: "dpn3_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn3_conv3_Slice"
  type: "Slice"

  bottom: "dpn3_scale/se"
  top: "dpn3_conv3_split1"  # 0~255
  top: "dpn3_conv3_split2"  # 256~271

  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn3_elewise"
  type: "Eltwise"

  bottom: "dpn2_elewise"
  bottom: "dpn3_conv3_split1"
  top: "dpn3_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn3_concat"
  type: "Concat"

  bottom: "dpn2_concat"
  bottom: "dpn3_conv3_split2"
  top: "dpn3_concat"
}

#################### dpn4 ####################
layer {
  name: "dpn4_concat_input"
  type: "Concat"

  bottom: "dpn3_elewise"
  bottom: "dpn3_concat"
  top: "dpn4_concat_input"
}
layer {
  name: "dpn4_bn"
  type: "BatchNorm"

  bottom: "dpn4_concat_input"
  top: "dpn4_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_scale"
  type: "Scale"

  bottom: "dpn4_bn"
  top: "dpn4_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_relu"
  type: "ReLU"

  bottom: "dpn4_bn"
  top: "dpn4_bn"
}
layer {
  name: "dpn4_conv1"
  type: "Convolution"

  bottom: "dpn4_bn"
  top: "dpn4_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn4_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn4_conv1"
  top: "dpn4_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_conv1_scale"
  type: "Scale"

  bottom: "dpn4_conv1"
  top: "dpn4_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_conv1_relu"
  type: "ReLU"

  bottom: "dpn4_conv1"
  top: "dpn4_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn4_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn4_conv1"
  top: "dpn4_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn4_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn4_shuffle"
  top: "dpn4_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 160

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn4_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn4_conv2"
  top: "dpn4_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_conv2_scale"
  type: "Scale"

  bottom: "dpn4_conv2"
  top: "dpn4_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_conv2_relu"
  type: "ReLU"

  bottom: "dpn4_conv2"
  top: "dpn4_conv2"
}
layer {
  name: "dpn4_conv3"
  type: "Convolution"

  bottom: "dpn4_conv2"
  top: "dpn4_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 272

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn4_pool/gap"
  type: "Pooling"

  bottom: "dpn4_conv3"
  top: "dpn4_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn4_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn4_pool/gap"
  top: "dpn4_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 17       # 272/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn4_relu/sqz"
  type: "ReLU"

  bottom: "dpn4_fc1/sqz"
  top: "dpn4_fc1/sqz"
}
layer {
  name: "dpn4_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn4_fc1/sqz"
  top: "dpn4_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 272

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn4_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn4_fc2/exc"
  top: "dpn4_fc2/exc"
}
layer {
  name: "dpn4_scale/se"
  type: "Scale"

  bottom: "dpn4_conv3"
  bottom: "dpn4_fc2/exc"
  top: "dpn4_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn4_conv3_Slice"
  type: "Slice"

  bottom: "dpn4_scale/se"
  top: "dpn4_conv3_split1"  # 0~255
  top: "dpn4_conv3_split2"  # 256~271

  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn4_elewise"
  type: "Eltwise"

  bottom: "dpn3_elewise"
  bottom: "dpn4_conv3_split1"
  top: "dpn4_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn4_concat"
  type: "Concat"

  bottom: "dpn3_concat"
  bottom: "dpn4_conv3_split2"
  top: "dpn4_concat"
}

###########################################################################################
#################### dpn5 ####################
###########################################################################################
layer {
  name: "dpn5_concat_input"
  type: "Concat"

  bottom: "dpn4_elewise"
  bottom: "dpn4_concat"
  top: "dpn5_concat_input"
}
layer {
  name: "dpn5_match_bn"
  type: "BatchNorm"

  bottom: "dpn5_concat_input"
  top: "dpn5_match_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_match_scale"
  type: "Scale"

  bottom: "dpn5_match_bn"
  top: "dpn5_match_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_match_relu"
  type: "ReLU"

  bottom: "dpn5_match_bn"
  top: "dpn5_match_bn"
}
layer {
  name: "dpn5_match_conv"
  type: "Convolution"

  bottom: "dpn5_match_bn"
  top: "dpn5_match_conv"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 576

    kernel_size: 1
    pad: 0
    stride: 2
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn5_match_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn5_match_conv"
  top: "dpn5_match_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End


layer {
  name: "dpn5_match_conv_Slice"
  type: "Slice"

  bottom: "dpn5_match_shuffle"
  top: "dpn5_match_conv_split1"  # 0~511
  top: "dpn5_match_conv_split2"  # 512~575

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn5_bn"
  type: "BatchNorm"

  bottom: "dpn5_concat_input"
  top: "dpn5_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_scale"
  type: "Scale"

  bottom: "dpn5_bn"
  top: "dpn5_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_relu"
  type: "ReLU"

  bottom: "dpn5_bn"
  top: "dpn5_bn"
}
layer {
  name: "dpn5_conv1"
  type: "Convolution"

  bottom: "dpn5_bn"
  top: "dpn5_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn5_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn5_conv1"
  top: "dpn5_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_conv1_scale"
  type: "Scale"

  bottom: "dpn5_conv1"
  top: "dpn5_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_conv1_relu"
  type: "ReLU"

  bottom: "dpn5_conv1"
  top: "dpn5_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn5_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn5_conv1"
  top: "dpn5_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn5_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn5_shuffle"
  top: "dpn5_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 2
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn5_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn5_conv2"
  top: "dpn5_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_conv2_scale"
  type: "Scale"

  bottom: "dpn5_conv2"
  top: "dpn5_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_conv2_relu"
  type: "ReLU"

  bottom: "dpn5_conv2"
  top: "dpn5_conv2"
}
layer {
  name: "dpn5_conv3"
  type: "Convolution"

  bottom: "dpn5_conv2"
  top: "dpn5_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn5_pool/gap"
  type: "Pooling"

  bottom: "dpn5_conv3"
  top: "dpn5_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn5_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn5_pool/gap"
  top: "dpn5_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn5_relu/sqz"
  type: "ReLU"

  bottom: "dpn5_fc1/sqz"
  top: "dpn5_fc1/sqz"
}
layer {
  name: "dpn5_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn5_fc1/sqz"
  top: "dpn5_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn5_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn5_fc2/exc"
  top: "dpn5_fc2/exc"
}
layer {
  name: "dpn5_scale/se"
  type: "Scale"

  bottom: "dpn5_conv3"
  bottom: "dpn5_fc2/exc"
  top: "dpn5_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn5_conv3_Slice"
  type: "Slice"

  bottom: "dpn5_scale/se"
  top: "dpn5_conv3_split1"  # 0~511
  top: "dpn5_conv3_split2"  # 511~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn5_elewise"
  type: "Eltwise"

  bottom: "dpn5_match_conv_split1"
  bottom: "dpn5_conv3_split1"

  top: "dpn5_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn5_concat"
  type: "Concat"

  bottom: "dpn5_match_conv_split2"
  bottom: "dpn5_conv3_split2"
  top: "dpn5_concat"
}
#################### dpn6 ####################
layer {
  name: "dpn6_concat_input"
  type: "Concat"

  bottom: "dpn5_elewise"
  bottom: "dpn5_concat"
  top: "dpn6_concat_input"
}
layer {
  name: "dpn6_bn"
  type: "BatchNorm"

  bottom: "dpn6_concat_input"
  top: "dpn6_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn6_scale"
  type: "Scale"

  bottom: "dpn6_bn"
  top: "dpn6_bn"

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn6_relu"
  type: "ReLU"

  bottom: "dpn6_bn"
  top: "dpn6_bn"
}
layer {
  name: "dpn6_conv1"
  type: "Convolution"

  bottom: "dpn6_bn"
  top: "dpn6_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn6_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn6_conv1"
  top: "dpn6_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn6_conv1_scale"
  type: "Scale"

  bottom: "dpn6_conv1"
  top: "dpn6_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn6_conv1_relu"
  type: "ReLU"

  bottom: "dpn6_conv1"
  top: "dpn6_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn6_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn6_conv1"
  top: "dpn6_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn6_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn6_shuffle"
  top: "dpn6_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn6_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn6_conv2"
  top: "dpn6_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn6_conv2_scale"
  type: "Scale"

  bottom: "dpn6_conv2"
  top: "dpn6_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn6_conv2_relu"
  type: "ReLU"

  bottom: "dpn6_conv2"
  top: "dpn6_conv2"
}
layer {
  name: "dpn6_conv3"
  type: "Convolution"

  bottom: "dpn6_conv2"
  top: "dpn6_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
	num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn6_pool/gap"
  type: "Pooling"

  bottom: "dpn6_conv3"
  top: "dpn6_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn6_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn6_pool/gap"
  top: "dpn6_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn6_relu/sqz"
  type: "ReLU"

  bottom: "dpn6_fc1/sqz"
  top: "dpn6_fc1/sqz"
}
layer {
  name: "dpn6_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn6_fc1/sqz"
  top: "dpn6_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn6_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn6_fc2/exc"
  top: "dpn6_fc2/exc"
}
layer {
  name: "dpn6_scale/se"
  type: "Scale"

  bottom: "dpn6_conv3"
  bottom: "dpn6_fc2/exc"
  top: "dpn6_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn6_conv3_Slice"
  type: "Slice"

  bottom: "dpn6_scale/se"
  top: "dpn6_conv3_split1"  # 0~511
  top: "dpn6_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn6_elewise"
  type: "Eltwise"

  bottom: "dpn5_elewise"
  bottom: "dpn6_conv3_split1"
  top: "dpn6_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn6_concat"
  type: "Concat"

  bottom: "dpn5_concat"
  bottom: "dpn6_conv3_split2"
  top: "dpn6_concat"
}
#################### dpn7 ####################
layer {
  name: "dpn7_concat_input"
  type: "Concat"

  bottom: "dpn6_elewise"
  bottom: "dpn6_concat"
  top: "dpn7_concat_input"
}
layer {
  name: "dpn7_bn"
  type: "BatchNorm"

  bottom: "dpn7_concat_input"
  top: "dpn7_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn7_scale"
  type: "Scale"

  bottom: "dpn7_bn"
  top: "dpn7_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn7_relu"
  type: "ReLU"

  bottom: "dpn7_bn"
  top: "dpn7_bn"
}
layer {
  name: "dpn7_conv1"
  type: "Convolution"

  bottom: "dpn7_bn"
  top: "dpn7_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn7_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn7_conv1"
  top: "dpn7_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn7_conv1_scale"
  type: "Scale"

  bottom: "dpn7_conv1"
  top: "dpn7_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn7_conv1_relu"
  type: "ReLU"

  bottom: "dpn7_conv1"
  top: "dpn7_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn7_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn7_conv1"
  top: "dpn7_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn7_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn7_shuffle"
  top: "dpn7_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn7_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn7_conv2"
  top: "dpn7_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn7_conv2_scale"
  type: "Scale"

  bottom: "dpn7_conv2"
  top: "dpn7_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 1.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn7_conv2_relu"
  type: "ReLU"

  bottom: "dpn7_conv2"
  top: "dpn7_conv2"
}
layer {
  name: "dpn7_conv3"
  type: "Convolution"

  bottom: "dpn7_conv2"
  top: "dpn7_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn7_pool/gap"
  type: "Pooling"

  bottom: "dpn7_conv3"
  top: "dpn7_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn7_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn7_pool/gap"
  top: "dpn7_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn7_relu/sqz"
  type: "ReLU"

  bottom: "dpn7_fc1/sqz"
  top: "dpn7_fc1/sqz"
}
layer {
  name: "dpn7_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn7_fc1/sqz"
  top: "dpn7_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn7_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn7_fc2/exc"
  top: "dpn7_fc2/exc"
}
layer {
  name: "dpn7_scale/se"
  type: "Scale"

  bottom: "dpn7_conv3"
  bottom: "dpn7_fc2/exc"
  top: "dpn7_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn7_conv3_Slice"
  type: "Slice"

  bottom: "dpn7_scale/se"
  top: "dpn7_conv3_split1"  # 0~511
  top: "dpn7_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn7_elewise"
  type: "Eltwise"

  bottom: "dpn6_elewise"
  bottom: "dpn7_conv3_split1"
  top: "dpn7_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn7_concat"
  type: "Concat"

  bottom: "dpn6_concat"
  bottom: "dpn7_conv3_split2"
  top: "dpn7_concat"
}
#################### dpn8 ####################
layer {
  name: "dpn8_concat_input"
  type: "Concat"

  bottom: "dpn7_elewise"
  bottom: "dpn7_concat"
  top: "dpn8_concat_input"
}
layer {
  name: "dpn8_bn"
  type: "BatchNorm"

  bottom: "dpn8_concat_input"
  top: "dpn8_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_scale"
  type: "Scale"

  bottom: "dpn8_bn"
  top: "dpn8_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_relu"
  type: "ReLU"

  bottom: "dpn8_bn"
  top: "dpn8_bn"
}
layer {
  name: "dpn8_conv1"
  type: "Convolution"

  bottom: "dpn8_bn"
  top: "dpn8_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn8_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn8_conv1"
  top: "dpn8_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_conv1_scale"
  type: "Scale"

  bottom: "dpn8_conv1"
  top: "dpn8_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_conv1_relu"
  type: "ReLU"

  bottom: "dpn8_conv1"
  top: "dpn8_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn8_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn8_conv1"
  top: "dpn8_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn8_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn8_shuffle"
  top: "dpn8_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn8_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn8_conv2"
  top: "dpn8_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_conv2_scale"
  type: "Scale"

  bottom: "dpn8_conv2"
  top: "dpn8_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_conv2_relu"
  type: "ReLU"

  bottom: "dpn8_conv2"
  top: "dpn8_conv2"
}
layer {
  name: "dpn8_conv3"
  type: "Convolution"

  bottom: "dpn8_conv2"
  top: "dpn8_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn8_pool/gap"
  type: "Pooling"

  bottom: "dpn8_conv3"
  top: "dpn8_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn8_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn8_pool/gap"
  top: "dpn8_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn8_relu/sqz"
  type: "ReLU"

  bottom: "dpn8_fc1/sqz"
  top: "dpn8_fc1/sqz"
}
layer {
  name: "dpn8_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn8_fc1/sqz"
  top: "dpn8_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn8_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn8_fc2/exc"
  top: "dpn8_fc2/exc"
}
layer {
  name: "dpn8_scale/se"
  type: "Scale"

  bottom: "dpn8_conv3"
  bottom: "dpn8_fc2/exc"
  top: "dpn8_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn8_conv3_Slice"
  type: "Slice"

  bottom: "dpn8_scale/se"
  top: "dpn8_conv3_split1"  # 0~511
  top: "dpn8_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn8_elewise"
  type: "Eltwise"

  bottom: "dpn7_elewise"
  bottom: "dpn8_conv3_split1"
  top: "dpn8_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn8_concat"
  type: "Concat"

  bottom: "dpn7_concat"
  bottom: "dpn8_conv3_split2"
  top: "dpn8_concat"
}
#################### dpn9 ####################
layer {
  name: "dpn9_concat_input"
  type: "Concat"

  bottom: "dpn8_elewise"
  bottom: "dpn8_concat"
  top: "dpn9_concat_input"
}
layer {
  name: "dpn9_bn"
  type: "BatchNorm"

  bottom: "dpn9_concat_input"
  top: "dpn9_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn9_scale"
  type: "Scale"

  bottom: "dpn9_bn"
  top: "dpn9_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn9_relu"
  type: "ReLU"

  bottom: "dpn9_bn"
  top: "dpn9_bn"
}
layer {
  name: "dpn9_conv1"
  type: "Convolution"

  bottom: "dpn9_bn"
  top: "dpn9_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn9_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn9_conv1"
  top: "dpn9_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn9_conv1_scale"
  type: "Scale"

  bottom: "dpn9_conv1"
  top: "dpn9_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn9_conv1_relu"
  type: "ReLU"

  bottom: "dpn9_conv1"
  top: "dpn9_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn9_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn9_conv1"
  top: "dpn9_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn9_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn9_shuffle"
  top: "dpn9_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn9_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn9_conv2"
  top: "dpn9_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn9_conv2_scale"
  type: "Scale"

  bottom: "dpn9_conv2"
  top: "dpn9_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn9_conv2_relu"
  type: "ReLU"

  bottom: "dpn9_conv2"
  top: "dpn9_conv2"
}
layer {
  name: "dpn9_conv3"
  type: "Convolution"

  bottom: "dpn9_conv2"
  top: "dpn9_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn9_pool/gap"
  type: "Pooling"

  bottom: "dpn9_conv3"
  top: "dpn9_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn9_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn9_pool/gap"
  top: "dpn9_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn9_relu/sqz"
  type: "ReLU"

  bottom: "dpn9_fc1/sqz"
  top: "dpn9_fc1/sqz"
}
layer {
  name: "dpn9_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn9_fc1/sqz"
  top: "dpn9_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn9_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn9_fc2/exc"
  top: "dpn9_fc2/exc"
}
layer {
  name: "dpn9_scale/se"
  type: "Scale"

  bottom: "dpn9_conv3"
  bottom: "dpn9_fc2/exc"
  top: "dpn9_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn9_conv3_Slice"
  type: "Slice"

  bottom: "dpn9_scale/se"
  top: "dpn9_conv3_split1"  # 0~511
  top: "dpn9_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn9_elewise"
  type: "Eltwise"

  bottom: "dpn8_elewise"
  bottom: "dpn9_conv3_split1"
  top: "dpn9_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn9_concat"
  type: "Concat"

  bottom: "dpn8_concat"
  bottom: "dpn9_conv3_split2"
  top: "dpn9_concat"
}
#################### dpn10 ####################
layer {
  name: "dpn10_concat_input"
  type: "Concat"

  bottom: "dpn9_elewise"
  bottom: "dpn9_concat"
  top: "dpn10_concat_input"
}
layer {
  name: "dpn10_bn"
  type: "BatchNorm"

  bottom: "dpn10_concat_input"
  top: "dpn10_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn10_scale"
  type: "Scale"

  bottom: "dpn10_bn"
  top: "dpn10_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn10_relu"
  type: "ReLU"

  bottom: "dpn10_bn"
  top: "dpn10_bn"
}
layer {
  name: "dpn10_conv1"
  type: "Convolution"

  bottom: "dpn10_bn"
  top: "dpn10_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn10_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn10_conv1"
  top: "dpn10_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn10_conv1_scale"
  type: "Scale"

  bottom: "dpn10_conv1"
  top: "dpn10_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn10_conv1_relu"
  type: "ReLU"

  bottom: "dpn10_conv1"
  top: "dpn10_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn10_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn10_conv1"
  top: "dpn10_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn10_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn10_shuffle"
  top: "dpn10_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn10_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn10_conv2"
  top: "dpn10_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn10_conv2_scale"
  type: "Scale"

  bottom: "dpn10_conv2"
  top: "dpn10_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn10_conv2_relu"
  type: "ReLU"

  bottom: "dpn10_conv2"
  top: "dpn10_conv2"
}
layer {
  name: "dpn10_conv3"
  type: "Convolution"

  bottom: "dpn10_conv2"
  top: "dpn10_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn10_pool/gap"
  type: "Pooling"

  bottom: "dpn10_conv3"
  top: "dpn10_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn10_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn10_pool/gap"
  top: "dpn10_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn10_relu/sqz"
  type: "ReLU"

  bottom: "dpn10_fc1/sqz"
  top: "dpn10_fc1/sqz"
}
layer {
  name: "dpn10_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn10_fc1/sqz"
  top: "dpn10_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn10_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn10_fc2/exc"
  top: "dpn10_fc2/exc"
}
layer {
  name: "dpn10_scale/se"
  type: "Scale"

  bottom: "dpn10_conv3"
  bottom: "dpn10_fc2/exc"
  top: "dpn10_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn10_conv3_Slice"
  type: "Slice"

  bottom: "dpn10_scale/se"
  top: "dpn10_conv3_split1"  # 0~511
  top: "dpn10_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn10_elewise"
  type: "Eltwise"

  bottom: "dpn9_elewise"
  bottom: "dpn10_conv3_split1"
  top: "dpn10_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn10_concat"
  type: "Concat"

  bottom: "dpn9_concat"
  bottom: "dpn10_conv3_split2"
  top: "dpn10_concat"
}
#################### dpn11 ####################
layer {
  name: "dpn11_concat_input"
  type: "Concat"

  bottom: "dpn10_elewise"
  bottom: "dpn10_concat"
  top: "dpn11_concat_input"
}
layer {
  name: "dpn11_bn"
  type: "BatchNorm"

  bottom: "dpn11_concat_input"
  top: "dpn11_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn11_scale"
  type: "Scale"

  bottom: "dpn11_bn"
  top: "dpn11_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn11_relu"
  type: "ReLU"

  bottom: "dpn11_bn"
  top: "dpn11_bn"
}
layer {
  name: "dpn11_conv1"
  type: "Convolution"

  bottom: "dpn11_bn"
  top: "dpn11_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn11_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn11_conv1"
  top: "dpn11_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn11_conv1_scale"
  type: "Scale"

  bottom: "dpn11_conv1"
  top: "dpn11_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn11_conv1_relu"
  type: "ReLU"

  bottom: "dpn11_conv1"
  top: "dpn11_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn11_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn11_conv1"
  top: "dpn11_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn11_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn11_shuffle"
  top: "dpn11_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn11_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn11_conv2"
  top: "dpn11_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn11_conv2_scale"
  type: "Scale"

  bottom: "dpn11_conv2"
  top: "dpn11_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn11_conv2_relu"
  type: "ReLU"

  bottom: "dpn11_conv2"
  top: "dpn11_conv2"
}
layer {
  name: "dpn11_conv3"
  type: "Convolution"

  bottom: "dpn11_conv2"
  top: "dpn11_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn11_pool/gap"
  type: "Pooling"

  bottom: "dpn11_conv3"
  top: "dpn11_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn11_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn11_pool/gap"
  top: "dpn11_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn11_relu/sqz"
  type: "ReLU"

  bottom: "dpn11_fc1/sqz"
  top: "dpn11_fc1/sqz"
}
layer {
  name: "dpn11_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn11_fc1/sqz"
  top: "dpn11_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn11_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn11_fc2/exc"
  top: "dpn11_fc2/exc"
}
layer {
  name: "dpn11_scale/se"
  type: "Scale"

  bottom: "dpn11_conv3"
  bottom: "dpn11_fc2/exc"
  top: "dpn11_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn11_conv3_Slice"
  type: "Slice"

  bottom: "dpn11_scale/se"
  top: "dpn11_conv3_split1"  # 0~511
  top: "dpn11_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn11_elewise"
  type: "Eltwise"

  bottom: "dpn10_elewise"
  bottom: "dpn11_conv3_split1"
  top: "dpn11_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn11_concat"
  type: "Concat"

  bottom: "dpn10_concat"
  bottom: "dpn11_conv3_split2"
  top: "dpn11_concat"
}
#################### dpn12 ####################
layer {
  name: "dpn12_concat_input"
  type: "Concat"

  bottom: "dpn11_elewise"
  bottom: "dpn11_concat"
  top: "dpn12_concat_input"
}
layer {
  name: "dpn12_bn"
  type: "BatchNorm"

  bottom: "dpn12_concat_input"
  top: "dpn12_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn12_scale"
  type: "Scale"

  bottom: "dpn12_bn"
  top: "dpn12_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn12_relu"
  type: "ReLU"

  bottom: "dpn12_bn"
  top: "dpn12_bn"
}
layer {
  name: "dpn12_conv1"
  type: "Convolution"

  bottom: "dpn12_bn"
  top: "dpn12_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn12_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn12_conv1"
  top: "dpn12_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn12_conv1_scale"
  type: "Scale"

  bottom: "dpn12_conv1"
  top: "dpn12_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn12_conv1_relu"
  type: "ReLU"

  bottom: "dpn12_conv1"
  top: "dpn12_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn12_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn12_conv1"
  top: "dpn12_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn12_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn12_shuffle"
  top: "dpn12_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 320

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn12_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn12_conv2"
  top: "dpn12_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn12_conv2_scale"
  type: "Scale"

  bottom: "dpn12_conv2"
  top: "dpn12_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn12_conv2_relu"
  type: "ReLU"

  bottom: "dpn12_conv2"
  top: "dpn12_conv2"
}
layer {
  name: "dpn12_conv3"
  type: "Convolution"

  bottom: "dpn12_conv2"
  top: "dpn12_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 544

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn12_pool/gap"
  type: "Pooling"

  bottom: "dpn12_conv3"
  top: "dpn12_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn12_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn12_pool/gap"
  top: "dpn12_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 34       # 544/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn12_relu/sqz"
  type: "ReLU"

  bottom: "dpn12_fc1/sqz"
  top: "dpn12_fc1/sqz"
}
layer {
  name: "dpn12_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn12_fc1/sqz"
  top: "dpn12_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 544

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn12_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn12_fc2/exc"
  top: "dpn12_fc2/exc"
}
layer {
  name: "dpn12_scale/se"
  type: "Scale"

  bottom: "dpn12_conv3"
  bottom: "dpn12_fc2/exc"
  top: "dpn12_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn12_conv3_Slice"
  type: "Slice"

  bottom: "dpn12_scale/se"
  top: "dpn12_conv3_split1"  # 0~511
  top: "dpn12_conv3_split2"  # 512~543

  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn12_elewise"
  type: "Eltwise"

  bottom: "dpn11_elewise"
  bottom: "dpn12_conv3_split1"
  top: "dpn12_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn12_concat"
  type: "Concat"

  bottom: "dpn11_concat"
  bottom: "dpn12_conv3_split2"
  top: "dpn12_concat"
}
####################################################################################################
#################### dpn13 ####################
####################################################################################################
layer {
  name: "dpn13_concat_input"
  type: "Concat"

  bottom: "dpn12_elewise"
  bottom: "dpn12_concat"
  top: "dpn13_concat_input"
}
layer {
  name: "dpn13_match_bn"
  type: "BatchNorm"

  bottom: "dpn13_concat_input"
  top: "dpn13_match_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_match_scale"
  type: "Scale"

  bottom: "dpn13_match_bn"
  top: "dpn13_match_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_match_relu"
  type: "ReLU"

  bottom: "dpn13_match_bn"
  top: "dpn13_match_bn"
}
layer {
  name: "dpn13_match_conv"
  type: "Convolution"

  bottom: "dpn13_match_bn"
  top: "dpn13_match_conv"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1088

    kernel_size: 1
    pad: 0
    stride: 2
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn13_match_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn13_match_conv"
  top: "dpn13_match_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End


layer {
  name: "dpn13_match_conv_Slice"
  type: "Slice"

  bottom: "dpn13_match_shuffle"
  top: "dpn13_match_conv_split1"  # 0~1023
  top: "dpn13_match_conv_split2"  # 1024~1087

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn13_bn"
  type: "BatchNorm"

  bottom: "dpn13_concat_input"
  top: "dpn13_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_scale"
  type: "Scale"

  bottom: "dpn13_bn"
  top: "dpn13_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_relu"
  type: "ReLU"

  bottom: "dpn13_bn"
  top: "dpn13_bn"
}
layer {
  name: "dpn13_conv1"
  type: "Convolution"

  bottom: "dpn13_bn"
  top: "dpn13_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn13_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn13_conv1"
  top: "dpn13_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_conv1_scale"
  type: "Scale"

  bottom: "dpn13_conv1"
  top: "dpn13_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_conv1_relu"
  type: "ReLU"

  bottom: "dpn13_conv1"
  top: "dpn13_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn13_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn13_conv1"
  top: "dpn13_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn13_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn13_shuffle"
  top: "dpn13_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 2
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn13_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn13_conv2"
  top: "dpn13_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_conv2_scale"
  type: "Scale"

  bottom: "dpn13_conv2"
  top: "dpn13_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_conv2_relu"
  type: "ReLU"

  bottom: "dpn13_conv2"
  top: "dpn13_conv2"
}
layer {
  name: "dpn13_conv3"
  type: "Convolution"

  bottom: "dpn13_conv2"
  top: "dpn13_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn13_pool/gap"
  type: "Pooling"

  bottom: "dpn13_conv3"
  top: "dpn13_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn13_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn13_pool/gap"
  top: "dpn13_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn13_relu/sqz"
  type: "ReLU"

  bottom: "dpn13_fc1/sqz"
  top: "dpn13_fc1/sqz"
}
layer {
  name: "dpn13_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn13_fc1/sqz"
  top: "dpn13_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn13_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn13_fc2/exc"
  top: "dpn13_fc2/exc"
}
layer {
  name: "dpn13_scale/se"
  type: "Scale"

  bottom: "dpn13_conv3"
  bottom: "dpn13_fc2/exc"
  top: "dpn13_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn13_conv3_Slice"
  type: "Slice"

  bottom: "dpn13_scale/se"
  top: "dpn13_conv3_split1"  # 0~1023
  top: "dpn13_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn13_elewise"
  type: "Eltwise"

  bottom: "dpn13_match_conv_split1"
  bottom: "dpn13_conv3_split1"
  top: "dpn13_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn13_concat"
  type: "Concat"

  bottom: "dpn13_match_conv_split2"
  bottom: "dpn13_conv3_split2"
  top: "dpn13_concat"
}
#################### dpn14 ####################
layer {
  name: "dpn14_concat_input"
  type: "Concat"

  bottom: "dpn13_elewise"
  bottom: "dpn13_concat"
  top: "dpn14_concat_input"
}
layer {
  name: "dpn14_bn"
  type: "BatchNorm"

  bottom: "dpn14_concat_input"
  top: "dpn14_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn14_scale"
  type: "Scale"

  bottom: "dpn14_bn"
  top: "dpn14_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn14_relu"
  type: "ReLU"

  bottom: "dpn14_bn"
  top: "dpn14_bn"
}
layer {
  name: "dpn14_conv1"
  type: "Convolution"

  bottom: "dpn14_bn"
  top: "dpn14_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn14_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn14_conv1"
  top: "dpn14_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn14_conv1_scale"
  type: "Scale"

  bottom: "dpn14_conv1"
  top: "dpn14_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn14_conv1_relu"
  type: "ReLU"

  bottom: "dpn14_conv1"
  top: "dpn14_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn14_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn14_conv1"
  top: "dpn14_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn14_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn14_shuffle"
  top: "dpn14_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn14_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn14_conv2"
  top: "dpn14_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn14_conv2_scale"
  type: "Scale"

  bottom: "dpn14_conv2"
  top: "dpn14_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn14_conv2_relu"
  type: "ReLU"

  bottom: "dpn14_conv2"
  top: "dpn14_conv2"
}
layer {
  name: "dpn14_conv3"
  type: "Convolution"

  bottom: "dpn14_conv2"
  top: "dpn14_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn14_pool/gap"
  type: "Pooling"

  bottom: "dpn14_conv3"
  top: "dpn14_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn14_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn14_pool/gap"
  top: "dpn14_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn14_relu/sqz"
  type: "ReLU"

  bottom: "dpn14_fc1/sqz"
  top: "dpn14_fc1/sqz"
}
layer {
  name: "dpn14_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn14_fc1/sqz"
  top: "dpn14_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn14_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn14_fc2/exc"
  top: "dpn14_fc2/exc"
}
layer {
  name: "dpn14_scale/se"
  type: "Scale"

  bottom: "dpn14_conv3"
  bottom: "dpn14_fc2/exc"
  top: "dpn14_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn14_conv3_Slice"
  type: "Slice"

  bottom: "dpn14_scale/se"
  top: "dpn14_conv3_split1"  # 0~1023
  top: "dpn14_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn14_elewise"
  type: "Eltwise"

  bottom: "dpn13_elewise"
  bottom: "dpn14_conv3_split1"
  top: "dpn14_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn14_concat"
  type: "Concat"

  bottom: "dpn13_concat"
  bottom: "dpn14_conv3_split2"
  top: "dpn14_concat"
}
#################### dpn15 ####################
layer {
  name: "dpn15_concat_input"
  type: "Concat"

  bottom: "dpn14_elewise"
  bottom: "dpn14_concat"
  top: "dpn15_concat_input"
}
layer {
  name: "dpn15_bn"
  type: "BatchNorm"

  bottom: "dpn15_concat_input"
  top: "dpn15_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn15_scale"
  type: "Scale"

  bottom: "dpn15_bn"
  top: "dpn15_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn15_relu"
  type: "ReLU"

  bottom: "dpn15_bn"
  top: "dpn15_bn"
}
layer {
  name: "dpn15_conv1"
  type: "Convolution"

  bottom: "dpn15_bn"
  top: "dpn15_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn15_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn15_conv1"
  top: "dpn15_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn15_conv1_scale"
  type: "Scale"

  bottom: "dpn15_conv1"
  top: "dpn15_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn15_conv1_relu"
  type: "ReLU"

  bottom: "dpn15_conv1"
  top: "dpn15_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn15_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn15_conv1"
  top: "dpn15_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn15_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn15_shuffle"
  top: "dpn15_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn15_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn15_conv2"
  top: "dpn15_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn15_conv2_scale"
  type: "Scale"

  bottom: "dpn15_conv2"
  top: "dpn15_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn15_conv2_relu"
  type: "ReLU"

  bottom: "dpn15_conv2"
  top: "dpn15_conv2"
}
layer {
  name: "dpn15_conv3"
  type: "Convolution"

  bottom: "dpn15_conv2"
  top: "dpn15_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn15_pool/gap"
  type: "Pooling"

  bottom: "dpn15_conv3"
  top: "dpn15_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn15_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn15_pool/gap"
  top: "dpn15_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn15_relu/sqz"
  type: "ReLU"

  bottom: "dpn15_fc1/sqz"
  top: "dpn15_fc1/sqz"
}
layer {
  name: "dpn15_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn15_fc1/sqz"
  top: "dpn15_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn15_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn15_fc2/exc"
  top: "dpn15_fc2/exc"
}
layer {
  name: "dpn15_scale/se"
  type: "Scale"

  bottom: "dpn15_conv3"
  bottom: "dpn15_fc2/exc"
  top: "dpn15_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn15_conv3_Slice"
  type: "Slice"

  bottom: "dpn15_scale/se"
  top: "dpn15_conv3_split1"  # 0~1023
  top: "dpn15_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn15_elewise"
  type: "Eltwise"

  bottom: "dpn14_elewise"
  bottom: "dpn15_conv3_split1"
  top: "dpn15_elewise"

  eltwise_param {
   operation: SUM
  }
}
layer {
  name: "dpn15_concat"
  type: "Concat"

  bottom: "dpn14_concat"
  bottom: "dpn15_conv3_split2"
  top: "dpn15_concat"
}
#################### dpn16 ####################
layer {
  name: "dpn16_concat_input"
  type: "Concat"

  bottom: "dpn15_elewise"
  bottom: "dpn15_concat"
  top: "dpn16_concat_input"
}
layer {
  name: "dpn16_bn"
  type: "BatchNorm"

  bottom: "dpn16_concat_input"
  top: "dpn16_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn16_scale"
  type: "Scale"

  bottom: "dpn16_bn"
  top: "dpn16_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn16_relu"
  type: "ReLU"

  bottom: "dpn16_bn"
  top: "dpn16_bn"
}
layer {
  name: "dpn16_conv1"
  type: "Convolution"

  bottom: "dpn16_bn"
  top: "dpn16_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn16_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn16_conv1"
  top: "dpn16_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn16_conv1_scale"
  type: "Scale"

  bottom: "dpn16_conv1"
  top: "dpn16_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn16_conv1_relu"
  type: "ReLU"

  bottom: "dpn16_conv1"
  top: "dpn16_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn16_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn16_conv1"
  top: "dpn16_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn16_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn16_shuffle"
  top: "dpn16_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn16_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn16_conv2"
  top: "dpn16_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn16_conv2_scale"
  type: "Scale"

  bottom: "dpn16_conv2"
  top: "dpn16_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn16_conv2_relu"
  type: "ReLU"

  bottom: "dpn16_conv2"
  top: "dpn16_conv2"
}
layer {
  name: "dpn16_conv3"
  type: "Convolution"

  bottom: "dpn16_conv2"
  top: "dpn16_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn16_pool/gap"
  type: "Pooling"

  bottom: "dpn16_conv3"
  top: "dpn16_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn16_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn16_pool/gap"
  top: "dpn16_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn16_relu/sqz"
  type: "ReLU"

  bottom: "dpn16_fc1/sqz"
  top: "dpn16_fc1/sqz"
}
layer {
  name: "dpn16_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn16_fc1/sqz"
  top: "dpn16_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn16_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn16_fc2/exc"
  top: "dpn16_fc2/exc"
}
layer {
  name: "dpn16_scale/se"
  type: "Scale"

  bottom: "dpn16_conv3"
  bottom: "dpn16_fc2/exc"
  top: "dpn16_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn16_conv3_Slice"
  type: "Slice"

  bottom: "dpn16_scale/se"
  top: "dpn16_conv3_split1"  # 0~1023
  top: "dpn16_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn16_elewise"
  type: "Eltwise"

  bottom: "dpn15_elewise"
  bottom: "dpn16_conv3_split1"
  top: "dpn16_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn16_concat"
  type: "Concat"

  bottom: "dpn15_concat"
  bottom: "dpn16_conv3_split2"
  top: "dpn16_concat"
}
#################### dpn17 ####################
layer {
  name: "dpn17_concat_input"
  type: "Concat"

  bottom: "dpn16_elewise"
  bottom: "dpn16_concat"
  top: "dpn17_concat_input"
}
layer {
  name: "dpn17_bn"
  type: "BatchNorm"

  bottom: "dpn17_concat_input"
  top: "dpn17_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn17_scale"
  type: "Scale"

  bottom: "dpn17_bn"
  top: "dpn17_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn17_relu"
  type: "ReLU"

  bottom: "dpn17_bn"
  top: "dpn17_bn"
}
layer {
  name: "dpn17_conv1"
  type: "Convolution"

  bottom: "dpn17_bn"
  top: "dpn17_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn17_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn17_conv1"
  top: "dpn17_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn17_conv1_scale"
  type: "Scale"

  bottom: "dpn17_conv1"
  top: "dpn17_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn17_conv1_relu"
  type: "ReLU"

  bottom: "dpn17_conv1"
  top: "dpn17_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn17_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn17_conv1"
  top: "dpn17_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn17_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn17_shuffle"
  top: "dpn17_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn17_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn17_conv2"
  top: "dpn17_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn17_conv2_scale"
  type: "Scale"

  bottom: "dpn17_conv2"
  top: "dpn17_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn17_conv2_relu"
  type: "ReLU"

  bottom: "dpn17_conv2"
  top: "dpn17_conv2"
}
layer {
  name: "dpn17_conv3"
  type: "Convolution"

  bottom: "dpn17_conv2"
  top: "dpn17_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn17_pool/gap"
  type: "Pooling"

  bottom: "dpn17_conv3"
  top: "dpn17_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn17_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn17_pool/gap"
  top: "dpn17_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn17_relu/sqz"
  type: "ReLU"

  bottom: "dpn17_fc1/sqz"
  top: "dpn17_fc1/sqz"
}
layer {
  name: "dpn17_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn17_fc1/sqz"
  top: "dpn17_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn17_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn17_fc2/exc"
  top: "dpn17_fc2/exc"
}
layer {
  name: "dpn17_scale/se"
  type: "Scale"

  bottom: "dpn17_conv3"
  bottom: "dpn17_fc2/exc"
  top: "dpn17_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn17_conv3_Slice"
  type: "Slice"

  bottom: "dpn17_scale/se"
  top: "dpn17_conv3_split1"  # 0~1023
  top: "dpn17_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn17_elewise"
  type: "Eltwise"

  bottom: "dpn16_elewise"
  bottom: "dpn17_conv3_split1"
  top: "dpn17_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn17_concat"
  type: "Concat"

  bottom: "dpn16_concat"
  bottom: "dpn17_conv3_split2"
  top: "dpn17_concat"
}
#################### dpn18 ####################
layer {
  name: "dpn18_concat_input"
  type: "Concat"

  bottom: "dpn17_elewise"
  bottom: "dpn17_concat"
  top: "dpn18_concat_input"
}
layer {
  name: "dpn18_bn"
  type: "BatchNorm"

  bottom: "dpn18_concat_input"
  top: "dpn18_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn18_scale"
  type: "Scale"

  bottom: "dpn18_bn"
  top: "dpn18_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn18_relu"
  type: "ReLU"

  bottom: "dpn18_bn"
  top: "dpn18_bn"
}
layer {
  name: "dpn18_conv1"
  type: "Convolution"

  bottom: "dpn18_bn"
  top: "dpn18_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn18_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn18_conv1"
  top: "dpn18_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn18_conv1_scale"
  type: "Scale"

  bottom: "dpn18_conv1"
  top: "dpn18_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn18_conv1_relu"
  type: "ReLU"

  bottom: "dpn18_conv1"
  top: "dpn18_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn18_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn18_conv1"
  top: "dpn18_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn18_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn18_shuffle"
  top: "dpn18_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn18_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn18_conv2"
  top: "dpn18_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn18_conv2_scale"
  type: "Scale"

  bottom: "dpn18_conv2"
  top: "dpn18_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn18_conv2_relu"
  type: "ReLU"

  bottom: "dpn18_conv2"
  top: "dpn18_conv2"
}
layer {
  name: "dpn18_conv3"
  type: "Convolution"

  bottom: "dpn18_conv2"
  top: "dpn18_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn18_pool/gap"
  type: "Pooling"

  bottom: "dpn18_conv3"
  top: "dpn18_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn18_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn18_pool/gap"
  top: "dpn18_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn18_relu/sqz"
  type: "ReLU"

  bottom: "dpn18_fc1/sqz"
  top: "dpn18_fc1/sqz"
}
layer {
  name: "dpn18_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn18_fc1/sqz"
  top: "dpn18_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn18_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn18_fc2/exc"
  top: "dpn18_fc2/exc"
}
layer {
  name: "dpn18_scale/se"
  type: "Scale"

  bottom: "dpn18_conv3"
  bottom: "dpn18_fc2/exc"
  top: "dpn18_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn18_conv3_Slice"
  type: "Slice"

  bottom: "dpn18_scale/se"
  top: "dpn18_conv3_split1"  # 0~1023
  top: "dpn18_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn18_elewise"
  type: "Eltwise"

  bottom: "dpn17_elewise"
  bottom: "dpn18_conv3_split1"
  top: "dpn18_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn18_concat"
  type: "Concat"

  bottom: "dpn17_concat"
  bottom: "dpn18_conv3_split2"
  top: "dpn18_concat"
}
#################### dpn19 ####################
layer {
  name: "dpn19_concat_input"
  type: "Concat"

  bottom: "dpn18_elewise"
  bottom: "dpn18_concat"
  top: "dpn19_concat_input"
}
layer {
  name: "dpn19_bn"
  type: "BatchNorm"

  bottom: "dpn19_concat_input"
  top: "dpn19_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn19_scale"
  type: "Scale"

  bottom: "dpn19_bn"
  top: "dpn19_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn19_relu"
  type: "ReLU"

  bottom: "dpn19_bn"
  top: "dpn19_bn"
}
layer {
  name: "dpn19_conv1"
  type: "Convolution"

  bottom: "dpn19_bn"
  top: "dpn19_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn19_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn19_conv1"
  top: "dpn19_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn19_conv1_scale"
  type: "Scale"

  bottom: "dpn19_conv1"
  top: "dpn19_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn19_conv1_relu"
  type: "ReLU"

  bottom: "dpn19_conv1"
  top: "dpn19_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn19_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn19_conv1"
  top: "dpn19_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn19_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn19_shuffle"
  top: "dpn19_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn19_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn19_conv2"
  top: "dpn19_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn19_conv2_scale"
  type: "Scale"

  bottom: "dpn19_conv2"
  top: "dpn19_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn19_conv2_relu"
  type: "ReLU"

  bottom: "dpn19_conv2"
  top: "dpn19_conv2"
}
layer {
  name: "dpn19_conv3"
  type: "Convolution"

  bottom: "dpn19_conv2"
  top: "dpn19_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn19_pool/gap"
  type: "Pooling"

  bottom: "dpn19_conv3"
  top: "dpn19_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn19_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn19_pool/gap"
  top: "dpn19_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn19_relu/sqz"
  type: "ReLU"

  bottom: "dpn19_fc1/sqz"
  top: "dpn19_fc1/sqz"
}
layer {
  name: "dpn19_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn19_fc1/sqz"
  top: "dpn19_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn19_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn19_fc2/exc"
  top: "dpn19_fc2/exc"
}
layer {
  name: "dpn19_scale/se"
  type: "Scale"

  bottom: "dpn19_conv3"
  bottom: "dpn19_fc2/exc"
  top: "dpn19_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn19_conv3_Slice"
  type: "Slice"

  bottom: "dpn19_scale/se"
  top: "dpn19_conv3_split1"  # 0~1023
  top: "dpn19_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn19_elewise"
  type: "Eltwise"

  bottom: "dpn18_elewise"
  bottom: "dpn19_conv3_split1"
  top: "dpn19_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn19_concat"
  type: "Concat"

  bottom: "dpn18_concat"
  bottom: "dpn19_conv3_split2"
  top: "dpn19_concat"
}
#################### dpn20 ####################
layer {
  name: "dpn20_concat_input"
  type: "Concat"

  bottom: "dpn19_elewise"
  bottom: "dpn19_concat"
  top: "dpn20_concat_input"
}
layer {
  name: "dpn20_bn"
  type: "BatchNorm"

  bottom: "dpn20_concat_input"
  top: "dpn20_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn20_scale"
  type: "Scale"

  bottom: "dpn20_bn"
  top: "dpn20_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn20_relu"
  type: "ReLU"

  bottom: "dpn20_bn"
  top: "dpn20_bn"
}
layer {
  name: "dpn20_conv1"
  type: "Convolution"

  bottom: "dpn20_bn"
  top: "dpn20_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn20_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn20_conv1"
  top: "dpn20_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn20_conv1_scale"
  type: "Scale"

  bottom: "dpn20_conv1"
  top: "dpn20_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn20_conv1_relu"
  type: "ReLU"

  bottom: "dpn20_conv1"
  top: "dpn20_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn20_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn20_conv1"
  top: "dpn20_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn20_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn20_shuffle"
  top: "dpn20_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn20_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn20_conv2"
  top: "dpn20_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn20_conv2_scale"
  type: "Scale"

  bottom: "dpn20_conv2"
  top: "dpn20_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn20_conv2_relu"
  type: "ReLU"

  bottom: "dpn20_conv2"
  top: "dpn20_conv2"
}
layer {
  name: "dpn20_conv3"
  type: "Convolution"

  bottom: "dpn20_conv2"
  top: "dpn20_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn20_pool/gap"
  type: "Pooling"

  bottom: "dpn20_conv3"
  top: "dpn20_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn20_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn20_pool/gap"
  top: "dpn20_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn20_relu/sqz"
  type: "ReLU"

  bottom: "dpn20_fc1/sqz"
  top: "dpn20_fc1/sqz"
}
layer {
  name: "dpn20_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn20_fc1/sqz"
  top: "dpn20_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn20_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn20_fc2/exc"
  top: "dpn20_fc2/exc"
}
layer {
  name: "dpn20_scale/se"
  type: "Scale"

  bottom: "dpn20_conv3"
  bottom: "dpn20_fc2/exc"
  top: "dpn20_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn20_conv3_Slice"
  type: "Slice"

  bottom: "dpn20_scale/se"
  top: "dpn20_conv3_split1"  # 0~1023
  top: "dpn20_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn20_elewise"
  type: "Eltwise"

  bottom: "dpn19_elewise"
  bottom: "dpn20_conv3_split1"
  top: "dpn20_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn20_concat"
  type: "Concat"

  bottom: "dpn19_concat"
  bottom: "dpn20_conv3_split2"
  top: "dpn20_concat"
}
#################### dpn21 ####################
layer {
  name: "dpn21_concat_input"
  type: "Concat"

  bottom: "dpn20_elewise"
  bottom: "dpn20_concat"
  top: "dpn21_concat_input"
}
layer {
  name: "dpn21_bn"
  type: "BatchNorm"

  bottom: "dpn21_concat_input"
  top: "dpn21_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn21_scale"
  type: "Scale"

  bottom: "dpn21_bn"
  top: "dpn21_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn21_relu"
  type: "ReLU"

  bottom: "dpn21_bn"
  top: "dpn21_bn"
}
layer {
  name: "dpn21_conv1"
  type: "Convolution"

  bottom: "dpn21_bn"
  top: "dpn21_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn21_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn21_conv1"
  top: "dpn21_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn21_conv1_scale"
  type: "Scale"

  bottom: "dpn21_conv1"
  top: "dpn21_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn21_conv1_relu"
  type: "ReLU"

  bottom: "dpn21_conv1"
  top: "dpn21_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn21_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn21_conv1"
  top: "dpn21_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn21_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn21_shuffle"
  top: "dpn21_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn21_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn21_conv2"
  top: "dpn21_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn21_conv2_scale"
  type: "Scale"

  bottom: "dpn21_conv2"
  top: "dpn21_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn21_conv2_relu"
  type: "ReLU"

  bottom: "dpn21_conv2"
  top: "dpn21_conv2"
}
layer {
  name: "dpn21_conv3"
  type: "Convolution"

  bottom: "dpn21_conv2"
  top: "dpn21_conv3"


  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn21_pool/gap"
  type: "Pooling"

  bottom: "dpn21_conv3"
  top: "dpn21_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn21_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn21_pool/gap"
  top: "dpn21_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn21_relu/sqz"
  type: "ReLU"

  bottom: "dpn21_fc1/sqz"
  top: "dpn21_fc1/sqz"
}
layer {
  name: "dpn21_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn21_fc1/sqz"
  top: "dpn21_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn21_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn21_fc2/exc"
  top: "dpn21_fc2/exc"
}
layer {
  name: "dpn21_scale/se"
  type: "Scale"

  bottom: "dpn21_conv3"
  bottom: "dpn21_fc2/exc"
  top: "dpn21_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn21_conv3_Slice"
  type: "Slice"

  bottom: "dpn21_scale/se"
  top: "dpn21_conv3_split1"  # 0~1023
  top: "dpn21_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn21_elewise"
  type: "Eltwise"

  bottom: "dpn20_elewise"
  bottom: "dpn21_conv3_split1"
  top: "dpn21_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn21_concat"
  type: "Concat"

  bottom: "dpn20_concat"
  bottom: "dpn21_conv3_split2"
  top: "dpn21_concat"
}
#################### dpn22 ####################
layer {
  name: "dpn22_concat_input"
  type: "Concat"

  bottom: "dpn21_elewise"
  bottom: "dpn21_concat"
  top: "dpn22_concat_input"
}
layer {
  name: "dpn22_bn"
  type: "BatchNorm"

  bottom: "dpn22_concat_input"
  top: "dpn22_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn22_scale"
  type: "Scale"

  bottom: "dpn22_bn"
  top: "dpn22_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn22_relu"
  type: "ReLU"

  bottom: "dpn22_bn"
  top: "dpn22_bn"
}
layer {
  name: "dpn22_conv1"
  type: "Convolution"

  bottom: "dpn22_bn"
  top: "dpn22_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn22_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn22_conv1"
  top: "dpn22_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn22_conv1_scale"
  type: "Scale"

  bottom: "dpn22_conv1"
  top: "dpn22_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn22_conv1_relu"
  type: "ReLU"

  bottom: "dpn22_conv1"
  top: "dpn22_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn22_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn22_conv1"
  top: "dpn22_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn22_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn22_shuffle"
  top: "dpn22_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn22_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn22_conv2"
  top: "dpn22_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn22_conv2_scale"
  type: "Scale"

  bottom: "dpn22_conv2"
  top: "dpn22_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn22_conv2_relu"
  type: "ReLU"

  bottom: "dpn22_conv2"
  top: "dpn22_conv2"
}
layer {
  name: "dpn22_conv3"
  type: "Convolution"

  bottom: "dpn22_conv2"
  top: "dpn22_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# -------------------- SE Block Start
layer {
  name: "dpn22_pool/gap"
  type: "Pooling"

  bottom: "dpn22_conv3"
  top: "dpn22_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn22_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn22_pool/gap"
  top: "dpn22_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn22_relu/sqz"
  type: "ReLU"

  bottom: "dpn22_fc1/sqz"
  top: "dpn22_fc1/sqz"
}
layer {
  name: "dpn22_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn22_fc1/sqz"
  top: "dpn22_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn22_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn22_fc2/exc"
  top: "dpn22_fc2/exc"
}
layer {
  name: "dpn22_scale/se"
  type: "Scale"

  bottom: "dpn22_conv3"
  bottom: "dpn22_fc2/exc"
  top: "dpn22_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn22_conv3_Slice"
  type: "Slice"

  bottom: "dpn22_scale/se"
  top: "dpn22_conv3_split1"  # 0~1023
  top: "dpn22_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn22_elewise"
  type: "Eltwise"

  bottom: "dpn21_elewise"
  bottom: "dpn22_conv3_split1"
  top: "dpn22_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn22_concat"
  type: "Concat"

  bottom: "dpn21_concat"
  bottom: "dpn22_conv3_split2"
  top: "dpn22_concat"
}
#################### dpn23 ####################
layer {
  name: "dpn23_concat_input"
  type: "Concat"

  bottom: "dpn22_elewise"
  bottom: "dpn22_concat"
  top: "dpn23_concat_input"
}
layer {
  name: "dpn23_bn"
  type: "BatchNorm"

  bottom: "dpn23_concat_input"
  top: "dpn23_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn23_scale"
  type: "Scale"

  bottom: "dpn23_bn"
  top: "dpn23_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn23_relu"
  type: "ReLU"

  bottom: "dpn23_bn"
  top: "dpn23_bn"
}
layer {
  name: "dpn23_conv1"
  type: "Convolution"

  bottom: "dpn23_bn"
  top: "dpn23_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn23_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn23_conv1"
  top: "dpn23_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn23_conv1_scale"
  type: "Scale"

  bottom: "dpn23_conv1"
  top: "dpn23_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn23_conv1_relu"
  type: "ReLU"

  bottom: "dpn23_conv1"
  top: "dpn23_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn23_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn23_conv1"
  top: "dpn23_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn23_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn23_shuffle"
  top: "dpn23_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn23_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn23_conv2"
  top: "dpn23_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn23_conv2_scale"
  type: "Scale"

  bottom: "dpn23_conv2"
  top: "dpn23_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn23_conv2_relu"
  type: "ReLU"

  bottom: "dpn23_conv2"
  top: "dpn23_conv2"
}
layer {
  name: "dpn23_conv3"
  type: "Convolution"

  bottom: "dpn23_conv2"
  top: "dpn23_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn23_pool/gap"
  type: "Pooling"

  bottom: "dpn23_conv3"
  top: "dpn23_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn23_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn23_pool/gap"
  top: "dpn23_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn23_relu/sqz"
  type: "ReLU"

  bottom: "dpn23_fc1/sqz"
  top: "dpn23_fc1/sqz"
}
layer {
  name: "dpn23_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn23_fc1/sqz"
  top: "dpn23_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn23_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn23_fc2/exc"
  top: "dpn23_fc2/exc"
}
layer {
  name: "dpn23_scale/se"
  type: "Scale"

  bottom: "dpn23_conv3"
  bottom: "dpn23_fc2/exc"
  top: "dpn23_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn23_conv3_Slice"
  type: "Slice"

  bottom: "dpn23_scale/se"
  top: "dpn23_conv3_split1"  # 0~1023
  top: "dpn23_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn23_elewise"
  type: "Eltwise"

  bottom: "dpn22_elewise"
  bottom: "dpn23_conv3_split1"
  top: "dpn23_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn23_concat"
  type: "Concat"

  bottom: "dpn22_concat"
  bottom: "dpn23_conv3_split2"
  top: "dpn23_concat"
}
#################### dpn24 ####################
layer {
  name: "dpn24_concat_input"
  type: "Concat"

  bottom: "dpn23_elewise"
  bottom: "dpn23_concat"
  top: "dpn24_concat_input"
}
layer {
  name: "dpn24_bn"
  type: "BatchNorm"

  bottom: "dpn24_concat_input"
  top: "dpn24_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn24_scale"
  type: "Scale"

  bottom: "dpn24_bn"
  top: "dpn24_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn24_relu"
  type: "ReLU"

  bottom: "dpn24_bn"
  top: "dpn24_bn"
}
layer {
  name: "dpn24_conv1"
  type: "Convolution"

  bottom: "dpn24_bn"
  top: "dpn24_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn24_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn24_conv1"
  top: "dpn24_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn24_conv1_scale"
  type: "Scale"

  bottom: "dpn24_conv1"
  top: "dpn24_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn24_conv1_relu"
  type: "ReLU"

  bottom: "dpn24_conv1"
  top: "dpn24_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn24_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn24_conv1"
  top: "dpn24_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn24_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn24_shuffle"
  top: "dpn24_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn24_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn24_conv2"
  top: "dpn24_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn24_conv2_scale"
  type: "Scale"

  bottom: "dpn24_conv2"
  top: "dpn24_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn24_conv2_relu"
  type: "ReLU"

  bottom: "dpn24_conv2"
  top: "dpn24_conv2"
}
layer {
  name: "dpn24_conv3"
  type: "Convolution"

  bottom: "dpn24_conv2"
  top: "dpn24_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn24_pool/gap"
  type: "Pooling"

  bottom: "dpn24_conv3"
  top: "dpn24_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn24_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn24_pool/gap"
  top: "dpn24_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn24_relu/sqz"
  type: "ReLU"

  bottom: "dpn24_fc1/sqz"
  top: "dpn24_fc1/sqz"
}
layer {
  name: "dpn24_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn24_fc1/sqz"
  top: "dpn24_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn24_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn24_fc2/exc"
  top: "dpn24_fc2/exc"
}
layer {
  name: "dpn24_scale/se"
  type: "Scale"

  bottom: "dpn24_conv3"
  bottom: "dpn24_fc2/exc"
  top: "dpn24_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn24_conv3_Slice"
  type: "Slice"

  bottom: "dpn24_scale/se"
  top: "dpn24_conv3_split1"  # 0~1023
  top: "dpn24_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn24_elewise"
  type: "Eltwise"

  bottom: "dpn23_elewise"
  bottom: "dpn24_conv3_split1"
  top: "dpn24_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn24_concat"
  type: "Concat"

  bottom: "dpn23_concat"
  bottom: "dpn24_conv3_split2"
  top: "dpn24_concat"
}
#################### dpn25 ####################
layer {
  name: "dpn25_concat_input"
  type: "Concat"

  bottom: "dpn24_elewise"
  bottom: "dpn24_concat"
  top: "dpn25_concat_input"
}
layer {
  name: "dpn25_bn"
  type: "BatchNorm"

  bottom: "dpn25_concat_input"
  top: "dpn25_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn25_scale"
  type: "Scale"

  bottom: "dpn25_bn"
  top: "dpn25_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn25_relu"
  type: "ReLU"

  bottom: "dpn25_bn"
  top: "dpn25_bn"
}
layer {
  name: "dpn25_conv1"
  type: "Convolution"

  bottom: "dpn25_bn"
  top: "dpn25_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn25_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn25_conv1"
  top: "dpn25_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn25_conv1_scale"
  type: "Scale"

  bottom: "dpn25_conv1"
  top: "dpn25_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn25_conv1_relu"
  type: "ReLU"

  bottom: "dpn25_conv1"
  top: "dpn25_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn25_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn25_conv1"
  top: "dpn25_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn25_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn25_shuffle"
  top: "dpn25_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn25_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn25_conv2"
  top: "dpn25_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn25_conv2_scale"
  type: "Scale"

  bottom: "dpn25_conv2"
  top: "dpn25_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn25_conv2_relu"
  type: "ReLU"

  bottom: "dpn25_conv2"
  top: "dpn25_conv2"
}
layer {
  name: "dpn25_conv3"
  type: "Convolution"

  bottom: "dpn25_conv2"
  top: "dpn25_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn25_pool/gap"
  type: "Pooling"

  bottom: "dpn25_conv3"
  top: "dpn25_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn25_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn25_pool/gap"
  top: "dpn25_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn25_relu/sqz"
  type: "ReLU"

  bottom: "dpn25_fc1/sqz"
  top: "dpn25_fc1/sqz"
}
layer {
  name: "dpn25_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn25_fc1/sqz"
  top: "dpn25_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn25_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn25_fc2/exc"
  top: "dpn25_fc2/exc"
}
layer {
  name: "dpn25_scale/se"
  type: "Scale"

  bottom: "dpn25_conv3"
  bottom: "dpn25_fc2/exc"
  top: "dpn25_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn25_conv3_Slice"
  type: "Slice"

  bottom: "dpn25_scale/se"
  top: "dpn25_conv3_split1"  # 0~1023
  top: "dpn25_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn25_elewise"
  type: "Eltwise"

  bottom: "dpn24_elewise"
  bottom: "dpn25_conv3_split1"
  top: "dpn25_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn25_concat"
  type: "Concat"

  bottom: "dpn24_concat"
  bottom: "dpn25_conv3_split2"
  top: "dpn25_concat"
}
#################### dpn26 ####################
layer {
  name: "dpn26_concat_input"
  type: "Concat"

  bottom: "dpn25_elewise"
  bottom: "dpn25_concat"
  top: "dpn26_concat_input"
}
layer {
  name: "dpn26_bn"
  type: "BatchNorm"

  bottom: "dpn26_concat_input"
  top: "dpn26_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn26_scale"
  type: "Scale"

  bottom: "dpn26_bn"
  top: "dpn26_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn26_relu"
  type: "ReLU"

  bottom: "dpn26_bn"
  top: "dpn26_bn"
}
layer {
  name: "dpn26_conv1"
  type: "Convolution"

  bottom: "dpn26_bn"
  top: "dpn26_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }


  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn26_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn26_conv1"
  top: "dpn26_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn26_conv1_scale"
  type: "Scale"

  bottom: "dpn26_conv1"
  top: "dpn26_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn26_conv1_relu"
  type: "ReLU"

  bottom: "dpn26_conv1"
  top: "dpn26_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn26_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn26_conv1"
  top: "dpn26_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn26_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn26_shuffle"
  top: "dpn26_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn26_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn26_conv2"
  top: "dpn26_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn26_conv2_scale"
  type: "Scale"

  bottom: "dpn26_conv2"
  top: "dpn26_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn26_conv2_relu"
  type: "ReLU"

  bottom: "dpn26_conv2"
  top: "dpn26_conv2"
}
layer {
  name: "dpn26_conv3"
  type: "Convolution"

  bottom: "dpn26_conv2"
  top: "dpn26_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn26_pool/gap"
  type: "Pooling"

  bottom: "dpn26_conv3"
  top: "dpn26_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn26_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn26_pool/gap"
  top: "dpn26_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn26_relu/sqz"
  type: "ReLU"

  bottom: "dpn26_fc1/sqz"
  top: "dpn26_fc1/sqz"
}
layer {
  name: "dpn26_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn26_fc1/sqz"
  top: "dpn26_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn26_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn26_fc2/exc"
  top: "dpn26_fc2/exc"
}
layer {
  name: "dpn26_scale/se"
  type: "Scale"

  bottom: "dpn26_conv3"
  bottom: "dpn26_fc2/exc"
  top: "dpn26_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn26_conv3_Slice"
  type: "Slice"

  bottom: "dpn26_scale/se"
  top: "dpn26_conv3_split1"  # 0~1023
  top: "dpn26_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn26_elewise"
  type: "Eltwise"

  bottom: "dpn25_elewise"
  bottom: "dpn26_conv3_split1"
  top: "dpn26_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn26_concat"
  type: "Concat"

  bottom: "dpn25_concat"
  bottom: "dpn26_conv3_split2"
  top: "dpn26_concat"
}
#################### dpn27 ####################
layer {
  name: "dpn27_concat_input"
  type: "Concat"

  bottom: "dpn26_elewise"
  bottom: "dpn26_concat"
  top: "dpn27_concat_input"
}
layer {
  name: "dpn27_bn"
  type: "BatchNorm"

  bottom: "dpn27_concat_input"
  top: "dpn27_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn27_scale"
  type: "Scale"

  bottom: "dpn27_bn"
  top: "dpn27_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn27_relu"
  type: "ReLU"

  bottom: "dpn27_bn"
  top: "dpn27_bn"
}
layer {
  name: "dpn27_conv1"
  type: "Convolution"

  bottom: "dpn27_bn"
  top: "dpn27_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn27_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn27_conv1"
  top: "dpn27_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn27_conv1_scale"
  type: "Scale"

  bottom: "dpn27_conv1"
  top: "dpn27_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn27_conv1_relu"
  type: "ReLU"

  bottom: "dpn27_conv1"
  top: "dpn27_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn27_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn27_conv1"
  top: "dpn27_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn27_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn27_shuffle"
  top: "dpn27_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn27_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn27_conv2"
  top: "dpn27_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn27_conv2_scale"
  type: "Scale"

  bottom: "dpn27_conv2"
  top: "dpn27_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn27_conv2_relu"
  type: "ReLU"

  bottom: "dpn27_conv2"
  top: "dpn27_conv2"
}
layer {
  name: "dpn27_conv3"
  type: "Convolution"

  bottom: "dpn27_conv2"
  top: "dpn27_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn27_pool/gap"
  type: "Pooling"

  bottom: "dpn27_conv3"
  top: "dpn27_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn27_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn27_pool/gap"
  top: "dpn27_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn27_relu/sqz"
  type: "ReLU"

  bottom: "dpn27_fc1/sqz"
  top: "dpn27_fc1/sqz"
}
layer {
  name: "dpn27_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn27_fc1/sqz"
  top: "dpn27_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn27_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn27_fc2/exc"
  top: "dpn27_fc2/exc"
}
layer {
  name: "dpn27_scale/se"
  type: "Scale"

  bottom: "dpn27_conv3"
  bottom: "dpn27_fc2/exc"
  top: "dpn27_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn27_conv3_Slice"
  type: "Slice"

  bottom: "dpn27_scale/se"
  top: "dpn27_conv3_split1"  # 0~1023
  top: "dpn27_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn27_elewise"
  type: "Eltwise"

  bottom: "dpn26_elewise"
  bottom: "dpn27_conv3_split1"
  top: "dpn27_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn27_concat"
  type: "Concat"

  bottom: "dpn26_concat"
  bottom: "dpn27_conv3_split2"
  top: "dpn27_concat"
}
#################### dpn28 ####################
layer {
  name: "dpn28_concat_input"
  type: "Concat"

  bottom: "dpn27_elewise"
  bottom: "dpn27_concat"
  top: "dpn28_concat_input"
}
layer {
  name: "dpn28_bn"
  type: "BatchNorm"

  bottom: "dpn28_concat_input"
  top: "dpn28_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_scale"
  type: "Scale"

  bottom: "dpn28_bn"
  top: "dpn28_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_relu"
  type: "ReLU"

  bottom: "dpn28_bn"
  top: "dpn28_bn"
}
layer {
  name: "dpn28_conv1"
  type: "Convolution"

  bottom: "dpn28_bn"
  top: "dpn28_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn28_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn28_conv1"
  top: "dpn28_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_conv1_scale"
  type: "Scale"

  bottom: "dpn28_conv1"
  top: "dpn28_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_conv1_relu"
  type: "ReLU"

  bottom: "dpn28_conv1"
  top: "dpn28_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn28_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn28_conv1"
  top: "dpn28_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn28_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn28_shuffle"
  top: "dpn28_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn28_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn28_conv2"
  top: "dpn28_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_conv2_scale"
  type: "Scale"

  bottom: "dpn28_conv2"
  top: "dpn28_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_conv2_relu"
  type: "ReLU"

  bottom: "dpn28_conv2"
  top: "dpn28_conv2"
}
layer {
  name: "dpn28_conv3"
  type: "Convolution"

  bottom: "dpn28_conv2"
  top: "dpn28_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn28_pool/gap"
  type: "Pooling"

  bottom: "dpn28_conv3"
  top: "dpn28_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn28_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn28_pool/gap"
  top: "dpn28_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn28_relu/sqz"
  type: "ReLU"

  bottom: "dpn28_fc1/sqz"
  top: "dpn28_fc1/sqz"
}
layer {
  name: "dpn28_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn28_fc1/sqz"
  top: "dpn28_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn28_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn28_fc2/exc"
  top: "dpn28_fc2/exc"
}
layer {
  name: "dpn28_scale/se"
  type: "Scale"

  bottom: "dpn28_conv3"
  bottom: "dpn28_fc2/exc"
  top: "dpn28_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn28_conv3_Slice"
  type: "Slice"

  bottom: "dpn28_scale/se"
  top: "dpn28_conv3_split1"  # 0~1023
  top: "dpn28_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn28_elewise"
  type: "Eltwise"

  bottom: "dpn27_elewise"
  bottom: "dpn28_conv3_split1"
  top: "dpn28_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn28_concat"
  type: "Concat"

  bottom: "dpn27_concat"
  bottom: "dpn28_conv3_split2"
  top: "dpn28_concat"
}
#################### dpn29 ####################
layer {
  name: "dpn29_concat_input"
  type: "Concat"

  bottom: "dpn28_elewise"
  bottom: "dpn28_concat"
  top: "dpn29_concat_input"
}
layer {
  name: "dpn29_bn"
  type: "BatchNorm"

  bottom: "dpn29_concat_input"
  top: "dpn29_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn29_scale"
  type: "Scale"

  bottom: "dpn29_bn"
  top: "dpn29_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn29_relu"
  type: "ReLU"

  bottom: "dpn29_bn"
  top: "dpn29_bn"
}
layer {
  name: "dpn29_conv1"
  type: "Convolution"

  bottom: "dpn29_bn"
  top: "dpn29_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn29_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn29_conv1"
  top: "dpn29_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn29_conv1_scale"
  type: "Scale"

  bottom: "dpn29_conv1"
  top: "dpn29_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn29_conv1_relu"
  type: "ReLU"

  bottom: "dpn29_conv1"
  top: "dpn29_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn29_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn29_conv1"
  top: "dpn29_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn29_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn29_shuffle"
  top: "dpn29_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn29_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn29_conv2"
  top: "dpn29_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn29_conv2_scale"
  type: "Scale"

  bottom: "dpn29_conv2"
  top: "dpn29_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn29_conv2_relu"
  top: "dpn29_conv2"
  bottom: "dpn29_conv2"
  type: "ReLU"
}
layer {
  name: "dpn29_conv3"
  type: "Convolution"

  bottom: "dpn29_conv2"
  top: "dpn29_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn29_pool/gap"
  type: "Pooling"

  bottom: "dpn29_conv3"
  top: "dpn29_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn29_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn29_pool/gap"
  top: "dpn29_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn29_relu/sqz"
  type: "ReLU"

  bottom: "dpn29_fc1/sqz"
  top: "dpn29_fc1/sqz"
}
layer {
  name: "dpn29_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn29_fc1/sqz"
  top: "dpn29_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn29_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn29_fc2/exc"
  top: "dpn29_fc2/exc"
}
layer {
  name: "dpn29_scale/se"
  type: "Scale"

  bottom: "dpn29_conv3"
  bottom: "dpn29_fc2/exc"
  top: "dpn29_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn29_conv3_Slice"
  type: "Slice"

  bottom: "dpn29_scale/se"
  top: "dpn29_conv3_split1"  # 0~1023
  top: "dpn29_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn29_elewise"
  type: "Eltwise"

  bottom: "dpn28_elewise"
  bottom: "dpn29_conv3_split1"
  top: "dpn29_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn29_concat"
  type: "Concat"

  bottom: "dpn28_concat"
  bottom: "dpn29_conv3_split2"
  top: "dpn29_concat"
}
#################### dpn30 ####################
layer {
  name: "dpn30_concat_input"
  type: "Concat"

  bottom: "dpn29_elewise"
  bottom: "dpn29_concat"
  top: "dpn30_concat_input"
}
layer {
  name: "dpn30_bn"
  type: "BatchNorm"

  bottom: "dpn30_concat_input"
  top: "dpn30_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn30_scale"
  type: "Scale"

  bottom: "dpn30_bn"
  top: "dpn30_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn30_relu"
  type: "ReLU"

  bottom: "dpn30_bn"
  top: "dpn30_bn"
}
layer {
  name: "dpn30_conv1"
  type: "Convolution"

  bottom: "dpn30_bn"
  top: "dpn30_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn30_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn30_conv1"
  top: "dpn30_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn30_conv1_scale"
  type: "Scale"

  bottom: "dpn30_conv1"
  top: "dpn30_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn30_conv1_relu"
  type: "ReLU"

  bottom: "dpn30_conv1"
  top: "dpn30_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn30_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn30_conv1"
  top: "dpn30_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn30_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn30_shuffle"
  top: "dpn30_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn30_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn30_conv2"
  top: "dpn30_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn30_conv2_scale"
  type: "Scale"

  bottom: "dpn30_conv2"
  top: "dpn30_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn30_conv2_relu"
  type: "ReLU"

  bottom: "dpn30_conv2"
  top: "dpn30_conv2"
}
layer {
  name: "dpn30_conv3"
  type: "Convolution"

  bottom: "dpn30_conv2"
  top: "dpn30_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn30_pool/gap"
  type: "Pooling"

  bottom: "dpn30_conv3"
  top: "dpn30_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn30_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn30_pool/gap"
  top: "dpn30_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn30_relu/sqz"
  type: "ReLU"

  bottom: "dpn30_fc1/sqz"
  top: "dpn30_fc1/sqz"
}
layer {
  name: "dpn30_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn30_fc1/sqz"
  top: "dpn30_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn30_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn30_fc2/exc"
  top: "dpn30_fc2/exc"
}
layer {
  name: "dpn30_scale/se"
  type: "Scale"

  bottom: "dpn30_conv3"
  bottom: "dpn30_fc2/exc"
  top: "dpn30_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn30_conv3_Slice"
  type: "Slice"

  bottom: "dpn30_scale/se"
  top: "dpn30_conv3_split1"  # 0~1023
  top: "dpn30_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn30_elewise"
  type: "Eltwise"

  bottom: "dpn29_elewise"
  bottom: "dpn30_conv3_split1"
  top: "dpn30_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn30_concat"
  type: "Concat"

  bottom: "dpn29_concat"
  bottom: "dpn30_conv3_split2"
  top: "dpn30_concat"
}
#################### dpn31 ####################
layer {
  name: "dpn31_concat_input"
  type: "Concat"

  bottom: "dpn30_elewise"
  bottom: "dpn30_concat"
  top: "dpn31_concat_input"
}
layer {
  name: "dpn31_bn"
  type: "BatchNorm"

  bottom: "dpn31_concat_input"
  top: "dpn31_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn31_scale"
  type: "Scale"

  bottom: "dpn31_bn"
  top: "dpn31_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn31_relu"
  type: "ReLU"

  bottom: "dpn31_bn"
  top: "dpn31_bn"
}
layer {
  name: "dpn31_conv1"
  type: "Convolution"

  bottom: "dpn31_bn"
  top: "dpn31_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn31_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn31_conv1"
  top: "dpn31_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn31_conv1_scale"
  type: "Scale"

  bottom: "dpn31_conv1"
  top: "dpn31_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn31_conv1_relu"
  type: "ReLU"

  bottom: "dpn31_conv1"
  top: "dpn31_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn31_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn31_conv1"
  top: "dpn31_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn31_conv2"
  type: "Convolution"

  bottom: "dpn31_shuffle"
  top: "dpn31_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn31_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn31_conv2"
  top: "dpn31_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn31_conv2_scale"
  type: "Scale"

  bottom: "dpn31_conv2"
  top: "dpn31_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn31_conv2_relu"
  type: "ReLU"

  bottom: "dpn31_conv2"
  top: "dpn31_conv2"
}
layer {
  name: "dpn31_conv3"
  type: "Convolution"

  bottom: "dpn31_conv2"
  top: "dpn31_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn31_pool/gap"
  type: "Pooling"

  bottom: "dpn31_conv3"
  top: "dpn31_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn31_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn31_pool/gap"
  top: "dpn31_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn31_relu/sqz"
  type: "ReLU"

  bottom: "dpn31_fc1/sqz"
  top: "dpn31_fc1/sqz"
}
layer {
  name: "dpn31_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn31_fc1/sqz"
  top: "dpn31_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn31_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn31_fc2/exc"
  top: "dpn31_fc2/exc"
}
layer {
  name: "dpn31_scale/se"
  type: "Scale"

  bottom: "dpn31_conv3"
  bottom: "dpn31_fc2/exc"
  top: "dpn31_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn31_conv3_Slice"
  type: "Slice"

  bottom: "dpn31_scale/se"
  top: "dpn31_conv3_split1"  # 0~1023
  top: "dpn31_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn31_elewise"
  type: "Eltwise"

  bottom: "dpn30_elewise"
  bottom: "dpn31_conv3_split1"
  top: "dpn31_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn31_concat"
  type: "Concat"

  bottom: "dpn30_concat"
  bottom: "dpn31_conv3_split2"
  top: "dpn31_concat"
}
#################### dpn32 ####################
layer {
  name: "dpn32_concat_input"
  type: "Concat"

  bottom: "dpn31_elewise"
  bottom: "dpn31_concat"
  top: "dpn32_concat_input"
}
layer {
  name: "dpn32_bn"
  type: "BatchNorm"

  bottom: "dpn32_concat_input"
  top: "dpn32_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn32_scale"
  type: "Scale"

  bottom: "dpn32_bn"
  top: "dpn32_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn32_relu"
  type: "ReLU"

  bottom: "dpn32_bn"
  top: "dpn32_bn"
}
layer {
  name: "dpn32_conv1"
  type: "Convolution"

  bottom: "dpn32_bn"
  top: "dpn32_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn32_conv1_bn"
  bottom: "dpn32_conv1"

  top: "dpn32_conv1"
  type: "BatchNorm"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn32_conv1_scale"
  type: "Scale"

  bottom: "dpn32_conv1"
  top: "dpn32_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn32_conv1_relu"
  type: "ReLU"

  bottom: "dpn32_conv1"
  top: "dpn32_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn32_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn32_conv1"
  top: "dpn32_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn32_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn32_shuffle"
  top: "dpn32_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn32_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn32_conv2"
  top: "dpn32_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn32_conv2_scale"
  type: "Scale"

  bottom: "dpn32_conv2"
  top: "dpn32_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn32_conv2_relu"
  type: "ReLU"

  bottom: "dpn32_conv2"
  top: "dpn32_conv2"
}
layer {
  name: "dpn32_conv3"
  type: "Convolution"

  bottom: "dpn32_conv2"
  top: "dpn32_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn32_pool/gap"
  type: "Pooling"

  bottom: "dpn32_conv3"
  top: "dpn32_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn32_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn32_pool/gap"
  top: "dpn32_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn32_relu/sqz"
  type: "ReLU"

  bottom: "dpn32_fc1/sqz"
  top: "dpn32_fc1/sqz"
}
layer {
  name: "dpn32_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn32_fc1/sqz"
  top: "dpn32_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn32_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn32_fc2/exc"
  top: "dpn32_fc2/exc"
}
layer {
  name: "dpn32_scale/se"
  type: "Scale"

  bottom: "dpn32_conv3"
  bottom: "dpn32_fc2/exc"
  top: "dpn32_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn32_conv3_Slice"
  type: "Slice"

  bottom: "dpn32_scale/se"
  top: "dpn32_conv3_split1"  # 0~1023
  top: "dpn32_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn32_elewise"
  type: "Eltwise"

  bottom: "dpn31_elewise"
  bottom: "dpn32_conv3_split1"
  top: "dpn32_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn32_concat"
  type: "Concat"

  bottom: "dpn31_concat"
  bottom: "dpn32_conv3_split2"
  top: "dpn32_concat"
}
#################### dpn33 ####################
layer {
  name: "dpn33_concat_input"
  type: "Concat"

  bottom: "dpn32_elewise"
  bottom: "dpn32_concat"
  top: "dpn33_concat_input"
}
layer {
  name: "dpn33_bn"
  type: "BatchNorm"

  bottom: "dpn33_concat_input"
  top: "dpn33_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn33_scale"
  type: "Scale"

  bottom: "dpn33_bn"
  top: "dpn33_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn33_relu"
  type: "ReLU"

  bottom: "dpn33_bn"
  top: "dpn33_bn"
}
layer {
  name: "dpn33_conv1"
  type: "Convolution"

  bottom: "dpn33_bn"
  top: "dpn33_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn33_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn33_conv1"
  top: "dpn33_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn33_conv1_scale"
  type: "Scale"

  bottom: "dpn33_conv1"
  top: "dpn33_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn33_conv1_relu"
  type: "ReLU"

  bottom: "dpn33_conv1"
  top: "dpn33_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn33_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn33_conv1"
  top: "dpn33_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn33_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn33_shuffle"
  top: "dpn33_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn33_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn33_conv2"
  top: "dpn33_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn33_conv2_scale"
  type: "Scale"

  bottom: "dpn33_conv2"
  top: "dpn33_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn33_conv2_relu"
  type: "ReLU"

  bottom: "dpn33_conv2"
  top: "dpn33_conv2"
}
layer {
  name: "dpn33_conv3"
  type: "Convolution"

  bottom: "dpn33_conv2"
  top: "dpn33_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn33_pool/gap"
  type: "Pooling"

  bottom: "dpn33_conv3"
  top: "dpn33_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn33_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn33_pool/gap"
  top: "dpn33_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn33_relu/sqz"
  type: "ReLU"

  bottom: "dpn33_fc1/sqz"
  top: "dpn33_fc1/sqz"
}
layer {
  name: "dpn33_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn33_fc1/sqz"
  top: "dpn33_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn33_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn33_fc2/exc"
  top: "dpn33_fc2/exc"
}
layer {
  name: "dpn33_scale/se"
  type: "Scale"

  bottom: "dpn33_conv3"
  bottom: "dpn33_fc2/exc"
  top: "dpn33_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn33_conv3_Slice"
  type: "Slice"

  bottom: "dpn33_scale/se"
  top: "dpn33_conv3_split1"  # 0~1023
  top: "dpn33_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn33_elewise"
  type: "Eltwise"

  bottom: "dpn32_elewise"
  bottom: "dpn33_conv3_split1"
  top: "dpn33_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn33_concat"
  type: "Concat"

  bottom: "dpn32_concat"
  bottom: "dpn33_conv3_split2"
  top: "dpn33_concat"
}
#################### dpn34 ####################
layer {
  name: "dpn34_concat_input"
  type: "Concat"

  bottom: "dpn33_elewise"
  bottom: "dpn33_concat"
  top: "dpn34_concat_input"
}
layer {
  name: "dpn34_bn"
  type: "BatchNorm"

  bottom: "dpn34_concat_input"
  top: "dpn34_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn34_scale"
  type: "Scale"

  bottom: "dpn34_bn"
  top: "dpn34_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn34_relu"
  type: "ReLU"

  bottom: "dpn34_bn"
  top: "dpn34_bn"
}
layer {
  name: "dpn34_conv1"
  type: "Convolution"

  bottom: "dpn34_bn"
  top: "dpn34_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn34_conv1_bn"
  bottom: "dpn34_conv1"

  top: "dpn34_conv1"
  type: "BatchNorm"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn34_conv1_scale"
  type: "Scale"

  bottom: "dpn34_conv1"
  top: "dpn34_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn34_conv1_relu"
  type: "ReLU"

  bottom: "dpn34_conv1"
  top: "dpn34_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn34_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn34_conv1"
  top: "dpn34_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn34_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn34_shuffle"
  top: "dpn34_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn34_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn34_conv2"
  top: "dpn34_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn34_conv2_scale"
  type: "Scale"

  bottom: "dpn34_conv2"
  top: "dpn34_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn34_conv2_relu"
  type: "ReLU"

  bottom: "dpn34_conv2"
  top: "dpn34_conv2"
}
layer {
  name: "dpn34_conv3"
  type: "Convolution"

  bottom: "dpn34_conv2"
  top: "dpn34_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn34_pool/gap"
  type: "Pooling"

  bottom: "dpn34_conv3"
  top: "dpn34_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn34_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn34_pool/gap"
  top: "dpn34_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn34_relu/sqz"
  type: "ReLU"

  bottom: "dpn34_fc1/sqz"
  top: "dpn34_fc1/sqz"
}
layer {
  name: "dpn34_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn34_fc1/sqz"
  top: "dpn34_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn34_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn34_fc2/exc"
  top: "dpn34_fc2/exc"
}
layer {
  name: "dpn34_scale/se"
  type: "Scale"

  bottom: "dpn34_conv3"
  bottom: "dpn34_fc2/exc"
  top: "dpn34_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn34_conv3_Slice"
  type: "Slice"

  bottom: "dpn34_scale/se"
  top: "dpn34_conv3_split1"  # 0~1023
  top: "dpn34_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn34_elewise"
  type: "Eltwise"

  bottom: "dpn33_elewise"
  bottom: "dpn34_conv3_split1"
  top: "dpn34_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn34_concat"
  type: "Concat"

  bottom: "dpn33_concat"
  bottom: "dpn34_conv3_split2"
  top: "dpn34_concat"
}
#################### dpn35 ####################
layer {
  name: "dpn35_concat_input"
  type: "Concat"

  bottom: "dpn34_elewise"
  bottom: "dpn34_concat"
  top: "dpn35_concat_input"
}
layer {
  name: "dpn35_bn"
  type: "BatchNorm"

  bottom: "dpn35_concat_input"
  top: "dpn35_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn35_scale"
  type: "Scale"

  bottom: "dpn35_bn"
  top: "dpn35_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn35_relu"
  type: "ReLU"

  bottom: "dpn35_bn"
  top: "dpn35_bn"
}
layer {
  name: "dpn35_conv1"
  type: "Convolution"

  bottom: "dpn35_bn"
  top: "dpn35_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn35_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn35_conv1"
  top: "dpn35_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn35_conv1_scale"
  type: "Scale"

  bottom: "dpn35_conv1"
  top: "dpn35_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn35_conv1_relu"
  type: "ReLU"

  bottom: "dpn35_conv1"
  top: "dpn35_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn35_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn35_conv1"
  top: "dpn35_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn35_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn35_shuffle"
  top: "dpn35_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn35_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn35_conv2"
  top: "dpn35_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn35_conv2_scale"
  type: "Scale"

  bottom: "dpn35_conv2"
  top: "dpn35_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn35_conv2_relu"
  type: "ReLU"

  bottom: "dpn35_conv2"
  top: "dpn35_conv2"
}
layer {
  name: "dpn35_conv3"
  type: "Convolution"

  bottom: "dpn35_conv2"
  top: "dpn35_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn35_pool/gap"
  type: "Pooling"

  bottom: "dpn35_conv3"
  top: "dpn35_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn35_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn35_pool/gap"
  top: "dpn35_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn35_relu/sqz"
  type: "ReLU"

  bottom: "dpn35_fc1/sqz"
  top: "dpn35_fc1/sqz"
}
layer {
  name: "dpn35_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn35_fc1/sqz"
  top: "dpn35_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn35_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn35_fc2/exc"
  top: "dpn35_fc2/exc"
}
layer {
  name: "dpn35_scale/se"
  type: "Scale"

  bottom: "dpn35_conv3"
  bottom: "dpn35_fc2/exc"
  top: "dpn35_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn35_conv3_Slice"
  type: "Slice"

  bottom: "dpn35_scale/se"
  top: "dpn35_conv3_split1"  # 0~1023
  top: "dpn35_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn35_elewise"
  type: "Eltwise"

  bottom: "dpn34_elewise"
  bottom: "dpn35_conv3_split1"
  top: "dpn35_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn35_concat"
  type: "Concat"

  bottom: "dpn34_concat"
  bottom: "dpn35_conv3_split2"
  top: "dpn35_concat"
}
#################### dpn36 ####################
layer {
  name: "dpn36_concat_input"
  type: "Concat"

  bottom: "dpn35_elewise"
  bottom: "dpn35_concat"
  top: "dpn36_concat_input"
}
layer {
  name: "dpn36_bn"
  type: "BatchNorm"

  bottom: "dpn36_concat_input"
  top: "dpn36_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn36_scale"
  type: "Scale"

  bottom: "dpn36_bn"
  top: "dpn36_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn36_relu"
  type: "ReLU"

  bottom: "dpn36_bn"
  top: "dpn36_bn"
}
layer {
  name: "dpn36_conv1"
  type: "Convolution"

  bottom: "dpn36_bn"
  top: "dpn36_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn36_conv1_bn"
  bottom: "dpn36_conv1"

  top: "dpn36_conv1"
  type: "BatchNorm"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn36_conv1_scale"
  type: "Scale"

  bottom: "dpn36_conv1"
  top: "dpn36_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn36_conv1_relu"
  type: "ReLU"

  bottom: "dpn36_conv1"
  top: "dpn36_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn36_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn36_conv1"
  top: "dpn36_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn36_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn36_shuffle"
  top: "dpn36_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn36_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn36_conv2"
  top: "dpn36_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn36_conv2_scale"
  type: "Scale"

  bottom: "dpn36_conv2"
  top: "dpn36_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn36_conv2_relu"
  type: "ReLU"

  bottom: "dpn36_conv2"
  top: "dpn36_conv2"
}
layer {
  name: "dpn36_conv3"
  type: "Convolution"

  bottom: "dpn36_conv2"
  top: "dpn36_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn36_pool/gap"
  type: "Pooling"

  bottom: "dpn36_conv3"
  top: "dpn36_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn36_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn36_pool/gap"
  top: "dpn36_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn36_relu/sqz"
  type: "ReLU"

  bottom: "dpn36_fc1/sqz"
  top: "dpn36_fc1/sqz"
}
layer {
  name: "dpn36_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn36_fc1/sqz"
  top: "dpn36_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn36_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn36_fc2/exc"
  top: "dpn36_fc2/exc"
}
layer {
  name: "dpn36_scale/se"
  type: "Scale"

  bottom: "dpn36_conv3"
  bottom: "dpn36_fc2/exc"
  top: "dpn36_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn36_conv3_Slice"
  type: "Slice"

  bottom: "dpn36_scale/se"
  top: "dpn36_conv3_split1"  # 0~1023
  top: "dpn36_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn36_elewise"
  type: "Eltwise"

  bottom: "dpn35_elewise"
  bottom: "dpn36_conv3_split1"
  top: "dpn36_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn36_concat"
  type: "Concat"

  bottom: "dpn35_concat"
  bottom: "dpn36_conv3_split2"
  top: "dpn36_concat"
}
#################### dpn37 ####################
layer {
  name: "dpn37_concat_input"
  type: "Concat"

  bottom: "dpn36_elewise"
  bottom: "dpn36_concat"
  top: "dpn37_concat_input"
}
layer {
  name: "dpn37_bn"
  type: "BatchNorm"

  bottom: "dpn37_concat_input"
  top: "dpn37_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn37_scale"
  type: "Scale"

  bottom: "dpn37_bn"
  top: "dpn37_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn37_relu"
  type: "ReLU"

  bottom: "dpn37_bn"
  top: "dpn37_bn"
}
layer {
  name: "dpn37_conv1"
  type: "Convolution"

  bottom: "dpn37_bn"
  top: "dpn37_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn37_conv1_bn"
  bottom: "dpn37_conv1"

  top: "dpn37_conv1"
  type: "BatchNorm"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn37_conv1_scale"
  type: "Scale"

  bottom: "dpn37_conv1"
  top: "dpn37_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn37_conv1_relu"
  type: "ReLU"

  bottom: "dpn37_conv1"
  top: "dpn37_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn37_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn37_conv1"
  top: "dpn37_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn37_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn37_shuffle"
  top: "dpn37_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn37_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn37_conv2"
  top: "dpn37_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn37_conv2_scale"
  type: "Scale"

  bottom: "dpn37_conv2"
  top: "dpn37_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn37_conv2_relu"
  type: "ReLU"

  bottom: "dpn37_conv2"
  top: "dpn37_conv2"
}
layer {
  name: "dpn37_conv3"
  type: "Convolution"

  bottom: "dpn37_conv2"
  top: "dpn37_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn37_pool/gap"
  type: "Pooling"

  bottom: "dpn37_conv3"
  top: "dpn37_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn37_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn37_pool/gap"
  top: "dpn37_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn37_relu/sqz"
  type: "ReLU"

  bottom: "dpn37_fc1/sqz"
  top: "dpn37_fc1/sqz"
}
layer {
  name: "dpn37_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn37_fc1/sqz"
  top: "dpn37_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn37_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn37_fc2/exc"
  top: "dpn37_fc2/exc"
}
layer {
  name: "dpn37_scale/se"
  type: "Scale"

  bottom: "dpn37_conv3"
  bottom: "dpn37_fc2/exc"
  top: "dpn37_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn37_conv3_Slice"
  type: "Slice"

  bottom: "dpn37_scale/se"
  top: "dpn37_conv3_split1"  # 0~1023
  top: "dpn37_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn37_elewise"
  type: "Eltwise"

  bottom: "dpn36_elewise"
  bottom: "dpn37_conv3_split1"
  top: "dpn37_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn37_concat"
  type: "Concat"

  bottom: "dpn36_concat"
  bottom: "dpn37_conv3_split2"
  top: "dpn37_concat"
}
#################### dpn38 ####################
layer {
  name: "dpn38_concat_input"
  type: "Concat"

  bottom: "dpn37_elewise"
  bottom: "dpn37_concat"
  top: "dpn38_concat_input"
}
layer {
  name: "dpn38_bn"
  type: "BatchNorm"

  bottom: "dpn38_concat_input"
  top: "dpn38_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn38_scale"
  type: "Scale"

  bottom: "dpn38_bn"
  top: "dpn38_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn38_relu"
  type: "ReLU"

  bottom: "dpn38_bn"
  top: "dpn38_bn"
}
layer {
  name: "dpn38_conv1"
  type: "Convolution"

  bottom: "dpn38_bn"
  top: "dpn38_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn38_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn38_conv1"
  top: "dpn38_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn38_conv1_scale"
  type: "Scale"

  bottom: "dpn38_conv1"
  top: "dpn38_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn38_conv1_relu"
  type: "ReLU"

  bottom: "dpn38_conv1"
  top: "dpn38_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn38_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn38_conv1"
  top: "dpn38_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn38_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn38_shuffle"
  top: "dpn38_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn38_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn38_conv2"
  top: "dpn38_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn38_conv2_scale"
  type: "Scale"

  bottom: "dpn38_conv2"
  top: "dpn38_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn38_conv2_relu"
  type: "ReLU"

  bottom: "dpn38_conv2"
  top: "dpn38_conv2"
}
layer {
  name: "dpn38_conv3"
  type: "Convolution"

  bottom: "dpn38_conv2"
  top: "dpn38_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn38_pool/gap"
  type: "Pooling"

  bottom: "dpn38_conv3"
  top: "dpn38_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn38_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn38_pool/gap"
  top: "dpn38_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn38_relu/sqz"
  type: "ReLU"

  bottom: "dpn38_fc1/sqz"
  top: "dpn38_fc1/sqz"
}
layer {
  name: "dpn38_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn38_fc1/sqz"
  top: "dpn38_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn38_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn38_fc2/exc"
  top: "dpn38_fc2/exc"
}
layer {
  name: "dpn38_scale/se"
  type: "Scale"

  bottom: "dpn38_conv3"
  bottom: "dpn38_fc2/exc"
  top: "dpn38_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn38_conv3_Slice"
  type: "Slice"

  bottom: "dpn38_scale/se"
  top: "dpn38_conv3_split1"  # 0~1023
  top: "dpn38_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn38_elewise"
  type: "Eltwise"

  bottom: "dpn37_elewise"
  bottom: "dpn38_conv3_split1"
  top: "dpn38_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn38_concat"
  type: "Concat"

  bottom: "dpn37_concat"
  bottom: "dpn38_conv3_split2"
  top: "dpn38_concat"
}
#################### dpn39 ####################
layer {
  name: "dpn39_concat_input"
  type: "Concat"

  bottom: "dpn38_elewise"
  bottom: "dpn38_concat"
  top: "dpn39_concat_input"
}
layer {
  name: "dpn39_bn"
  type: "BatchNorm"

  bottom: "dpn39_concat_input"
  top: "dpn39_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn39_scale"
  type: "Scale"

  bottom: "dpn39_bn"
  top: "dpn39_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn39_relu"
  type: "ReLU"

  bottom: "dpn39_bn"
  top: "dpn39_bn"
}
layer {
  name: "dpn39_conv1"
  type: "Convolution"

  bottom: "dpn39_bn"
  top: "dpn39_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn39_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn39_conv1"
  top: "dpn39_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn39_conv1_scale"
  type: "Scale"

  bottom: "dpn39_conv1"
  top: "dpn39_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn39_conv1_relu"
  type: "ReLU"

  bottom: "dpn39_conv1"
  top: "dpn39_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn39_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn39_conv1"
  top: "dpn39_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn39_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn39_shuffle"
  top: "dpn39_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn39_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn39_conv2"
  top: "dpn39_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn39_conv2_scale"
  type: "Scale"

  bottom: "dpn39_conv2"
  top: "dpn39_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn39_conv2_relu"
  type: "ReLU"

  bottom: "dpn39_conv2"
  top: "dpn39_conv2"
}
layer {
  name: "dpn39_conv3"
  type: "Convolution"

  bottom: "dpn39_conv2"
  top: "dpn39_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn39_pool/gap"
  type: "Pooling"

  bottom: "dpn39_conv3"
  top: "dpn39_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn39_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn39_pool/gap"
  top: "dpn39_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn39_relu/sqz"
  type: "ReLU"

  bottom: "dpn39_fc1/sqz"
  top: "dpn39_fc1/sqz"
}
layer {
  name: "dpn39_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn39_fc1/sqz"
  top: "dpn39_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn39_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn39_fc2/exc"
  top: "dpn39_fc2/exc"
}
layer {
  name: "dpn39_scale/se"
  type: "Scale"

  bottom: "dpn39_conv3"
  bottom: "dpn39_fc2/exc"
  top: "dpn39_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn39_conv3_Slice"
  type: "Slice"

  bottom: "dpn39_scale/se"
  top: "dpn39_conv3_split1"  # 0~1023
  top: "dpn39_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn39_elewise"
  type: "Eltwise"

  bottom: "dpn38_elewise"
  bottom: "dpn39_conv3_split1"
  top: "dpn39_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn39_concat"
  type: "Concat"

  bottom: "dpn38_concat"
  bottom: "dpn39_conv3_split2"
  top: "dpn39_concat"
}
#################### dpn40 ####################
layer {
  name: "dpn40_concat_input"
  type: "Concat"

  bottom: "dpn39_elewise"
  bottom: "dpn39_concat"
  top: "dpn40_concat_input"
}
layer {
  name: "dpn40_bn"
  type: "BatchNorm"

  bottom: "dpn40_concat_input"
  top: "dpn40_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn40_scale"
  type: "Scale"

  bottom: "dpn40_bn"
  top: "dpn40_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn40_relu"
  type: "ReLU"

  bottom: "dpn40_bn"
  top: "dpn40_bn"
}
layer {
  name: "dpn40_conv1"
  type: "Convolution"

  bottom: "dpn40_bn"
  top: "dpn40_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn40_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn40_conv1"
  top: "dpn40_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn40_conv1_scale"
  type: "Scale"

  bottom: "dpn40_conv1"
  top: "dpn40_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn40_conv1_relu"
  type: "ReLU"

  bottom: "dpn40_conv1"
  top: "dpn40_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn40_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn40_conv1"
  top: "dpn40_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn40_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn40_shuffle"
  top: "dpn40_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 640

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn40_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn40_conv2"
  top: "dpn40_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn40_conv2_scale"
  type: "Scale"

  bottom: "dpn40_conv2"
  top: "dpn40_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn40_conv2_relu"
  type: "ReLU"

  bottom: "dpn40_conv2"
  top: "dpn40_conv2"
}
layer {
  name: "dpn40_conv3"
  type: "Convolution"

  bottom: "dpn40_conv2"
  top: "dpn40_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1056

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn40_pool/gap"
  type: "Pooling"

  bottom: "dpn40_conv3"
  top: "dpn40_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn40_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn40_pool/gap"
  top: "dpn40_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 66       # 1056/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn40_relu/sqz"
  type: "ReLU"

  bottom: "dpn40_fc1/sqz"
  top: "dpn40_fc1/sqz"
}
layer {
  name: "dpn40_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn40_fc1/sqz"
  top: "dpn40_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1056

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn40_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn40_fc2/exc"
  top: "dpn40_fc2/exc"
}
layer {
  name: "dpn40_scale/se"
  type: "Scale"

  bottom: "dpn40_conv3"
  bottom: "dpn40_fc2/exc"
  top: "dpn40_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn40_conv3_Slice"
  type: "Slice"

  bottom: "dpn40_scale/se"
  top: "dpn40_conv3_split1"  # 0~1023
  top: "dpn40_conv3_split2"  # 1024~1055

  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn40_elewise"
  type: "Eltwise"

  bottom: "dpn39_elewise"
  bottom: "dpn40_conv3_split1"
  top: "dpn40_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn40_concat"
  type: "Concat"

  bottom: "dpn39_concat"
  bottom: "dpn40_conv3_split2"
  top: "dpn40_concat"
}
#################################################################################################
#################### dpn41 ####################
#################################################################################################
layer {
  name: "dpn41_concat_input"
  type: "Concat"

  bottom: "dpn40_elewise"
  bottom: "dpn40_concat"
  top: "dpn41_concat_input"
}
layer {
  name: "dpn41_match_bn"
  type: "BatchNorm"

  bottom: "dpn41_concat_input"
  top: "dpn41_match_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn41_match_scale"
  type: "Scale"

  bottom: "dpn41_match_bn"
  top: "dpn41_match_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn41_match_relu"
  type: "ReLU"

  bottom: "dpn41_match_bn"
  top: "dpn41_match_bn"
}
layer {
  name: "dpn41_match_conv"
  type: "Convolution"

  bottom: "dpn41_match_bn"
  top: "dpn41_match_conv"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 2304

    kernel_size: 1
    pad: 0
    stride: 2
    # dilation: 1

    group: 4
    bias_term: false
  }
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn41_match_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn41_match_conv"
  top: "dpn41_match_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn41_match_conv_Slice"
  type: "Slice"

  bottom: "dpn41_match_shuffle"
  top: "dpn41_match_conv_split1"  # 0~2047
  top: "dpn41_match_conv_split2"  # 2048~2303

  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn41_bn"
  type: "BatchNorm"

  bottom: "dpn41_concat_input"
  top: "dpn41_bn"

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn41_scale"
  type: "Scale"

  bottom: "dpn41_bn"
  top: "dpn41_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn41_relu"
  type: "ReLU"

  bottom: "dpn41_bn"
  top: "dpn41_bn"
}
layer {
  name: "dpn41_conv1"
  type: "Convolution"

  bottom: "dpn41_bn"
  top: "dpn41_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1280

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn41_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn41_conv1"
  top: "dpn41_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn41_conv1_scale"
  type: "Scale"

  bottom: "dpn41_conv1"
  top: "dpn41_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn41_conv1_relu"
  type: "ReLU"

  bottom: "dpn41_conv1"
  top: "dpn41_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn41_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn41_conv1"
  top: "dpn41_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn41_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn41_shuffle"
  top: "dpn41_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1280

    kernel_size: 3
    pad: 1
    stride: 2
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn41_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn41_conv2"
  top: "dpn41_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn41_conv2_scale"
  type: "Scale"

  bottom: "dpn41_conv2"
  top: "dpn41_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn41_conv2_relu"
  type: "ReLU"

  bottom: "dpn41_conv2"
  top: "dpn41_conv2"
}
layer {
  name: "dpn41_conv3"
  type: "Convolution"

  bottom: "dpn41_conv2"
  top: "dpn41_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 2176

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn41_pool/gap"
  type: "Pooling"

  bottom: "dpn41_conv3"
  top: "dpn41_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn41_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn41_pool/gap"
  top: "dpn41_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 136       # 2176/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn41_relu/sqz"
  type: "ReLU"

  bottom: "dpn41_fc1/sqz"
  top: "dpn41_fc1/sqz"
}
layer {
  name: "dpn41_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn41_fc1/sqz"
  top: "dpn41_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 2176

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn41_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn41_fc2/exc"
  top: "dpn41_fc2/exc"
}
layer {
  name: "dpn41_scale/se"
  type: "Scale"

  bottom: "dpn41_conv3"
  bottom: "dpn41_fc2/exc"
  top: "dpn41_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn41_conv3_Slice"
  type: "Slice"

  bottom: "dpn41_scale/se"
  top: "dpn41_conv3_split1"  # 0~2047
  top: "dpn41_conv3_split2"  # 2048~2175

  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn41_elewise"
  type: "Eltwise"

  bottom: "dpn41_match_conv_split1"
  bottom: "dpn41_conv3_split1"
  top: "dpn41_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn41_concat"
  type: "Concat"

  bottom: "dpn41_match_conv_split2"
  bottom: "dpn41_conv3_split2"
  top: "dpn41_concat"
}
#################### dpn42 ####################
layer {
  name: "dpn42_concat_input"
  type: "Concat"

  bottom: "dpn41_elewise"
  bottom: "dpn41_concat"
  top: "dpn42_concat_input"
}
layer {
  name: "dpn42_bn"
  type: "BatchNorm"

  bottom: "dpn42_concat_input"
  top: "dpn42_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn42_scale"
  type: "Scale"

  bottom: "dpn42_bn"
  top: "dpn42_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn42_relu"
  type: "ReLU"

  bottom: "dpn42_bn"
  top: "dpn42_bn"
}
layer {
  name: "dpn42_conv1"
  type: "Convolution"

  bottom: "dpn42_bn"
  top: "dpn42_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1280

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn42_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn42_conv1"
  top: "dpn42_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn42_conv1_scale"
  type: "Scale"

  bottom: "dpn42_conv1"
  top: "dpn42_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn42_conv1_relu"
  type: "ReLU"

  bottom: "dpn42_conv1"
  top: "dpn42_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn42_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn42_conv1"
  top: "dpn42_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn42_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn42_shuffle"
  top: "dpn42_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1280

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn42_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn42_conv2"
  top: "dpn42_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn42_conv2_scale"
  type: "Scale"

  bottom: "dpn42_conv2"
  top: "dpn42_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn42_conv2_relu"
  type: "ReLU"

  bottom: "dpn42_conv2"
  top: "dpn42_conv2"
}
layer {
  name: "dpn42_conv3"
  type: "Convolution"

  bottom: "dpn42_conv2"
  top: "dpn42_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 2176

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn42_pool/gap"
  type: "Pooling"

  bottom: "dpn42_conv3"
  top: "dpn42_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn42_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn42_pool/gap"
  top: "dpn42_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 136       # 2176/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn42_relu/sqz"
  type: "ReLU"

  bottom: "dpn42_fc1/sqz"
  top: "dpn42_fc1/sqz"
}
layer {
  name: "dpn42_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn42_fc1/sqz"
  top: "dpn42_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 2176

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn42_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn42_fc2/exc"
  top: "dpn42_fc2/exc"
}
layer {
  name: "dpn42_scale/se"
  type: "Scale"

  bottom: "dpn42_conv3"
  bottom: "dpn42_fc2/exc"
  top: "dpn42_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn42_conv3_Slice"
  type: "Slice"

  bottom: "dpn42_scale/se"
  top: "dpn42_conv3_split1"  # 0~2047
  top: "dpn42_conv3_split2"  # 2048~2175

  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn42_elewise"
  type: "Eltwise"

  bottom: "dpn41_elewise"
  bottom: "dpn42_conv3_split1"
  top: "dpn42_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn42_concat"
  type: "Concat"

  bottom: "dpn41_concat"
  bottom: "dpn42_conv3_split2"
  top: "dpn42_concat"
}
#################### dpn43 ####################
layer {
  name: "dpn43_concat_input"
  type: "Concat"

  bottom: "dpn42_elewise"
  bottom: "dpn42_concat"
  top: "dpn43_concat_input"
}
layer {
  name: "dpn43_bn"
  type: "BatchNorm"

  bottom: "dpn43_concat_input"
  top: "dpn43_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn43_scale"
  type: "Scale"

  bottom: "dpn43_bn"
  top: "dpn43_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn43_relu"
  type: "ReLU"

  bottom: "dpn43_bn"
  top: "dpn43_bn"
}
layer {
  name: "dpn43_conv1"
  type: "Convolution"

  bottom: "dpn43_bn"
  top: "dpn43_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1280

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}
layer {
  name: "dpn43_conv1_bn"
  type: "BatchNorm"

  bottom: "dpn43_conv1"
  top: "dpn43_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn43_conv1_scale"
  type: "Scale"

  bottom: "dpn43_conv1"
  top: "dpn43_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn43_conv1_relu"
  type: "ReLU"

  bottom: "dpn43_conv1"
  top: "dpn43_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "dpn43_shuffle"
  type: "ShuffleChannel"

  bottom: "dpn43_conv1"
  top: "dpn43_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "dpn43_conv2"
  type: "ConvolutionDepthwise"

  bottom: "dpn43_shuffle"
  top: "dpn43_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1280

    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1

    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn43_conv2_bn"
  type: "BatchNorm"

  bottom: "dpn43_conv2"
  top: "dpn43_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn43_conv2_scale"
  type: "Scale"

  bottom: "dpn43_conv2"
  top: "dpn43_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn43_conv2_relu"
  type: "ReLU"

  bottom: "dpn43_conv2"
  top: "dpn43_conv2"
}
layer {
  name: "dpn43_conv3"
  type: "Convolution"

  bottom: "dpn43_conv2"
  top: "dpn43_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 2176

    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1

    group: 4
    bias_term: false
  }
}


# -------------------- SE Block Start
layer {
  name: "dpn43_pool/gap"
  type: "Pooling"

  bottom: "dpn43_conv3"
  top: "dpn43_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "dpn43_fc1/sqz"
  type: "InnerProduct"

  bottom: "dpn43_pool/gap"
  top: "dpn43_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 136       # 2176/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn43_relu/sqz"
  type: "ReLU"

  bottom: "dpn43_fc1/sqz"
  top: "dpn43_fc1/sqz"
}
layer {
  name: "dpn43_fc2/exc"
  type: "InnerProduct"

  bottom: "dpn43_fc1/sqz"
  top: "dpn43_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 2176

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "dpn43_sigm/gate"
  type: "Sigmoid"
  bottom: "dpn43_fc2/exc"
  top: "dpn43_fc2/exc"
}
layer {
  name: "dpn43_scale/se"
  type: "Scale"

  bottom: "dpn43_conv3"
  bottom: "dpn43_fc2/exc"
  top: "dpn43_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


layer {
  name: "dpn43_conv3_Slice"
  type: "Slice"

  bottom: "dpn43_scale/se"
  top: "dpn43_conv3_split1"  # 0~2047
  top: "dpn43_conv3_split2"  # 2048~2175

  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn43_elewise"
  type: "Eltwise"

  bottom: "dpn42_elewise"
  bottom: "dpn43_conv3_split1"
  top: "dpn43_elewise"

  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn43_concat"
  type: "Concat"

  bottom: "dpn42_concat"
  bottom: "dpn43_conv3_split2"
  top: "dpn43_concat"
}


# -------------------------- Decoder -------------------------- #
# -------------------------- Stage #1
layer {
  name: "decode1_concat_input"
  type: "Concat"

  bottom: "dpn43_elewise"
  bottom: "dpn43_concat"
  top: "decode1_concat_input"
}

layer {
  name: "decode1_concat_bn"
  type: "BatchNorm"

  bottom: "decode1_concat_input"
  top: "decode1_concat_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "decode1_concat_scale"
  type: "Scale"

  bottom: "decode1_concat_bn"
  top: "decode1_concat_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode1_concat_relu"
  type: "ReLU"

  bottom: "decode1_concat_bn"
  top: "decode1_concat_bn"
}


layer {
  name: "decode1_conv1"
  type: "Convolution"

  bottom: "decode1_concat_bn"
  top: "decode1_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 512

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0
    # dilation: 1

    group: 4

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode1_conv1_bn"
  type: "BatchNorm"

  bottom: "decode1_conv1"
  top: "decode1_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode1_conv1_scale"
  type: "Scale"

  bottom: "decode1_conv1"
  top: "decode1_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode1_conv1_relu"
  type: "ReLU"

  bottom: "decode1_conv1"
  top: "decode1_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "decode1_conv1_shuffle"
  type: "ShuffleChannel"

  bottom: "decode1_conv1"
  top: "decode1_conv1_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "decode1_conv2"
  type: "ConvolutionDepthwise"

  bottom: "decode1_conv1_shuffle"
  top: "decode1_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 512

    bias_term: false
    kernel_size: 3
    stride: 1
    pad: 1

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode1_conv2_bn"
  type: "BatchNorm"

  bottom: "decode1_conv2"
  top: "decode1_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode1_conv2_scale"
  type: "Scale"

  bottom: "decode1_conv2"
  top: "decode1_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}

layer {
  name: "decode1_conv3"
  type: "Convolution"

  bottom: "decode1_conv2"
  top: "decode1_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 1024

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0

    group: 4

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}

# -------------------- SE Block Start
layer {
  name: "decode1_pool/gap"
  type: "Pooling"

  bottom: "decode1_conv3"
  top: "decode1_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "decode1_fc1/sqz"
  type: "InnerProduct"

  bottom: "decode1_pool/gap"
  top: "decode1_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 64       # 1024/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode1_relu/sqz"
  type: "ReLU"

  bottom: "decode1_fc1/sqz"
  top: "decode1_fc1/sqz"
}
layer {
  name: "decode1_fc2/exc"
  type: "InnerProduct"

  bottom: "decode1_fc1/sqz"
  top: "decode1_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 1024

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode1_sigm/gate"
  type: "Sigmoid"
  bottom: "decode1_fc2/exc"
  top: "decode1_fc2/exc"
}
layer {
  name: "decode1_scale/se"
  type: "Scale"

  bottom: "decode1_conv3"
  bottom: "decode1_fc2/exc"
  top: "decode1_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End

# ------------------------- Up sampling #1 1/32 -> 1/16
layer {
  name: "decode1_conv3_bn"
  type: "BatchNorm"

  bottom: "decode1_scale/se"
  top: "decode1_conv3_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "decode1_conv3_scale"
  type: "Scale"

  bottom: "decode1_conv3_bn"
  top: "decode1_conv3_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode1_conv3_relu"
  type: "ReLU"

  bottom: "decode1_conv3_bn"
  top: "decode1_conv3_bn"
}

layer {
    name: "decode1_deconv"
    type: "Deconvolution"

    bottom: "decode1_conv3_bn"   # (1024 12 16)
    top: "decode1_deconv"      # (128 96 128)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 1024
        group: 1024

        kernel_size: 4
        stride: 2
        pad: 1

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}

# ----------------------- Skip #1 1/16
layer {
  name: "decode1_elewise"
  type: "Eltwise"

  bottom: "decode1_deconv"
  bottom: "dpn40_elewise"
  top: "decode1_elewise"

  eltwise_param {
    operation: SUM
  }
}


# -------------------------- Stage #2  1/16 -> 1/32
layer {
  name: "skip1_bn"
  type: "BatchNorm"

  bottom: "decode1_elewise"
  top: "skip1_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "skip1_scale"
  type: "Scale"

  bottom: "skip1_bn"
  top: "skip1_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "skip1_relu"
  type: "ReLU"

  bottom: "skip1_bn"
  top: "skip1_bn"
}


layer {
  name: "decode2_conv1"
  type: "Convolution"

  bottom: "skip1_bn"
  top: "decode2_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 256

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0
    # dilation: 1

    group: 4

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode2_conv1_bn"
  type: "BatchNorm"

  bottom: "decode2_conv1"
  top: "decode2_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode2_conv1_scale"
  type: "Scale"

  bottom: "decode2_conv1"
  top: "decode2_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode2_conv1_relu"
  type: "ReLU"

  bottom: "decode2_conv1"
  top: "decode2_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "decode2_conv1_shuffle"
  type: "ShuffleChannel"

  bottom: "decode2_conv1"
  top: "decode2_conv1_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "decode2_conv2"
  type: "ConvolutionDepthwise"

  bottom: "decode2_conv1_shuffle"
  top: "decode2_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 256

    bias_term: false
    kernel_size: 3
    stride: 1
    pad: 1

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode2_conv2_bn"
  type: "BatchNorm"

  bottom: "decode2_conv2"
  top: "decode2_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode2_conv2_scale"
  type: "Scale"

  bottom: "decode2_conv2"
  top: "decode2_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}

layer {
  name: "decode2_conv3"
  type: "Convolution"

  bottom: "decode2_conv2"
  top: "decode2_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 512

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0

    group: 4

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}

# -------------------- SE Block Start
layer {
  name: "decode2_pool/gap"
  type: "Pooling"

  bottom: "decode2_conv3"
  top: "decode2_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "decode2_fc1/sqz"
  type: "InnerProduct"

  bottom: "decode2_pool/gap"
  top: "decode2_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 32       # 512/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode2_relu/sqz"
  type: "ReLU"

  bottom: "decode2_fc1/sqz"
  top: "decode2_fc1/sqz"
}
layer {
  name: "decode2_fc2/exc"
  type: "InnerProduct"

  bottom: "decode2_fc1/sqz"
  top: "decode2_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 512

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode2_sigm/gate"
  type: "Sigmoid"
  bottom: "decode2_fc2/exc"
  top: "decode2_fc2/exc"
}
layer {
  name: "decode2_scale/se"
  type: "Scale"

  bottom: "decode2_conv3"
  bottom: "decode2_fc2/exc"
  top: "decode2_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


# ------------------------- Up sampling #2 1/16 -> 1/8
layer {
  name: "decode2_conv3_bn"
  type: "BatchNorm"

  bottom: "decode2_scale/se"
  top: "decode2_conv3_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "decode2_conv3_scale"
  type: "Scale"

  bottom: "decode2_conv3_bn"
  top: "decode2_conv3_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode2_conv3_relu"
  type: "ReLU"

  bottom: "decode2_conv3_bn"
  top: "decode2_conv3_bn"
}

layer {
    name: "decode2_deconv"
    type: "Deconvolution"

    bottom: "decode2_conv3_bn"   # (512 24 32)
    top: "decode2_deconv"        # (512 48 64)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 512
        group: 512

        kernel_size: 4
        stride: 2
        pad: 1

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}

# ----------------------- Skip #2 1/8
layer {
  name: "decode2_elewise"
  type: "Eltwise"

  bottom: "decode2_deconv"
  bottom: "dpn12_elewise"
  top: "decode2_elewise"

  eltwise_param {
    operation: SUM
  }
}


# -------------------------- Stage #3  1/8 -> 1/4
layer {
  name: "skip2_bn"
  type: "BatchNorm"

  bottom: "decode2_elewise"
  top: "skip2_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "skip2_scale"
  type: "Scale"

  bottom: "skip2_bn"
  top: "skip2_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "skip2_relu"
  type: "ReLU"

  bottom: "skip2_bn"
  top: "skip2_bn"
}


layer {
  name: "decode3_conv1"
  type: "Convolution"

  bottom: "skip2_bn"
  top: "decode3_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 128

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0
    # dilation: 1

    group: 4

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode3_conv1_bn"
  type: "BatchNorm"

  bottom: "decode3_conv1"
  top: "decode3_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode3_conv1_scale"
  type: "Scale"

  bottom: "decode3_conv1"
  top: "decode3_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode3_conv1_relu"
  type: "ReLU"

  bottom: "decode3_conv1"
  top: "decode3_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "decode3_conv1_shuffle"
  type: "ShuffleChannel"

  bottom: "decode3_conv1"
  top: "decode3_conv1_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "decode3_conv2"
  type: "ConvolutionDepthwise"

  bottom: "decode3_conv1_shuffle"
  top: "decode3_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 128

    bias_term: false
    kernel_size: 3
    stride: 1
    pad: 1

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode3_conv2_bn"
  type: "BatchNorm"

  bottom: "decode3_conv2"
  top: "decode3_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode3_conv2_scale"
  type: "Scale"

  bottom: "decode3_conv2"
  top: "decode3_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}

layer {
  name: "decode3_conv3"
  type: "Convolution"

  bottom: "decode3_conv2"
  top: "decode3_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 256

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0

    group: 4

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}

# -------------------- SE Block Start
layer {
  name: "decode3_pool/gap"
  type: "Pooling"

  bottom: "decode3_conv3"
  top: "decode3_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "decode3_fc1/sqz"
  type: "InnerProduct"

  bottom: "decode3_pool/gap"
  top: "decode3_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 16       # 256/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode3_relu/sqz"
  type: "ReLU"

  bottom: "decode3_fc1/sqz"
  top: "decode3_fc1/sqz"
}
layer {
  name: "decode3_fc2/exc"
  type: "InnerProduct"

  bottom: "decode3_fc1/sqz"
  top: "decode3_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 256

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode3_sigm/gate"
  type: "Sigmoid"
  bottom: "decode3_fc2/exc"
  top: "decode3_fc2/exc"
}
layer {
  name: "decode3_scale/se"
  type: "Scale"

  bottom: "decode3_conv3"
  bottom: "decode3_fc2/exc"
  top: "decode3_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


# ------------------------- Up sampling #3 1/8 -> 1/4
layer {
  name: "decode3_conv3_bn"
  type: "BatchNorm"

  bottom: "decode3_scale/se"
  top: "decode3_conv3_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "decode3_conv3_scale"
  type: "Scale"

  bottom: "decode3_conv3_bn"
  top: "decode3_conv3_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode3_conv3_relu"
  type: "ReLU"

  bottom: "decode3_conv3_bn"
  top: "decode3_conv3_bn"
}

layer {
    name: "decode3_deconv"
    type: "Deconvolution"

    bottom: "decode3_conv3_bn"   # (256 48 64)
    top: "decode3_deconv"        # (512 96 32)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 256
        group: 256

        kernel_size: 4
        stride: 2
        pad: 1

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}

# ----------------------- Skip #3 1/4
layer {
  name: "decode3_elewise"
  type: "Eltwise"

  bottom: "decode3_deconv"
  bottom: "dpn4_elewise"
  top: "decode3_elewise"

  eltwise_param {
    operation: SUM
  }
}


# -------------------------- Stage #4  1/4 -> 1/2
layer {
  name: "skip3_bn"
  type: "BatchNorm"

  bottom: "decode3_elewise"
  top: "skip3_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "skip3_scale"
  type: "Scale"

  bottom: "skip3_bn"
  top: "skip3_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "skip3_relu"
  type: "ReLU"

  bottom: "skip3_bn"
  top: "skip3_bn"
}


layer {
  name: "decode4_conv1"
  type: "Convolution"

  bottom: "skip3_bn"
  top: "decode4_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 64

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0
    # dilation: 1

    group: 4

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode4_conv1_bn"
  type: "BatchNorm"

  bottom: "decode4_conv1"
  top: "decode4_conv1"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode4_conv1_scale"
  type: "Scale"

  bottom: "decode4_conv1"
  top: "decode4_conv1"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode4_conv1_relu"
  type: "ReLU"

  bottom: "decode4_conv1"
  top: "decode4_conv1"
}

# ------------------------- Channel Shuffle Start
layer {
  name: "decode4_conv1_shuffle"
  type: "ShuffleChannel"

  bottom: "decode4_conv1"
  top: "decode4_conv1_shuffle"

  shuffle_channel_param {
    group: 4
  }
}
# ------------------------- Channel Shuffle End

layer {
  name: "decode4_conv2"
  type: "ConvolutionDepthwise"

  bottom: "decode4_conv1_shuffle"
  top: "decode4_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 64

    bias_term: false
    kernel_size: 3
    stride: 1
    pad: 1

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "decode4_conv2_bn"
  type: "BatchNorm"

  bottom: "decode4_conv2"
  top: "decode4_conv2"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "decode4_conv2_scale"
  type: "Scale"

  bottom: "decode4_conv2"
  top: "decode4_conv2"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}

layer {
  name: "decode4_conv3"
  type: "Convolution"

  bottom: "decode4_conv2"
  top: "decode4_conv3"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }

  convolution_param {
    num_output: 128

    bias_term: false

    kernel_size: 1
    stride: 1
    pad: 0

    group: 4

    dilation: 1

    weight_filler {
      type: "msra"
    }
  }
}

# -------------------- SE Block Start
layer {
  name: "decode4_pool/gap"
  type: "Pooling"

  bottom: "decode4_conv3"
  top: "decode4_pool/gap"

  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "decode4_fc1/sqz"
  type: "InnerProduct"

  bottom: "decode4_pool/gap"
  top: "decode4_fc1/sqz"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  inner_product_param {
    num_output: 8       # 128/16

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode4_relu/sqz"
  type: "ReLU"

  bottom: "decode4_fc1/sqz"
  top: "decode4_fc1/sqz"
}
layer {
  name: "decode4_fc2/exc"
  type: "InnerProduct"

  bottom: "decode4_fc1/sqz"
  top: "decode4_fc2/exc"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  inner_product_param {
    num_output: 128

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "decode4_sigm/gate"
  type: "Sigmoid"
  bottom: "decode4_fc2/exc"
  top: "decode4_fc2/exc"
}
layer {
  name: "decode4_scale/se"
  type: "Scale"

  bottom: "decode4_conv3"
  bottom: "decode4_fc2/exc"
  top: "decode4_scale/se"

  scale_param {
    axis: 0
    bias_term: false
  }
}
# ------------------------- SE Block End


# ------------------------- Up sampling #4 1/4 -> 1/2
layer {
  name: "decode4_conv3_bn"
  type: "BatchNorm"

  bottom: "decode4_scale/se"
  top: "decode4_conv3_bn"

  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }

  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "decode4_conv3_scale"
  type: "Scale"

  bottom: "decode4_conv3_bn"
  top: "decode4_conv3_bn"

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

  scale_param {
    bias_term: true
  }
}
layer {
  name: "decode4_conv3_relu"
  type: "ReLU"

  bottom: "decode4_conv3_bn"
  top: "decode4_conv3_bn"
}

layer {
    name: "decode4_deconv"
    type: "Deconvolution"

    bottom: "decode4_conv3_bn"   # (128 96 128)
    top: "decode4_deconv"        # (128 192 256)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 128
        group: 128

        kernel_size: 8
        stride: 4
        pad: 2

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}


# --------------------------- Stage #2 Out ---------------------------- #
layer {
    name: "decode2_conv_score"
    type: "Convolution"

    bottom: "decode2_conv3_bn"  # (512 24 32)
    top: "decode2_conv_score"   # (19 24 32)

    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }

    convolution_param {
        num_output: 19

        pad: 0
        stride: 1
        kernel_size: 1

        weight_filler {
            type: "msra"
        }
        bias_filler {
            type: "constant" # initialize the biases to zero (0)
            value: 0
        }
    }
}

# --------------------------- Stage #3 Out ---------------------------- #
layer {
    name: "decode3_conv_score"
    type: "Convolution"

    bottom: "decode3_conv3_bn"  # (256 48 64)
    top: "decode3_conv_score"   # (19 48 64)

    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }

    convolution_param {
        num_output: 19

        pad: 0
        stride: 1
        kernel_size: 1

        weight_filler {
            type: "msra"
        }
        bias_filler {
            type: "constant" # initialize the biases to zero (0)
            value: 0
        }
    }
}

# --------------------------- Stage #4 Out ---------------------------- #
layer {
    name: "decode4_conv_score"
    type: "Convolution"

    bottom: "decode4_conv3_bn"  # (128 96 128)
    top: "decode4_conv_score"   # (19 96 128)

  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }

    convolution_param {
        num_output: 19

        pad: 0
        stride: 1
        kernel_size: 1

    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant" # initialize the biases to zero (0)
      value: 0
    }
    }
}

# --------------------------- Mask Out ------------------------ #
layer {
    name: "decode5_conv1"
    type: "Convolution"

    bottom: "decode4_deconv"  # (128 384 512)
    top: "decode5_conv1"         # (64 384 512)

    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }

    convolution_param {
        num_output: 64

        pad: 1
        stride: 1
        kernel_size: 3

        dilation: 1

        weight_filler {
            type: "msra"
        }
        bias_term: false
    }
}
layer {
    name: "decode5_conv1_bn"
    type: "BatchNorm"

    bottom: "decode5_conv1"
    top: "decode5_conv1"

    param {
        lr_mult: 0
    }
    param {
        lr_mult: 0
    }
    param {
        lr_mult: 0
    }

    batch_norm_param {
        use_global_stats: false
    }
}
layer {
    name: "decode5_conv1_scale"
    type: "Scale"

    bottom: "decode5_conv1"
    top: "decode5_conv1"

    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }

    scale_param {
        bias_term: true
    }
}
layer {
    name: "decode5_conv1_relu"
    type: "ReLU"

    bottom: "decode5_conv1"
    top: "decode5_conv1"
}

layer {
    name: "decode5_conv_score"
    type: "Convolution"

    bottom: "decode5_conv1"    # (64 384 512)
    top: "decode5_conv_score"  # (19 384 512)

    param {
        lr_mult: 1.0
        decay_mult: 1.0
    }
    param {
        lr_mult: 2.0
        decay_mult: 0.0
    }

    convolution_param {
        num_output: 19

        pad: 0
        stride: 1
        kernel_size: 1

        weight_filler {
            type: "msra"
        }
        bias_filler {
            type: "constant" # initialize the biases to zero (0)
            value: 0
        }
    }
}


# --------------------------- Output Mask Sum ------------------------------ #
layer {
    name: "decode2_deconv_score"
    type: "Deconvolution"

    bottom: "decode2_conv_score"   # (19 24 32)
    top: "decode2_deconv_score"    # (19 384 512)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 19
        group: 19

        kernel_size: 32
        stride: 16
        pad: 8

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}

layer {
    name: "decode3_deconv_score"
    type: "Deconvolution"

    bottom: "decode3_conv_score"   # (19 48 64)
    top: "decode3_deconv_score"    # (19 384 512)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 19
        group: 19

        kernel_size: 16
        stride: 8
        pad: 4

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}

layer {
    name: "decode4_deconv_score"
    type: "Deconvolution"

    bottom: "decode4_conv_score"   # (19 96 128)
    top: "decode4_deconv_score"    # (19 384 512)

    param {
      lr_mult: 0.0
      decay_mult: 0.0
    }

    convolution_param {
        num_output: 19
        group: 19

        kernel_size: 8
        stride: 4
        pad: 2

        dilation: 1

        weight_filler {
            type: "bilinear"
        }
        bias_term: false
    }
}

layer {
    name: "decode_score"
    type: "Eltwise"

    bottom: "decode2_deconv_score"
    bottom: "decode3_deconv_score"
    bottom: "decode4_deconv_score"
    bottom: "decode5_conv_score"
    top: "decode_score"

    eltwise_param {
        operation: SUM
    }
}

# --------------------------- Main Losses ---------------------------- #
layer {
  name: "prob"
  type: "Softmax"

  bottom: "decode_score"
  top: "prob"
}


