input: "data"
input_shape {
  dim: 1
  dim: 3
  dim: 224
  dim: 224
}

#################### conv1 ####################
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    kernel_size: 7
    pad: 3
    stride: 2
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
#################### dpn1 ####################
layer {
  name: "dpn1_match_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "dpn1_match_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_match_scale"
  type: "Scale"
  bottom: "dpn1_match_bn"
  top: "dpn1_match_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_match_relu"
  type: "ReLU"
  bottom: "dpn1_match_bn"
  top: "dpn1_match_bn"
}
layer {
  name: "dpn1_match_conv"
  type: "Convolution"
  bottom: "dpn1_match_bn"
  top: "dpn1_match_conv"
  convolution_param {
    num_output: 288
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn1_match_conv_Slice"
  type: "Slice"
  bottom: "dpn1_match_conv"
  top: "dpn1_match_conv_split1"  # 0~255
  top: "dpn1_match_conv_split2"  # 256~288
  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn1_bn"
  type: "BatchNorm"
  bottom: "pool1"
  top: "dpn1_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_scale"
  type: "Scale"
  bottom: "dpn1_bn"
  top: "dpn1_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_relu"
  type: "ReLU"
  bottom: "dpn1_bn"
  top: "dpn1_bn"
}
layer {
  name: "dpn1_conv1"
  type: "Convolution"
  bottom: "dpn1_bn"
  top: "dpn1_conv1"
  convolution_param {
    num_output: 96
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn1_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn1_conv1"
  top: "dpn1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_conv1_scale"
  type: "Scale"
  bottom: "dpn1_conv1"
  top: "dpn1_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_conv1_relu"
  type: "ReLU"
  bottom: "dpn1_conv1"
  top: "dpn1_conv1"
}
layer {
  name: "dpn1_conv2"
  type: "Convolution"
  bottom: "dpn1_conv1"
  top: "dpn1_conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn1_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn1_conv2"
  top: "dpn1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn1_conv2_scale"
  type: "Scale"
  bottom: "dpn1_conv2"
  top: "dpn1_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn1_conv2_relu"
  type: "ReLU"
  bottom: "dpn1_conv2"
  top: "dpn1_conv2"
}
layer {
  name: "dpn1_conv3"
  type: "Convolution"
  bottom: "dpn1_conv2"
  top: "dpn1_conv3"
  convolution_param {
    num_output: 272
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn1_conv3_Slice"
  type: "Slice"
  bottom: "dpn1_conv3"
  top: "dpn1_conv3_split1"  # 0~255
  top: "dpn1_conv3_split2"  # 256~272
  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn1_elewise"
  type: "Eltwise"
  bottom: "dpn1_match_conv_split1"
  bottom: "dpn1_conv3_split1"
  top: "dpn1_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn1_concat"
  type: "Concat"
  bottom: "dpn1_match_conv_split2"
  bottom: "dpn1_conv3_split2"
  top: "dpn1_concat"
}
#################### dpn2 ####################
layer {
  name: "dpn2_concat_input"
  type: "Concat"
  bottom: "dpn1_elewise"
  bottom: "dpn1_concat"
  top: "dpn2_concat_input"
}
layer {
  name: "dpn2_bn"
  type: "BatchNorm"
  bottom: "dpn2_concat_input"
  top: "dpn2_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn2_scale"
  type: "Scale"
  bottom: "dpn2_bn"
  top: "dpn2_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn2_relu"
  type: "ReLU"
  bottom: "dpn2_bn"
  top: "dpn2_bn"
}
layer {
  name: "dpn2_conv1"
  type: "Convolution"
  bottom: "dpn2_bn"
  top: "dpn2_conv1"
  convolution_param {
    num_output: 96
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn2_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn2_conv1"
  top: "dpn2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn2_conv1_scale"
  type: "Scale"
  bottom: "dpn2_conv1"
  top: "dpn2_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn2_conv1_relu"
  type: "ReLU"
  bottom: "dpn2_conv1"
  top: "dpn2_conv1"
}
layer {
  name: "dpn2_conv2"
  type: "Convolution"
  bottom: "dpn2_conv1"
  top: "dpn2_conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn2_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn2_conv2"
  top: "dpn2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn2_conv2_scale"
  type: "Scale"
  bottom: "dpn2_conv2"
  top: "dpn2_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn2_conv2_relu"
  type: "ReLU"
  bottom: "dpn2_conv2"
  top: "dpn2_conv2"
}
layer {
  name: "dpn2_conv3"
  type: "Convolution"
  bottom: "dpn2_conv2"
  top: "dpn2_conv3"
  convolution_param {
    num_output: 272
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn2_conv3_Slice"
  type: "Slice"
  bottom: "dpn2_conv3"
  top: "dpn2_conv3_split1"  # 0~255
  top: "dpn2_conv3_split2"  # 256~272
  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn2_elewise"
  type: "Eltwise"
  bottom: "dpn1_elewise"
  bottom: "dpn2_conv3_split1"
  top: "dpn2_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn2_concat"
  type: "Concat"
  bottom: "dpn1_concat"
  bottom: "dpn2_conv3_split2"
  top: "dpn2_concat"
}
#################### dpn3 ####################
layer {
  name: "dpn3_concat_input"
  type: "Concat"
  bottom: "dpn2_elewise"
  bottom: "dpn2_concat"
  top: "dpn3_concat_input"
}
layer {
  name: "dpn3_bn"
  type: "BatchNorm"
  bottom: "dpn3_concat_input"
  top: "dpn3_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn3_scale"
  type: "Scale"
  bottom: "dpn3_bn"
  top: "dpn3_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn3_relu"
  type: "ReLU"
  bottom: "dpn3_bn"
  top: "dpn3_bn"
}
layer {
  name: "dpn3_conv1"
  type: "Convolution"
  bottom: "dpn3_bn"
  top: "dpn3_conv1"
  convolution_param {
    num_output: 96
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn3_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn3_conv1"
  top: "dpn3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn3_conv1_scale"
  type: "Scale"
  bottom: "dpn3_conv1"
  top: "dpn3_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn3_conv1_relu"
  type: "ReLU"
  bottom: "dpn3_conv1"
  top: "dpn3_conv1"
}
layer {
  name: "dpn3_conv2"
  type: "Convolution"
  bottom: "dpn3_conv1"
  top: "dpn3_conv2"
  convolution_param {
    num_output: 96
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn3_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn3_conv2"
  top: "dpn3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn3_conv2_scale"
  type: "Scale"
  bottom: "dpn3_conv2"
  top: "dpn3_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn3_conv2_relu"
  type: "ReLU"
  bottom: "dpn3_conv2"
  top: "dpn3_conv2"
}
layer {
  name: "dpn3_conv3"
  type: "Convolution"
  bottom: "dpn3_conv2"
  top: "dpn3_conv3"
  convolution_param {
    num_output: 272
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn3_conv3_Slice"
  type: "Slice"
  bottom: "dpn3_conv3"
  top: "dpn3_conv3_split1"  # 0~255
  top: "dpn3_conv3_split2"  # 256~272
  slice_param {
    axis: 1
    slice_point: 256
  }
}
layer {
  name: "dpn3_elewise"
  type: "Eltwise"
  bottom: "dpn2_elewise"
  bottom: "dpn3_conv3_split1"
  top: "dpn3_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn3_concat"
  type: "Concat"
  bottom: "dpn2_concat"
  bottom: "dpn3_conv3_split2"
  top: "dpn3_concat"
}
#################### dpn4 ####################
layer {
  name: "dpn4_concat_input"
  type: "Concat"
  bottom: "dpn3_elewise"
  bottom: "dpn3_concat"
  top: "dpn4_concat_input"
}
layer {
  name: "dpn4_match_bn"
  type: "BatchNorm"
  bottom: "dpn4_concat_input"
  top: "dpn4_match_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_match_scale"
  type: "Scale"
  bottom: "dpn4_match_bn"
  top: "dpn4_match_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_match_relu"
  type: "ReLU"
  bottom: "dpn4_match_bn"
  top: "dpn4_match_bn"
}
layer {
  name: "dpn4_match_conv"
  type: "Convolution"
  bottom: "dpn4_match_bn"
  top: "dpn4_match_conv"
  convolution_param {
    num_output: 576
    kernel_size: 1
    pad: 0
    stride: 2
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn4_match_conv_Slice"
  type: "Slice"
  bottom: "dpn4_match_conv"
  top: "dpn4_match_conv_split1"  # 0~511
  top: "dpn4_match_conv_split2"  # 512~576
  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn4_bn"
  type: "BatchNorm"
  bottom: "dpn4_concat_input"
  top: "dpn4_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_scale"
  type: "Scale"
  bottom: "dpn4_bn"
  top: "dpn4_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_relu"
  type: "ReLU"
  bottom: "dpn4_bn"
  top: "dpn4_bn"
}
layer {
  name: "dpn4_conv1"
  type: "Convolution"
  bottom: "dpn4_bn"
  top: "dpn4_conv1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn4_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn4_conv1"
  top: "dpn4_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_conv1_scale"
  type: "Scale"
  bottom: "dpn4_conv1"
  top: "dpn4_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_conv1_relu"
  type: "ReLU"
  bottom: "dpn4_conv1"
  top: "dpn4_conv1"
}
layer {
  name: "dpn4_conv2"
  type: "Convolution"
  bottom: "dpn4_conv1"
  top: "dpn4_conv2"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    stride: 2
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn4_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn4_conv2"
  top: "dpn4_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn4_conv2_scale"
  type: "Scale"
  bottom: "dpn4_conv2"
  top: "dpn4_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn4_conv2_relu"
  type: "ReLU"
  bottom: "dpn4_conv2"
  top: "dpn4_conv2"
}
layer {
  name: "dpn4_conv3"
  type: "Convolution"
  bottom: "dpn4_conv2"
  top: "dpn4_conv3"
  convolution_param {
    num_output: 544
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn4_conv3_Slice"
  type: "Slice"
  bottom: "dpn4_conv3"
  top: "dpn4_conv3_split1"  # 0~511
  top: "dpn4_conv3_split2"  # 511~544
  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn4_elewise"
  type: "Eltwise"
  bottom: "dpn4_match_conv_split1"
  bottom: "dpn4_conv3_split1"
  top: "dpn4_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn4_concat"
  type: "Concat"
  bottom: "dpn4_match_conv_split2"
  bottom: "dpn4_conv3_split2"
  top: "dpn4_concat"
}
#################### dpn5 ####################
layer {
  name: "dpn5_concat_input"
  type: "Concat"
  bottom: "dpn4_elewise"
  bottom: "dpn4_concat"
  top: "dpn5_concat_input"
}
layer {
  name: "dpn5_bn"
  type: "BatchNorm"
  bottom: "dpn5_concat_input"
  top: "dpn5_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_scale"
  type: "Scale"
  bottom: "dpn5_bn"
  top: "dpn5_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_relu"
  type: "ReLU"
  bottom: "dpn5_bn"
  top: "dpn5_bn"
}
layer {
  name: "dpn5_conv1"
  type: "Convolution"
  bottom: "dpn5_bn"
  top: "dpn5_conv1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn5_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn5_conv1"
  top: "dpn5_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_conv1_scale"
  type: "Scale"
  bottom: "dpn5_conv1"
  top: "dpn5_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_conv1_relu"
  type: "ReLU"
  bottom: "dpn5_conv1"
  top: "dpn5_conv1"
}
layer {
  name: "dpn5_conv2"
  type: "Convolution"
  bottom: "dpn5_conv1"
  top: "dpn5_conv2"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn5_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn5_conv2"
  top: "dpn5_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn5_conv2_scale"
  type: "Scale"
  bottom: "dpn5_conv2"
  top: "dpn5_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn5_conv2_relu"
  type: "ReLU"
  bottom: "dpn5_conv2"
  top: "dpn5_conv2"
}
layer {
  name: "dpn5_conv3"
  type: "Convolution"
  bottom: "dpn5_conv2"
  top: "dpn5_conv3"
  convolution_param {
    num_output: 544
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn5_conv3_Slice"
  type: "Slice"
  bottom: "dpn5_conv3"
  top: "dpn5_conv3_split1"  # 0~511
  top: "dpn5_conv3_split2"  # 512~544
  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn5_elewise"
  type: "Eltwise"
  bottom: "dpn4_elewise"
  bottom: "dpn5_conv3_split1"
  top: "dpn5_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn5_concat"
  type: "Concat"
  bottom: "dpn4_concat"
  bottom: "dpn5_conv3_split2"
  top: "dpn5_concat"
}
#################### dpn6 ####################
layer {
  name: "dpn6_concat_input"
  type: "Concat"
  bottom: "dpn5_elewise"
  bottom: "dpn5_concat"
  top: "dpn6_concat_input"
}
layer {
  name: "dpn6_bn"
  type: "BatchNorm"
  bottom: "dpn6_concat_input"
  top: "dpn6_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn6_scale"
  type: "Scale"
  bottom: "dpn6_bn"
  top: "dpn6_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn6_relu"
  type: "ReLU"
  bottom: "dpn6_bn"
  top: "dpn6_bn"
}
layer {
  name: "dpn6_conv1"
  type: "Convolution"
  bottom: "dpn6_bn"
  top: "dpn6_conv1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn6_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn6_conv1"
  top: "dpn6_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn6_conv1_scale"
  type: "Scale"
  bottom: "dpn6_conv1"
  top: "dpn6_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn6_conv1_relu"
  type: "ReLU"
  bottom: "dpn6_conv1"
  top: "dpn6_conv1"
}
layer {
  name: "dpn6_conv2"
  type: "Convolution"
  bottom: "dpn6_conv1"
  top: "dpn6_conv2"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn6_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn6_conv2"
  top: "dpn6_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn6_conv2_scale"
  type: "Scale"
  bottom: "dpn6_conv2"
  top: "dpn6_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn6_conv2_relu"
  type: "ReLU"
  bottom: "dpn6_conv2"
  top: "dpn6_conv2"
}
layer {
  name: "dpn6_conv3"
  type: "Convolution"
  bottom: "dpn6_conv2"
  top: "dpn6_conv3"
  convolution_param {
	num_output: 544
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn6_conv3_Slice"
  type: "Slice"
  bottom: "dpn6_conv3"
  top: "dpn6_conv3_split1"  # 0~511
  top: "dpn6_conv3_split2"  # 512~544
  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn6_elewise"
  type: "Eltwise"
  bottom: "dpn5_elewise"
  bottom: "dpn6_conv3_split1"
  top: "dpn6_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn6_concat"
  type: "Concat"
  bottom: "dpn5_concat"
  bottom: "dpn6_conv3_split2"
  top: "dpn6_concat"
}
#################### dpn7 ####################
layer {
  name: "dpn7_concat_input"
  type: "Concat"
  bottom: "dpn6_elewise"
  bottom: "dpn6_concat"
  top: "dpn7_concat_input"
}
layer {
  name: "dpn7_bn"
  type: "BatchNorm"
  bottom: "dpn7_concat_input"
  top: "dpn7_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn7_scale"
  type: "Scale"
  bottom: "dpn7_bn"
  top: "dpn7_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn7_relu"
  type: "ReLU"
  bottom: "dpn7_bn"
  top: "dpn7_bn"
}
layer {
  name: "dpn7_conv1"
  type: "Convolution"
  bottom: "dpn7_bn"
  top: "dpn7_conv1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn7_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn7_conv1"
  top: "dpn7_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn7_conv1_scale"
  type: "Scale"
  bottom: "dpn7_conv1"
  top: "dpn7_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn7_conv1_relu"
  type: "ReLU"
  bottom: "dpn7_conv1"
  top: "dpn7_conv1"
}
layer {
  name: "dpn7_conv2"
  type: "Convolution"
  bottom: "dpn7_conv1"
  top: "dpn7_conv2"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn7_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn7_conv2"
  top: "dpn7_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn7_conv2_scale"
  type: "Scale"
  bottom: "dpn7_conv2"
  top: "dpn7_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn7_conv2_relu"
  type: "ReLU"
  bottom: "dpn7_conv2"
  top: "dpn7_conv2"
}
layer {
  name: "dpn7_conv3"
  type: "Convolution"
  bottom: "dpn7_conv2"
  top: "dpn7_conv3"
  convolution_param {
    num_output: 544
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn7_conv3_Slice"
  type: "Slice"
  bottom: "dpn7_conv3"
  top: "dpn7_conv3_split1"  # 0~511
  top: "dpn7_conv3_split2"  # 512~544
  slice_param {
    axis: 1
    slice_point: 512
  }
}
layer {
  name: "dpn7_elewise"
  type: "Eltwise"
  bottom: "dpn6_elewise"
  bottom: "dpn7_conv3_split1"
  top: "dpn7_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn7_concat"
  type: "Concat"
  bottom: "dpn6_concat"
  bottom: "dpn7_conv3_split2"
  top: "dpn7_concat"
}
#################### dpn8 ####################
layer {
  name: "dpn8_concat_input"
  type: "Concat"
  bottom: "dpn7_elewise"
  bottom: "dpn7_concat"
  top: "dpn8_concat_input"
}
layer {
  name: "dpn8_match_bn"
  type: "BatchNorm"
  bottom: "dpn8_concat_input"
  top: "dpn8_match_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_match_scale"
  type: "Scale"
  bottom: "dpn8_match_bn"
  top: "dpn8_match_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_match_relu"
  type: "ReLU"
  bottom: "dpn8_match_bn"
  top: "dpn8_match_bn"
}
layer {
  name: "dpn8_match_conv"
  type: "Convolution"
  bottom: "dpn8_match_bn"
  top: "dpn8_match_conv"
  convolution_param {
    num_output: 1072
    kernel_size: 1
    pad: 0
    stride: 2
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn8_match_conv_Slice"
  type: "Slice"
  bottom: "dpn8_match_conv"
  top: "dpn8_match_conv_split1"  # 0~1023
  top: "dpn8_match_conv_split2"  # 1024~1072
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn8_bn"
  type: "BatchNorm"
  bottom: "dpn8_concat_input"
  top: "dpn8_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_scale"
  type: "Scale"
  bottom: "dpn8_bn"
  top: "dpn8_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_relu"
  type: "ReLU"
  bottom: "dpn8_bn"
  top: "dpn8_bn"
}
layer {
  name: "dpn8_conv1"
  type: "Convolution"
  bottom: "dpn8_bn"
  top: "dpn8_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn8_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn8_conv1"
  top: "dpn8_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_conv1_scale"
  type: "Scale"
  bottom: "dpn8_conv1"
  top: "dpn8_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_conv1_relu"
  type: "ReLU"
  bottom: "dpn8_conv1"
  top: "dpn8_conv1"
}
layer {
  name: "dpn8_conv2"
  type: "Convolution"
  bottom: "dpn8_conv1"
  top: "dpn8_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 2
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn8_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn8_conv2"
  top: "dpn8_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn8_conv2_scale"
  type: "Scale"
  bottom: "dpn8_conv2"
  top: "dpn8_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn8_conv2_relu"
  type: "ReLU"
  bottom: "dpn8_conv2"
  top: "dpn8_conv2"
}
layer {
  name: "dpn8_conv3"
  type: "Convolution"
  bottom: "dpn8_conv2"
  top: "dpn8_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn8_conv3_Slice"
  type: "Slice"
  bottom: "dpn8_conv3"
  top: "dpn8_conv3_split1"  # 0~1023
  top: "dpn8_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn8_elewise"
  type: "Eltwise"
  bottom: "dpn8_match_conv_split1"
  bottom: "dpn8_conv3_split1"
  top: "dpn8_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn8_concat"
  type: "Concat"
  bottom: "dpn8_match_conv_split2"
  bottom: "dpn8_conv3_split2"
  top: "dpn8_concat"
}
#################### dpn9 ####################
layer {
  name: "dpn9_concat_input"
  type: "Concat"
  bottom: "dpn8_elewise"
  bottom: "dpn8_concat"
  top: "dpn9_concat_input"
}
layer {
  name: "dpn9_bn"
  type: "BatchNorm"
  bottom: "dpn9_concat_input"
  top: "dpn9_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn9_scale"
  type: "Scale"
  bottom: "dpn9_bn"
  top: "dpn9_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn9_relu"
  type: "ReLU"
  bottom: "dpn9_bn"
  top: "dpn9_bn"
}
layer {
  name: "dpn9_conv1"
  type: "Convolution"
  bottom: "dpn9_bn"
  top: "dpn9_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn9_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn9_conv1"
  top: "dpn9_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn9_conv1_scale"
  type: "Scale"
  bottom: "dpn9_conv1"
  top: "dpn9_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn9_conv1_relu"
  type: "ReLU"
  bottom: "dpn9_conv1"
  top: "dpn9_conv1"
}
layer {
  name: "dpn9_conv2"
  type: "Convolution"
  bottom: "dpn9_conv1"
  top: "dpn9_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn9_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn9_conv2"
  top: "dpn9_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn9_conv2_scale"
  type: "Scale"
  bottom: "dpn9_conv2"
  top: "dpn9_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn9_conv2_relu"
  type: "ReLU"
  bottom: "dpn9_conv2"
  top: "dpn9_conv2"
}
layer {
  name: "dpn9_conv3"
  type: "Convolution"
  bottom: "dpn9_conv2"
  top: "dpn9_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn9_conv3_Slice"
  type: "Slice"
  bottom: "dpn9_conv3"
  top: "dpn9_conv3_split1"  # 0~1023
  top: "dpn9_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn9_elewise"
  type: "Eltwise"
  bottom: "dpn8_elewise"
  bottom: "dpn9_conv3_split1"
  top: "dpn9_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn9_concat"
  type: "Concat"
  bottom: "dpn8_concat"
  bottom: "dpn9_conv3_split2"
  top: "dpn9_concat"
}
#################### dpn10 ####################
layer {
  name: "dpn10_concat_input"
  type: "Concat"
  bottom: "dpn9_elewise"
  bottom: "dpn9_concat"
  top: "dpn10_concat_input"
}
layer {
  name: "dpn10_bn"
  type: "BatchNorm"
  bottom: "dpn10_concat_input"
  top: "dpn10_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn10_scale"
  type: "Scale"
  bottom: "dpn10_bn"
  top: "dpn10_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn10_relu"
  type: "ReLU"
  bottom: "dpn10_bn"
  top: "dpn10_bn"
}
layer {
  name: "dpn10_conv1"
  type: "Convolution"
  bottom: "dpn10_bn"
  top: "dpn10_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn10_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn10_conv1"
  top: "dpn10_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn10_conv1_scale"
  type: "Scale"
  bottom: "dpn10_conv1"
  top: "dpn10_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn10_conv1_relu"
  type: "ReLU"
  bottom: "dpn10_conv1"
  top: "dpn10_conv1"
}
layer {
  name: "dpn10_conv2"
  type: "Convolution"
  bottom: "dpn10_conv1"
  top: "dpn10_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn10_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn10_conv2"
  top: "dpn10_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn10_conv2_scale"
  type: "Scale"
  bottom: "dpn10_conv2"
  top: "dpn10_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn10_conv2_relu"
  top: "dpn10_conv2"
  bottom: "dpn10_conv2"
  type: "ReLU"
}
layer {
  name: "dpn10_conv3"
  type: "Convolution"
  bottom: "dpn10_conv2"
  top: "dpn10_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn10_conv3_Slice"
  type: "Slice"
  bottom: "dpn10_conv3"
  top: "dpn10_conv3_split1"  # 0~1023
  top: "dpn10_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn10_elewise"
  type: "Eltwise"
  bottom: "dpn9_elewise"
  bottom: "dpn10_conv3_split1"
  top: "dpn10_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn10_concat"
  type: "Concat"
  bottom: "dpn9_concat"
  bottom: "dpn10_conv3_split2"
  top: "dpn10_concat"
}
#################### dpn11 ####################
layer {
  name: "dpn11_concat_input"
  type: "Concat"
  bottom: "dpn10_elewise"
  bottom: "dpn10_concat"
  top: "dpn11_concat_input"
}
layer {
  name: "dpn11_bn"
  type: "BatchNorm"
  bottom: "dpn11_concat_input"
  top: "dpn11_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn11_scale"
  type: "Scale"
  bottom: "dpn11_bn"
  top: "dpn11_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn11_relu"
  type: "ReLU"
  bottom: "dpn11_bn"
  top: "dpn11_bn"
}
layer {
  name: "dpn11_conv1"
  bottom: "dpn11_bn"
  top: "dpn11_conv1"
  type: "Convolution"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn11_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn11_conv1"
  top: "dpn11_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn11_conv1_scale"
  type: "Scale"
  bottom: "dpn11_conv1"
  top: "dpn11_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn11_conv1_relu"
  type: "ReLU"
  bottom: "dpn11_conv1"
  top: "dpn11_conv1"
}
layer {
  name: "dpn11_conv2"
  type: "Convolution"
  bottom: "dpn11_conv1"
  top: "dpn11_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn11_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn11_conv2"
  top: "dpn11_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn11_conv2_scale"
  type: "Scale"
  bottom: "dpn11_conv2"
  top: "dpn11_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn11_conv2_relu"
  type: "ReLU"
  bottom: "dpn11_conv2"
  top: "dpn11_conv2"
}
layer {
  name: "dpn11_conv3"
  type: "Convolution"
  bottom: "dpn11_conv2"
  top: "dpn11_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn11_conv3_Slice"
  type: "Slice"
  bottom: "dpn11_conv3"
  top: "dpn11_conv3_split1"  # 0~1023
  top: "dpn11_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn11_elewise"
  type: "Eltwise"
  bottom: "dpn10_elewise"
  bottom: "dpn11_conv3_split1"
  top: "dpn11_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn11_concat"
  type: "Concat"
  bottom: "dpn10_concat"
  bottom: "dpn11_conv3_split2"
  top: "dpn11_concat"
}
#################### dpn12 ####################
layer {
  name: "dpn12_concat_input"
  type: "Concat"
  bottom: "dpn11_elewise"
  bottom: "dpn11_concat"
  top: "dpn12_concat_input"
}
layer {
  name: "dpn12_bn"
  type: "BatchNorm"
  bottom: "dpn12_concat_input"
  top: "dpn12_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn12_scale"
  type: "Scale"
  bottom: "dpn12_bn"
  top: "dpn12_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn12_relu"
  type: "ReLU"
  bottom: "dpn12_bn"
  top: "dpn12_bn"
}
layer {
  name: "dpn12_conv1"
  type: "Convolution"
  bottom: "dpn12_bn"
  top: "dpn12_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn12_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn12_conv1"
  top: "dpn12_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn12_conv1_scale"
  type: "Scale"
  bottom: "dpn12_conv1"
  top: "dpn12_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn12_conv1_relu"
  type: "ReLU"
  bottom: "dpn12_conv1"
  top: "dpn12_conv1"
}
layer {
  name: "dpn12_conv2"
  type: "Convolution"
  bottom: "dpn12_conv1"
  top: "dpn12_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn12_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn12_conv2"
  top: "dpn12_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn12_conv2_scale"
  type: "Scale"
  bottom: "dpn12_conv2"
  top: "dpn12_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn12_conv2_relu"
  type: "ReLU"
  bottom: "dpn12_conv2"
  top: "dpn12_conv2"
}
layer {
  name: "dpn12_conv3"
  type: "Convolution"
  bottom: "dpn12_conv2"
  top: "dpn12_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn12_conv3_Slice"
  type: "Slice"
  bottom: "dpn12_conv3"
  top: "dpn12_conv3_split1"  # 0~1023
  top: "dpn12_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn12_elewise"
  type: "Eltwise"
  bottom: "dpn11_elewise"
  bottom: "dpn12_conv3_split1"
  top: "dpn12_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn12_concat"
  type: "Concat"
  bottom: "dpn11_concat"
  bottom: "dpn12_conv3_split2"
  top: "dpn12_concat"
}
#################### dpn13 ####################
layer {
  name: "dpn13_concat_input"
  type: "Concat"
  bottom: "dpn12_elewise"
  bottom: "dpn12_concat"
  top: "dpn13_concat_input"
}
layer {
  name: "dpn13_bn"
  type: "BatchNorm"
  bottom: "dpn13_concat_input"
  top: "dpn13_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_scale"
  type: "Scale"
  bottom: "dpn13_bn"
  top: "dpn13_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_relu"
  type: "ReLU"
  bottom: "dpn13_bn"
  top: "dpn13_bn"
}
layer {
  name: "dpn13_conv1"
  type: "Convolution"
  bottom: "dpn13_bn"
  top: "dpn13_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn13_conv1_bn"
  bottom: "dpn13_conv1"
  top: "dpn13_conv1"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_conv1_scale"
  type: "Scale"
  bottom: "dpn13_conv1"
  top: "dpn13_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_conv1_relu"
  type: "ReLU"
  bottom: "dpn13_conv1"
  top: "dpn13_conv1"
}
layer {
  name: "dpn13_conv2"
  type: "Convolution"
  bottom: "dpn13_conv1"
  top: "dpn13_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn13_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn13_conv2"
  top: "dpn13_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn13_conv2_scale"
  type: "Scale"
  bottom: "dpn13_conv2"
  top: "dpn13_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn13_conv2_relu"
  type: "ReLU"
  bottom: "dpn13_conv2"
  top: "dpn13_conv2"
}
layer {
  name: "dpn13_conv3"
  type: "Convolution"
  bottom: "dpn13_conv2"
  top: "dpn13_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn13_conv3_Slice"
  type: "Slice"
  bottom: "dpn13_conv3"
  top: "dpn13_conv3_split1"  # 0~1023
  top: "dpn13_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
   slice_point: 1024
  }
}
layer {
  name: "dpn13_elewise"
  type: "Eltwise"
  bottom: "dpn12_elewise"
  bottom: "dpn13_conv3_split1"
  top: "dpn13_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn13_concat"
  type: "Concat"
  bottom: "dpn12_concat"
  bottom: "dpn13_conv3_split2"
  top: "dpn13_concat"
}
#################### dpn14 ####################
layer {
  name: "dpn14_concat_input"
  type: "Concat"
  bottom: "dpn13_elewise"
  bottom: "dpn13_concat"
  top: "dpn14_concat_input"
}
layer {
  name: "dpn14_bn"
  type: "BatchNorm"
  bottom: "dpn14_concat_input"
  top: "dpn14_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn14_scale"
  type: "Scale"
  bottom: "dpn14_bn"
  top: "dpn14_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn14_relu"
  type: "ReLU"
  bottom: "dpn14_bn"
  top: "dpn14_bn"
}
layer {
  name: "dpn14_conv1"
  type: "Convolution"
  bottom: "dpn14_bn"
  top: "dpn14_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn14_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn14_conv1"
  top: "dpn14_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn14_conv1_scale"
  type: "Scale"
  bottom: "dpn14_conv1"
  top: "dpn14_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn14_conv1_relu"
  type: "ReLU"
  bottom: "dpn14_conv1"
  top: "dpn14_conv1"
}
layer {
  name: "dpn14_conv2"
  type: "Convolution"
  bottom: "dpn14_conv1"
  top: "dpn14_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn14_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn14_conv2"
  top: "dpn14_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn14_conv2_scale"
  type: "Scale"
  bottom: "dpn14_conv2"
  top: "dpn14_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn14_conv2_relu"
  type: "ReLU"
  bottom: "dpn14_conv2"
  top: "dpn14_conv2"
}
layer {
  name: "dpn14_conv3"
  type: "Convolution"
  bottom: "dpn14_conv2"
  top: "dpn14_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn14_conv3_Slice"
  type: "Slice"
  bottom: "dpn14_conv3"
  top: "dpn14_conv3_split1"  # 0~1023
  top: "dpn14_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn14_elewise"
  type: "Eltwise"
  bottom: "dpn13_elewise"
  bottom: "dpn14_conv3_split1"
  top: "dpn14_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn14_concat"
  type: "Concat"
  bottom: "dpn13_concat"
  bottom: "dpn14_conv3_split2"
  top: "dpn14_concat"
}
#################### dpn15 ####################
layer {
  name: "dpn15_concat_input"
  type: "Concat"
  bottom: "dpn14_elewise"
  bottom: "dpn14_concat"
  top: "dpn15_concat_input"
}
layer {
  name: "dpn15_bn"
  type: "BatchNorm"
  bottom: "dpn15_concat_input"
  top: "dpn15_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn15_scale"
  type: "Scale"
  bottom: "dpn15_bn"
  top: "dpn15_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn15_relu"
  type: "ReLU"
  bottom: "dpn15_bn"
  top: "dpn15_bn"
}
layer {
  name: "dpn15_conv1"
  type: "Convolution"
  bottom: "dpn15_bn"
  top: "dpn15_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn15_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn15_conv1"
  top: "dpn15_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn15_conv1_scale"
  type: "Scale"
  bottom: "dpn15_conv1"
  top: "dpn15_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn15_conv1_relu"
  type: "ReLU"
  bottom: "dpn15_conv1"
  top: "dpn15_conv1"
}
layer {
  name: "dpn15_conv2"
  bottom: "dpn15_conv1"
  top: "dpn15_conv2"
  type: "Convolution"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn15_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn15_conv2"
  top: "dpn15_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn15_conv2_scale"
  type: "Scale"
  bottom: "dpn15_conv2"
  top: "dpn15_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn15_conv2_relu"
  type: "ReLU"
  bottom: "dpn15_conv2"
  top: "dpn15_conv2"
}
layer {
  name: "dpn15_conv3"
  type: "Convolution"
  bottom: "dpn15_conv2"
  top: "dpn15_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn15_conv3_Slice"
  type: "Slice"
  bottom: "dpn15_conv3"
  top: "dpn15_conv3_split1"  # 0~1023
  top: "dpn15_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn15_elewise"
  type: "Eltwise"
  bottom: "dpn14_elewise"
  bottom: "dpn15_conv3_split1"
  top: "dpn15_elewise"
  eltwise_param {
   operation: SUM
  }
}
layer {
  name: "dpn15_concat"
  type: "Concat"
  bottom: "dpn14_concat"
  bottom: "dpn15_conv3_split2"
  top: "dpn15_concat"
}
#################### dpn16 ####################
layer {
  name: "dpn16_concat_input"
  type: "Concat"
  bottom: "dpn15_elewise"
  bottom: "dpn15_concat"
  top: "dpn16_concat_input"
}
layer {
  name: "dpn16_bn"
  type: "BatchNorm"
  bottom: "dpn16_concat_input"
  top: "dpn16_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn16_scale"
  type: "Scale"
  bottom: "dpn16_bn"
  top: "dpn16_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn16_relu"
  type: "ReLU"
  bottom: "dpn16_bn"
  top: "dpn16_bn"
}
layer {
  name: "dpn16_conv1"
  type: "Convolution"
  bottom: "dpn16_bn"
  top: "dpn16_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn16_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn16_conv1"
  top: "dpn16_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn16_conv1_scale"
  type: "Scale"
  bottom: "dpn16_conv1"
  top: "dpn16_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn16_conv1_relu"
  type: "ReLU"
  bottom: "dpn16_conv1"
  top: "dpn16_conv1"
}
layer {
  name: "dpn16_conv2"
  type: "Convolution"
  bottom: "dpn16_conv1"
  top: "dpn16_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn16_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn16_conv2"
  top: "dpn16_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn16_conv2_scale"
  type: "Scale"
  bottom: "dpn16_conv2"
  top: "dpn16_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn16_conv2_relu"
  type: "ReLU"
  bottom: "dpn16_conv2"
  top: "dpn16_conv2"
}
layer {
  name: "dpn16_conv3"
  type: "Convolution"
  bottom: "dpn16_conv2"
  top: "dpn16_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn16_conv3_Slice"
  type: "Slice"
  bottom: "dpn16_conv3"
  top: "dpn16_conv3_split1"  # 0~1023
  top: "dpn16_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn16_elewise"
  type: "Eltwise"
  bottom: "dpn15_elewise"
  bottom: "dpn16_conv3_split1"
  top: "dpn16_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn16_concat"
  type: "Concat"
  bottom: "dpn15_concat"
  bottom: "dpn16_conv3_split2"
  top: "dpn16_concat"
}
#################### dpn17 ####################
layer {
  name: "dpn17_concat_input"
  type: "Concat"
  bottom: "dpn16_elewise"
  bottom: "dpn16_concat"
  top: "dpn17_concat_input"
}
layer {
  name: "dpn17_bn"
  type: "BatchNorm"
  bottom: "dpn17_concat_input"
  top: "dpn17_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn17_scale"
  type: "Scale"
  bottom: "dpn17_bn"
  top: "dpn17_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn17_relu"
  type: "ReLU"
  bottom: "dpn17_bn"
  top: "dpn17_bn"
}
layer {
  name: "dpn17_conv1"
  type: "Convolution"
  bottom: "dpn17_bn"
  top: "dpn17_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn17_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn17_conv1"
  top: "dpn17_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn17_conv1_scale"
  type: "Scale"
  bottom: "dpn17_conv1"
  top: "dpn17_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn17_conv1_relu"
  type: "ReLU"
  bottom: "dpn17_conv1"
  top: "dpn17_conv1"
}
layer {
  name: "dpn17_conv2"
  type: "Convolution"
  bottom: "dpn17_conv1"
  top: "dpn17_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn17_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn17_conv2"
  top: "dpn17_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn17_conv2_scale"
  type: "Scale"
  bottom: "dpn17_conv2"
  top: "dpn17_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn17_conv2_relu"
  type: "ReLU"
  bottom: "dpn17_conv2"
  top: "dpn17_conv2"
}
layer {
  name: "dpn17_conv3"
  type: "Convolution"
  bottom: "dpn17_conv2"
  top: "dpn17_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn17_conv3_Slice"
  type: "Slice"
  bottom: "dpn17_conv3"
  top: "dpn17_conv3_split1"  # 0~1023
  top: "dpn17_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
   slice_point: 1024
  }
}
layer {
  name: "dpn17_elewise"
  type: "Eltwise"
  bottom: "dpn16_elewise"
  bottom: "dpn17_conv3_split1"
  top: "dpn17_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn17_concat"
  type: "Concat"
  bottom: "dpn16_concat"
  bottom: "dpn17_conv3_split2"
  top: "dpn17_concat"
}
#################### dpn18 ####################
layer {
  name: "dpn18_concat_input"
  type: "Concat"
  bottom: "dpn17_elewise"
  bottom: "dpn17_concat"
  top: "dpn18_concat_input"
}
layer {
  name: "dpn18_bn"
  type: "BatchNorm"
  bottom: "dpn18_concat_input"
  top: "dpn18_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn18_scale"
  type: "Scale"
  bottom: "dpn18_bn"
  top: "dpn18_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn18_relu"
  type: "ReLU"
  bottom: "dpn18_bn"
  top: "dpn18_bn"
}
layer {
  name: "dpn18_conv1"
  type: "Convolution"
  bottom: "dpn18_bn"
  top: "dpn18_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn18_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn18_conv1"
  top: "dpn18_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn18_conv1_scale"
  type: "Scale"
  bottom: "dpn18_conv1"
  top: "dpn18_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn18_conv1_relu"
  type: "ReLU"
  bottom: "dpn18_conv1"
  top: "dpn18_conv1"
}
layer {
  name: "dpn18_conv2"
  type: "Convolution"
  bottom: "dpn18_conv1"
  top: "dpn18_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn18_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn18_conv2"
  top: "dpn18_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn18_conv2_scale"
  type: "Scale"
  bottom: "dpn18_conv2"
  top: "dpn18_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn18_conv2_relu"
  type: "ReLU"
  bottom: "dpn18_conv2"
  top: "dpn18_conv2"
}
layer {
  name: "dpn18_conv3"
  type: "Convolution"
  bottom: "dpn18_conv2"
  top: "dpn18_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn18_conv3_Slice"
  type: "Slice"
  bottom: "dpn18_conv3"
  top: "dpn18_conv3_split1"  # 0~1023
  top: "dpn18_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn18_elewise"
  type: "Eltwise"
  bottom: "dpn17_elewise"
  bottom: "dpn18_conv3_split1"
  top: "dpn18_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn18_concat"
  type: "Concat"
  bottom: "dpn17_concat"
  bottom: "dpn18_conv3_split2"
  top: "dpn18_concat"
}
#################### dpn19 ####################
layer {
  name: "dpn19_concat_input"
  type: "Concat"
  bottom: "dpn18_elewise"
  bottom: "dpn18_concat"
  top: "dpn19_concat_input"
}
layer {
  name: "dpn19_bn"
  type: "BatchNorm"
  bottom: "dpn19_concat_input"
  top: "dpn19_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn19_scale"
  type: "Scale"
  bottom: "dpn19_bn"
  top: "dpn19_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn19_relu"
  type: "ReLU"
  bottom: "dpn19_bn"
  top: "dpn19_bn"
}
layer {
  name: "dpn19_conv1"
  type: "Convolution"
  bottom: "dpn19_bn"
  top: "dpn19_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn19_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn19_conv1"
  top: "dpn19_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn19_conv1_scale"
  type: "Scale"
  bottom: "dpn19_conv1"
  top: "dpn19_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn19_conv1_relu"
  type: "ReLU"
  bottom: "dpn19_conv1"
  top: "dpn19_conv1"
}
layer {
  name: "dpn19_conv2"
  type: "Convolution"
  bottom: "dpn19_conv1"
  top: "dpn19_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn19_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn19_conv2"
  top: "dpn19_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn19_conv2_scale"
  type: "Scale"
  bottom: "dpn19_conv2"
  top: "dpn19_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn19_conv2_relu"
  type: "ReLU"
  bottom: "dpn19_conv2"
  top: "dpn19_conv2"
}
layer {
  name: "dpn19_conv3"
  type: "Convolution"
  bottom: "dpn19_conv2"
  top: "dpn19_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn19_conv3_Slice"
  type: "Slice"
  bottom: "dpn19_conv3"
  top: "dpn19_conv3_split1"  # 0~1023
  top: "dpn19_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn19_elewise"
  type: "Eltwise"
  bottom: "dpn18_elewise"
  bottom: "dpn19_conv3_split1"
  top: "dpn19_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn19_concat"
  type: "Concat"
  bottom: "dpn18_concat"
  bottom: "dpn19_conv3_split2"
  top: "dpn19_concat"
}
#################### dpn20 ####################
layer {
  name: "dpn20_concat_input"
  type: "Concat"
  bottom: "dpn19_elewise"
  bottom: "dpn19_concat"
  top: "dpn20_concat_input"
}
layer {
  name: "dpn20_bn"
  type: "BatchNorm"
  bottom: "dpn20_concat_input"
  top: "dpn20_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn20_scale"
  type: "Scale"
  bottom: "dpn20_bn"
  top: "dpn20_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn20_relu"
  type: "ReLU"
  bottom: "dpn20_bn"
  top: "dpn20_bn"
}
layer {
  name: "dpn20_conv1"
  type: "Convolution"
  bottom: "dpn20_bn"
  top: "dpn20_conv1"
	convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn20_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn20_conv1"
  top: "dpn20_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn20_conv1_scale"
  type: "Scale"
  bottom: "dpn20_conv1"
  top: "dpn20_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn20_conv1_relu"
  type: "ReLU"
  bottom: "dpn20_conv1"
  top: "dpn20_conv1"
}
layer {
  name: "dpn20_conv2"
  type: "Convolution"
  bottom: "dpn20_conv1"
  top: "dpn20_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn20_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn20_conv2"
  top: "dpn20_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn20_conv2_scale"
  type: "Scale"
  bottom: "dpn20_conv2"
  top: "dpn20_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn20_conv2_relu"
  type: "ReLU"
  bottom: "dpn20_conv2"
  top: "dpn20_conv2"
}
layer {
  name: "dpn20_conv3"
  type: "Convolution"
  bottom: "dpn20_conv2"
  top: "dpn20_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn20_conv3_Slice"
  type: "Slice"
  bottom: "dpn20_conv3"
  top: "dpn20_conv3_split1"  # 0~1023
  top: "dpn20_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn20_elewise"
  type: "Eltwise"
  bottom: "dpn19_elewise"
  bottom: "dpn20_conv3_split1"
  top: "dpn20_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn20_concat"
  type: "Concat"
  bottom: "dpn19_concat"
  bottom: "dpn20_conv3_split2"
  top: "dpn20_concat"
}
#################### dpn21 ####################
layer {
  name: "dpn21_concat_input"
  type: "Concat"
  bottom: "dpn20_elewise"
  bottom: "dpn20_concat"
  top: "dpn21_concat_input"
}
layer {
  name: "dpn21_bn"
  type: "BatchNorm"
  bottom: "dpn21_concat_input"
  top: "dpn21_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn21_scale"
  type: "Scale"
  bottom: "dpn21_bn"
  top: "dpn21_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn21_relu"
  type: "ReLU"
  bottom: "dpn21_bn"
  top: "dpn21_bn"
}
layer {
  name: "dpn21_conv1"
  type: "Convolution"
  bottom: "dpn21_bn"
  top: "dpn21_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn21_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn21_conv1"
  top: "dpn21_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn21_conv1_scale"
  type: "Scale"
  bottom: "dpn21_conv1"
  top: "dpn21_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn21_conv1_relu"
  type: "ReLU"
  bottom: "dpn21_conv1"
  top: "dpn21_conv1"
}
layer {
  name: "dpn21_conv2"
  type: "Convolution"
  bottom: "dpn21_conv1"
  top: "dpn21_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn21_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn21_conv2"
  top: "dpn21_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn21_conv2_scale"
  type: "Scale"
  bottom: "dpn21_conv2"
  top: "dpn21_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn21_conv2_relu"
  type: "ReLU"
  bottom: "dpn21_conv2"
  top: "dpn21_conv2"
}
layer {
  name: "dpn21_conv3"
  type: "Convolution"
  bottom: "dpn21_conv2"
  top: "dpn21_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn21_conv3_Slice"
  type: "Slice"
  bottom: "dpn21_conv3"
  top: "dpn21_conv3_split1"  # 0~1023
  top: "dpn21_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn21_elewise"
  type: "Eltwise"
  bottom: "dpn20_elewise"
  bottom: "dpn21_conv3_split1"
  top: "dpn21_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn21_concat"
  type: "Concat"
  bottom: "dpn20_concat"
  bottom: "dpn21_conv3_split2"
  top: "dpn21_concat"
}
#################### dpn22 ####################
layer {
  name: "dpn22_concat_input"
  type: "Concat"
  bottom: "dpn21_elewise"
  bottom: "dpn21_concat"
  top: "dpn22_concat_input"
}
layer {
  name: "dpn22_bn"
  type: "BatchNorm"
  bottom: "dpn22_concat_input"
  top: "dpn22_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn22_scale"
  type: "Scale"
  bottom: "dpn22_bn"
  top: "dpn22_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn22_relu"
  type: "ReLU"
  bottom: "dpn22_bn"
  top: "dpn22_bn"
}
layer {
  name: "dpn22_conv1"
  type: "Convolution"
  bottom: "dpn22_bn"
  top: "dpn22_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn22_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn22_conv1"
  top: "dpn22_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn22_conv1_scale"
  type: "Scale"
  bottom: "dpn22_conv1"
  top: "dpn22_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn22_conv1_relu"
  type: "ReLU"
  bottom: "dpn22_conv1"
  top: "dpn22_conv1"
}
layer {
  name: "dpn22_conv2"
  type: "Convolution"
  bottom: "dpn22_conv1"
  top: "dpn22_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn22_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn22_conv2"
  top: "dpn22_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn22_conv2_scale"
  type: "Scale"
  bottom: "dpn22_conv2"
  top: "dpn22_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn22_conv2_relu"
  type: "ReLU"
  bottom: "dpn22_conv2"
  top: "dpn22_conv2"
}
layer {
  name: "dpn22_conv3"
  type: "Convolution"
  bottom: "dpn22_conv2"
  top: "dpn22_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn22_conv3_Slice"
  type: "Slice"
  bottom: "dpn22_conv3"
  top: "dpn22_conv3_split1"  # 0~1023
  top: "dpn22_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn22_elewise"
  type: "Eltwise"
  bottom: "dpn21_elewise"
  bottom: "dpn22_conv3_split1"
  top: "dpn22_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn22_concat"
  type: "Concat"
  bottom: "dpn21_concat"
  bottom: "dpn22_conv3_split2"
  top: "dpn22_concat"
}
#################### dpn23 ####################
layer {
  name: "dpn23_concat_input"
  type: "Concat"
  bottom: "dpn22_elewise"
  bottom: "dpn22_concat"
  top: "dpn23_concat_input"
}
layer {
  name: "dpn23_bn"
  type: "BatchNorm"
  bottom: "dpn23_concat_input"
  top: "dpn23_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn23_scale"
  type: "Scale"
  bottom: "dpn23_bn"
  top: "dpn23_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn23_relu"
  type: "ReLU"
  bottom: "dpn23_bn"
  top: "dpn23_bn"
}
layer {
  name: "dpn23_conv1"
  type: "Convolution"
  bottom: "dpn23_bn"
  top: "dpn23_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn23_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn23_conv1"
  top: "dpn23_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn23_conv1_scale"
  type: "Scale"
  bottom: "dpn23_conv1"
  top: "dpn23_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn23_conv1_relu"
  type: "ReLU"
  bottom: "dpn23_conv1"
  top: "dpn23_conv1"
}
layer {
  name: "dpn23_conv2"
  type: "Convolution"
  bottom: "dpn23_conv1"
  top: "dpn23_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn23_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn23_conv2"
  top: "dpn23_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn23_conv2_scale"
  type: "Scale"
  bottom: "dpn23_conv2"
  top: "dpn23_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn23_conv2_relu"
  type: "ReLU"
  bottom: "dpn23_conv2"
  top: "dpn23_conv2"
}
layer {
  name: "dpn23_conv3"
  bottom: "dpn23_conv2"
  top: "dpn23_conv3"
  type: "Convolution"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn23_conv3_Slice"
  type: "Slice"
  bottom: "dpn23_conv3"
  top: "dpn23_conv3_split1"  # 0~1023
  top: "dpn23_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn23_elewise"
  type: "Eltwise"
  bottom: "dpn22_elewise"
  bottom: "dpn23_conv3_split1"
  top: "dpn23_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn23_concat"
  type: "Concat"
  bottom: "dpn22_concat"
  bottom: "dpn23_conv3_split2"
  top: "dpn23_concat"
}
#################### dpn24 ####################
layer {
  name: "dpn24_concat_input"
  type: "Concat"
  bottom: "dpn23_elewise"
  bottom: "dpn23_concat"
  top: "dpn24_concat_input"
}
layer {
  name: "dpn24_bn"
  type: "BatchNorm"
  bottom: "dpn24_concat_input"
  top: "dpn24_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn24_scale"
  type: "Scale"
  bottom: "dpn24_bn"
  top: "dpn24_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn24_relu"
  type: "ReLU"
  bottom: "dpn24_bn"
  top: "dpn24_bn"
}
layer {
  name: "dpn24_conv1"
  type: "Convolution"
  bottom: "dpn24_bn"
  top: "dpn24_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn24_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn24_conv1"
  top: "dpn24_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn24_conv1_scale"
  type: "Scale"
  bottom: "dpn24_conv1"
  top: "dpn24_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn24_conv1_relu"
  type: "ReLU"
  bottom: "dpn24_conv1"
  top: "dpn24_conv1"
}
layer {
  name: "dpn24_conv2"
  type: "Convolution"
  bottom: "dpn24_conv1"
  top: "dpn24_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn24_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn24_conv2"
  top: "dpn24_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn24_conv2_scale"
  type: "Scale"
  bottom: "dpn24_conv2"
  top: "dpn24_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn24_conv2_relu"
  type: "ReLU"
  bottom: "dpn24_conv2"
  top: "dpn24_conv2"
}
layer {
  name: "dpn24_conv3"
  type: "Convolution"
  bottom: "dpn24_conv2"
  top: "dpn24_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn24_conv3_Slice"
  type: "Slice"
  bottom: "dpn24_conv3"
  top: "dpn24_conv3_split1"  # 0~1023
  top: "dpn24_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn24_elewise"
  type: "Eltwise"
  bottom: "dpn23_elewise"
  bottom: "dpn24_conv3_split1"
  top: "dpn24_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn24_concat"
  type: "Concat"
  bottom: "dpn23_concat"
  bottom: "dpn24_conv3_split2"
  top: "dpn24_concat"
}
#################### dpn25 ####################
layer {
  name: "dpn25_concat_input"
  type: "Concat"
  bottom: "dpn24_elewise"
  bottom: "dpn24_concat"
  top: "dpn25_concat_input"
}
layer {
  name: "dpn25_bn"
  type: "BatchNorm"
  bottom: "dpn25_concat_input"
  top: "dpn25_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn25_scale"
  type: "Scale"
  bottom: "dpn25_bn"
  top: "dpn25_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn25_relu"
  type: "ReLU"
  bottom: "dpn25_bn"
  top: "dpn25_bn"
}
layer {
  name: "dpn25_conv1"
  type: "Convolution"
  bottom: "dpn25_bn"
  top: "dpn25_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn25_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn25_conv1"
  top: "dpn25_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn25_conv1_scale"
  type: "Scale"
  bottom: "dpn25_conv1"
  top: "dpn25_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn25_conv1_relu"
  type: "ReLU"
  bottom: "dpn25_conv1"
  top: "dpn25_conv1"
}
layer {
  name: "dpn25_conv2"
  type: "Convolution"
  bottom: "dpn25_conv1"
  top: "dpn25_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn25_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn25_conv2"
  top: "dpn25_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn25_conv2_scale"
  type: "Scale"
  bottom: "dpn25_conv2"
  top: "dpn25_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn25_conv2_relu"
  type: "ReLU"
  bottom: "dpn25_conv2"
  top: "dpn25_conv2"
}
layer {
  name: "dpn25_conv3"
  type: "Convolution"
  bottom: "dpn25_conv2"
  top: "dpn25_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn25_conv3_Slice"
  type: "Slice"
  bottom: "dpn25_conv3"
  top: "dpn25_conv3_split1"  # 0~1023
  top: "dpn25_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn25_elewise"
  type: "Eltwise"
  bottom: "dpn24_elewise"
  bottom: "dpn25_conv3_split1"
  top: "dpn25_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn25_concat"
  type: "Concat"
  bottom: "dpn24_concat"
  bottom: "dpn25_conv3_split2"
  top: "dpn25_concat"
}
#################### dpn26 ####################
layer {
  name: "dpn26_concat_input"
  type: "Concat"
  bottom: "dpn25_elewise"
  bottom: "dpn25_concat"
  top: "dpn26_concat_input"
}
layer {
  name: "dpn26_bn"
  type: "BatchNorm"
  bottom: "dpn26_concat_input"
  top: "dpn26_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn26_scale"
  type: "Scale"
  bottom: "dpn26_bn"
  top: "dpn26_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn26_relu"
  type: "ReLU"
  bottom: "dpn26_bn"
  top: "dpn26_bn"
}
layer {
  name: "dpn26_conv1"
  type: "Convolution"
  bottom: "dpn26_bn"
  top: "dpn26_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn26_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn26_conv1"
  top: "dpn26_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn26_conv1_scale"
  type: "Scale"
  bottom: "dpn26_conv1"
  top: "dpn26_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn26_conv1_relu"
  type: "ReLU"
  bottom: "dpn26_conv1"
  top: "dpn26_conv1"
}
layer {
  name: "dpn26_conv2"
  type: "Convolution"
  bottom: "dpn26_conv1"
  top: "dpn26_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn26_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn26_conv2"
  top: "dpn26_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn26_conv2_scale"
  type: "Scale"
  bottom: "dpn26_conv2"
  top: "dpn26_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn26_conv2_relu"
  type: "ReLU"
  bottom: "dpn26_conv2"
  top: "dpn26_conv2"
}
layer {
  name: "dpn26_conv3"
  type: "Convolution"
  bottom: "dpn26_conv2"
  top: "dpn26_conv3"
  convolution_param {
    num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn26_conv3_Slice"
  type: "Slice"
  bottom: "dpn26_conv3"
  top: "dpn26_conv3_split1"  # 0~1023
  top: "dpn26_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn26_elewise"
  type: "Eltwise"
  bottom: "dpn25_elewise"
  bottom: "dpn26_conv3_split1"
  top: "dpn26_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn26_concat"
  type: "Concat"
  bottom: "dpn25_concat"
  bottom: "dpn26_conv3_split2"
  top: "dpn26_concat"
}
#################### dpn27 ####################
layer {
  name: "dpn27_concat_input"
  type: "Concat"
  bottom: "dpn26_elewise"
  bottom: "dpn26_concat"
  top: "dpn27_concat_input"
}
layer {
  name: "dpn27_bn"
  type: "BatchNorm"
  bottom: "dpn27_concat_input"
  top: "dpn27_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn27_scale"
  type: "Scale"
  bottom: "dpn27_bn"
  top: "dpn27_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn27_relu"
  type: "ReLU"
  bottom: "dpn27_bn"
  top: "dpn27_bn"
}
layer {
  name: "dpn27_conv1"
  type: "Convolution"
  bottom: "dpn27_bn"
  top: "dpn27_conv1"
  convolution_param {
    num_output: 384
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn27_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn27_conv1"
  top: "dpn27_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn27_conv1_scale"
  type: "Scale"
  bottom: "dpn27_conv1"
  top: "dpn27_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn27_conv1_relu"
  type: "ReLU"
  bottom: "dpn27_conv1"
  top: "dpn27_conv1"
}
layer {
  name: "dpn27_conv2"
  type: "Convolution"
  bottom: "dpn27_conv1"
  top: "dpn27_conv2"
  convolution_param {
    num_output: 384
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn27_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn27_conv2"
  top: "dpn27_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn27_conv2_scale"
  type: "Scale"
  bottom: "dpn27_conv2"
  top: "dpn27_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn27_conv2_relu"
  type: "ReLU"
  bottom: "dpn27_conv2"
  top: "dpn27_conv2"
}
layer {
  name: "dpn27_conv3"
  type: "Convolution"
  bottom: "dpn27_conv2"
  top: "dpn27_conv3"
  convolution_param {
  num_output: 1048
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn27_conv3_Slice"
  type: "Slice"
  bottom: "dpn27_conv3"
  top: "dpn27_conv3_split1"  # 0~1023
  top: "dpn27_conv3_split2"  # 1024~1048
  slice_param {
    axis: 1
    slice_point: 1024
  }
}
layer {
  name: "dpn27_elewise"
  type: "Eltwise"
  bottom: "dpn26_elewise"
  bottom: "dpn27_conv3_split1"
  top: "dpn27_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn27_concat"
  type: "Concat"
  bottom: "dpn26_concat"
  bottom: "dpn27_conv3_split2"
  top: "dpn27_concat"
}
#################### dpn28 ####################
layer {
  name: "dpn28_concat_input"
  type: "Concat"
  bottom: "dpn27_elewise"
  bottom: "dpn27_concat"
  top: "dpn28_concat_input"
}
layer {
  name: "dpn28_match_bn"
  type: "BatchNorm"
  bottom: "dpn28_concat_input"
  top: "dpn28_match_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_match_scale"
  type: "Scale"
  bottom: "dpn28_match_bn"
  top: "dpn28_match_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_match_relu"
  type: "ReLU"
  bottom: "dpn28_match_bn"
  top: "dpn28_match_bn"
}
layer {
  name: "dpn28_match_conv"
  type: "Convolution"
  bottom: "dpn28_match_bn"
  top: "dpn28_match_conv"
  convolution_param {
    num_output: 2304
    kernel_size: 1
    pad: 0
    stride: 2
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn28_match_conv_Slice"
  type: "Slice"
  bottom: "dpn28_match_conv"
  top: "dpn28_match_conv_split1"  # 0~2047
  top: "dpn28_match_conv_split2"  # 2048~2304
  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn28_bn"
  type: "BatchNorm"
  bottom: "dpn28_concat_input"
  top: "dpn28_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_scale"
  type: "Scale"
  bottom: "dpn28_bn"
  top: "dpn28_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_relu"
  type: "ReLU"
  bottom: "dpn28_bn"
  top: "dpn28_bn"
}
layer {
  name: "dpn28_conv1"
  type: "Convolution"
  bottom: "dpn28_bn"
  top: "dpn28_conv1"
  convolution_param {
    num_output: 768
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn28_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn28_conv1"
  top: "dpn28_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_conv1_scale"
  type: "Scale"
  bottom: "dpn28_conv1"
  top: "dpn28_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_conv1_relu"
  type: "ReLU"
  bottom: "dpn28_conv1"
  top: "dpn28_conv1"
}
layer {
  name: "dpn28_conv2"
  type: "Convolution"
  bottom: "dpn28_conv1"
  top: "dpn28_conv2"
  convolution_param {
    num_output: 768
    kernel_size: 3
    pad: 1
    stride: 2
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn28_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn28_conv2"
  top: "dpn28_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn28_conv2_scale"
  type: "Scale"
  bottom: "dpn28_conv2"
  top: "dpn28_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn28_conv2_relu"
  type: "ReLU"
  bottom: "dpn28_conv2"
  top: "dpn28_conv2"
}
layer {
  name: "dpn28_conv3"
  type: "Convolution"
  bottom: "dpn28_conv2"
  top: "dpn28_conv3"
  convolution_param {
    num_output: 2176
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn28_conv3_Slice"
  type: "Slice"
  bottom: "dpn28_conv3"
  top: "dpn28_conv3_split1"  # 0~2047
  top: "dpn28_conv3_split2"  # 2048~2176
  slice_param {
    axis: 1
   slice_point: 2048
  }
}
layer {
  name: "dpn28_elewise"
  type: "Eltwise"
  bottom: "dpn28_match_conv_split1"
  bottom: "dpn28_conv3_split1"
  top: "dpn28_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn28_concat"
  type: "Concat"
  bottom: "dpn28_match_conv_split2"
  bottom: "dpn28_conv3_split2"
  top: "dpn28_concat"
}
#################### dpn29 ####################
layer {
  name: "dpn29_concat_input"
  type: "Concat"
  bottom: "dpn28_elewise"
  bottom: "dpn28_concat"
  top: "dpn29_concat_input"
}
layer {
  name: "dpn29_bn"
  type: "BatchNorm"
  bottom: "dpn29_concat_input"
  top: "dpn29_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn29_scale"
  type: "Scale"
  bottom: "dpn29_bn"
  top: "dpn29_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn29_relu"
  type: "ReLU"
  bottom: "dpn29_bn"
  top: "dpn29_bn"
}
layer {
  name: "dpn29_conv1"
  type: "Convolution"
  bottom: "dpn29_bn"
  top: "dpn29_conv1"
  convolution_param {
    num_output: 768
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn29_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn29_conv1"
  top: "dpn29_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn29_conv1_scale"
  type: "Scale"
  bottom: "dpn29_conv1"
  top: "dpn29_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn29_conv1_relu"
  type: "ReLU"
  bottom: "dpn29_conv1"
  top: "dpn29_conv1"
}
layer {
  name: "dpn29_conv2"
  type: "Convolution"
  bottom: "dpn29_conv1"
  top: "dpn29_conv2"
  convolution_param {
    num_output: 768
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn29_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn29_conv2"
  top: "dpn29_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn29_conv2_scale"
  type: "Scale"
  bottom: "dpn29_conv2"
  top: "dpn29_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn29_conv2_relu"
  type: "ReLU"
  bottom: "dpn29_conv2"
  top: "dpn29_conv2"
}
layer {
  name: "dpn29_conv3"
  type: "Convolution"
  bottom: "dpn29_conv2"
  top: "dpn29_conv3"
  convolution_param {
    num_output: 2176
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn29_conv3_Slice"
  type: "Slice"
  bottom: "dpn29_conv3"
  top: "dpn29_conv3_split1"  # 0~2047
  top: "dpn29_conv3_split2"  # 2048~2176
  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn29_elewise"
  type: "Eltwise"
  bottom: "dpn28_elewise"
  bottom: "dpn29_conv3_split1"
  top: "dpn29_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn29_concat"
  type: "Concat"
  bottom: "dpn28_concat"
  bottom: "dpn29_conv3_split2"
  top: "dpn29_concat"
}
#################### dpn30 ####################
layer {
  name: "dpn30_concat_input"
  type: "Concat"
  bottom: "dpn29_elewise"
  bottom: "dpn29_concat"
  top: "dpn30_concat_input"
}
layer {
  name: "dpn30_bn"
  type: "BatchNorm"
  bottom: "dpn30_concat_input"
  top: "dpn30_bn"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn30_scale"
  type: "Scale"
  bottom: "dpn30_bn"
  top: "dpn30_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn30_relu"
  type: "ReLU"
  bottom: "dpn30_bn"
  top: "dpn30_bn"
}
layer {
  name: "dpn30_conv1"
  type: "Convolution"
  bottom: "dpn30_bn"
  top: "dpn30_conv1"
  convolution_param {
    num_output: 768
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn30_conv1_bn"
  type: "BatchNorm"
  bottom: "dpn30_conv1"
  top: "dpn30_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn30_conv1_scale"
  type: "Scale"
  bottom: "dpn30_conv1"
  top: "dpn30_conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn30_conv1_relu"
  type: "ReLU"
  bottom: "dpn30_conv1"
  top: "dpn30_conv1"
}
layer {
  name: "dpn30_conv2"
  type: "Convolution"
  bottom: "dpn30_conv1"
  top: "dpn30_conv2"
  convolution_param {
    num_output: 768
    kernel_size: 3
    pad: 1
    stride: 1
    # dilation: 1
    group: 32
    bias_term: false
  }
}
layer {
  name: "dpn30_conv2_bn"
  type: "BatchNorm"
  bottom: "dpn30_conv2"
  top: "dpn30_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "dpn30_conv2_scale"
  type: "Scale"
  bottom: "dpn30_conv2"
  top: "dpn30_conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "dpn30_conv2_relu"
  type: "ReLU"
  bottom: "dpn30_conv2"
  top: "dpn30_conv2"
}
layer {
  name: "dpn30_conv3"
  type: "Convolution"
  bottom: "dpn30_conv2"
  top: "dpn30_conv3"
  convolution_param {
    num_output: 2176
    kernel_size: 1
    pad: 0
    stride: 1
    # dilation: 1
    group: 1
    bias_term: false
  }
}
layer {
  name: "dpn30_conv3_Slice"
  type: "Slice"
  bottom: "dpn30_conv3"
  top: "dpn30_conv3_split1"  # 0~2047
  top: "dpn30_conv3_split2"  # 2048~2176
  slice_param {
    axis: 1
    slice_point: 2048
  }
}
layer {
  name: "dpn30_elewise"
  type: "Eltwise"
  bottom: "dpn29_elewise"
  bottom: "dpn30_conv3_split1"
  top: "dpn30_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "dpn30_concat"
  type: "Concat"
  bottom: "dpn29_concat"
  bottom: "dpn30_conv3_split2"
  top: "dpn30_concat"
}
#################### pool_ave ####################
layer {
  name: "pool_ave_concat_input"
  type: "Concat"
  bottom: "dpn30_elewise"
  bottom: "dpn30_concat"
  top: "pool_ave_concat_input"
}
layer {
  name: "pool_ave_concat_bn"
  bottom: "pool_ave_concat_input"
  top: "pool_ave_concat_bn"
  type: "BatchNorm"
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "pool_ave_concat_scale"
  type: "Scale"
  bottom: "pool_ave_concat_bn"
  top: "pool_ave_concat_bn"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "pool_ave_concat_relu"
  type: "ReLU"
  bottom: "pool_ave_concat_bn"
  top: "pool_ave_concat_bn"
}
layer {
  name: "pool_ave"
  type: "Pooling"
  bottom: "pool_ave_concat_bn"
  top: "pool_ave"
  pooling_param {
    global_pooling : true
    pool: AVE
  }
}
layer {
  name: "pool_ave_flat"
  type: "Flatten"
  bottom: "pool_ave"
  top: "pool_ave_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "classifier"
  type: "InnerProduct"
  bottom: "pool_ave_flat"
  top: "classifier"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "classifier"
  top: "prob"
}